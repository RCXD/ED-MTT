{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### This notebook shows how to reproduce the results of Engagement Detection with Multi-Task Training (ED-MTT) system\n",
        "## Note\n",
        "Before running this notebook make sure that your runtime type is 'Python 3 with GPU acceleration'. Go to Edit > Notebook settings > Hardware Accelerator > Select \"GPU\".\n",
        "\n",
        "## More Info\n",
        "- Paper: \n",
        "- Repo: https://github.com/CopurOnur/ED-MTT"
      ],
      "metadata": {
        "id": "T5eNQ932D7Nd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Clone the repo from githup and install the requirements"
      ],
      "metadata": {
        "id": "dIcu2tiXE0TW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAvCsS_XlAyJ",
        "outputId": "9c6a5d3e-2099-4db8-e23f-808fc9ef115d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ED-MTT'...\n",
            "remote: Enumerating objects: 63, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (46/46), done.\u001b[K\n",
            "remote: Total 63 (delta 24), reused 47 (delta 17), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (63/63), done.\n",
            "Collecting https://github.com/ufoym/imbalanced-dataset-sampler/archive/master.zip\n",
            "  Using cached https://github.com/ufoym/imbalanced-dataset-sampler/archive/master.zip\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.7/dist-packages (from torchsampler==0.1.1) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.7/dist-packages (from torchsampler==0.1.1) (0.11.1+cu111)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from torchsampler==0.1.1) (1.1.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3->torchsampler==0.1.1) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5->torchsampler==0.1.1) (1.19.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.5->torchsampler==0.1.1) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsampler==0.1.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->torchsampler==0.1.1) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->torchsampler==0.1.1) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/CopurOnur/ED-MTT.git\n",
        "!pip install https://github.com/ufoym/imbalanced-dataset-sampler/archive/master.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "%cd /content/ED-MTT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk89oGsclMNP",
        "outputId": "f138329c-a32c-439e-9c92-0a35cec15d45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ED-MTT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r code/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nm19C8Tklicd",
        "outputId": "39e0ad09-5197-49fb-ffb2-3a3ab055f020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.12.9-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[?25l\r\u001b[K     |▏                               | 10 kB 33.5 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 27.0 MB/s eta 0:00:01\r\u001b[K     |▋                               | 30 kB 18.8 MB/s eta 0:00:01\r\u001b[K     |▊                               | 40 kB 16.0 MB/s eta 0:00:01\r\u001b[K     |█                               | 51 kB 8.2 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 61 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 71 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 81 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 92 kB 10.1 MB/s eta 0:00:01\r\u001b[K     |██                              | 102 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 112 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 122 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 133 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 143 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 153 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███                             | 163 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 174 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 184 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 194 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 204 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████                            | 215 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 225 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 235 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 245 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 256 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████                           | 266 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 276 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 286 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 296 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 307 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████                          | 317 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 327 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 337 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 348 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 358 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 368 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████                         | 378 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 389 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 399 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 409 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 419 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████                        | 430 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 440 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 450 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 460 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 471 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 481 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 491 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 501 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 512 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 522 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 532 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 542 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 552 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 563 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 573 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 583 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 593 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 604 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 614 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 624 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 634 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 645 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 655 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 665 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 675 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 686 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 696 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 706 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 716 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 727 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 737 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 747 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 757 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 768 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 778 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 788 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 798 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 808 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 819 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 829 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 839 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 849 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 860 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 870 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 880 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 890 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 901 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 911 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 921 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 931 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 942 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 952 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 962 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 972 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 983 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 993 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 1.0 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.0 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 1.0 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.0 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.0 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.1 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.1 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.1 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.1 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.1 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.1 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.1 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.1 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.1 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.2 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.2 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.2 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.2 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.2 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.2 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.2 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.2 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.2 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.3 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.3 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.3 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.3 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.3 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.3 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.3 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.3 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.3 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.4 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.4 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.4 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.4 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.4 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.4 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.4 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.4 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.4 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.4 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.5 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.5 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.5 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.5 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.5 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.5 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.5 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 1.5 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 1.5 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.5 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.6 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.6 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.6 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.6 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.6 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.6 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.6 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.6 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.6 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.6 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.7 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.7 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.7 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.7 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.7 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.7 MB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.7 MB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy> in /usr/local/lib/python3.7/dist-packages (from -r code/requirements.txt (line 2)) (1.4.1)\n",
            "Collecting stumpy\n",
            "  Downloading stumpy-1.10.2-py3-none-any.whl (119 kB)\n",
            "\u001b[K     |████████████████████████████████| 119 kB 68.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r code/requirements.txt (line 4)) (1.10.0+cu111)\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-1.5.8-py3-none-any.whl (526 kB)\n",
            "\u001b[K     |████████████████████████████████| 526 kB 78.0 MB/s \n",
            "\u001b[?25hCollecting torchmetrics\n",
            "  Downloading torchmetrics-0.7.0-py3-none-any.whl (396 kB)\n",
            "\u001b[K     |████████████████████████████████| 396 kB 76.0 MB/s \n",
            "\u001b[?25hCollecting hydra-core\n",
            "  Downloading hydra_core-1.1.1-py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 84.7 MB/s \n",
            "\u001b[?25hCollecting hydra_colorlog\n",
            "  Downloading hydra_colorlog-1.1.0-py3-none-any.whl (3.6 kB)\n",
            "Collecting tsfresh\n",
            "  Downloading tsfresh-0.19.0-py2.py3-none-any.whl (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 9.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy>->-r code/requirements.txt (line 2)) (1.19.5)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r code/requirements.txt (line 1)) (1.15.0)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb->-r code/requirements.txt (line 1)) (2.8.2)\n",
            "Collecting yaspin>=1.0.0\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.2-py2.py3-none-any.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 72.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r code/requirements.txt (line 1)) (3.17.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r code/requirements.txt (line 1)) (5.4.8)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r code/requirements.txt (line 1)) (2.23.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.26-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 80.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r code/requirements.txt (line 1)) (7.1.2)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 9.6 MB/s \n",
            "\u001b[?25hCollecting configparser>=3.8.1\n",
            "  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb->-r code/requirements.txt (line 1)) (3.13)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r code/requirements.txt (line 1)) (2.3)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb->-r code/requirements.txt (line 1)) (3.10.0.2)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.0 MB/s \n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->-r code/requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->-r code/requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->-r code/requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb->-r code/requirements.txt (line 1)) (2021.10.8)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb->-r code/requirements.txt (line 1)) (1.1.0)\n",
            "Collecting scipy>\n",
            "  Downloading scipy-1.7.3-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (38.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.1 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numba>=0.48 in /usr/local/lib/python3.7/dist-packages (from stumpy->-r code/requirements.txt (line 3)) (0.51.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.48->stumpy->-r code/requirements.txt (line 3)) (57.4.0)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.48->stumpy->-r code/requirements.txt (line 3)) (0.34.0)\n",
            "Collecting pyDeprecate==0.3.1\n",
            "  Downloading pyDeprecate-0.3.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning->-r code/requirements.txt (line 5)) (2.7.0)\n",
            "Collecting future>=0.17.1\n",
            "  Downloading future-0.18.2.tar.gz (829 kB)\n",
            "\u001b[K     |████████████████████████████████| 829 kB 58.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning->-r code/requirements.txt (line 5)) (4.62.3)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-lightning->-r code/requirements.txt (line 5)) (21.3)\n",
            "Collecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "  Downloading fsspec-2022.1.0-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 60.8 MB/s \n",
            "\u001b[?25hCollecting PyYAML\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 64.4 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 67.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch-lightning->-r code/requirements.txt (line 5)) (3.0.6)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r code/requirements.txt (line 5)) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r code/requirements.txt (line 5)) (3.3.6)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r code/requirements.txt (line 5)) (1.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r code/requirements.txt (line 5)) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r code/requirements.txt (line 5)) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r code/requirements.txt (line 5)) (1.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r code/requirements.txt (line 5)) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r code/requirements.txt (line 5)) (0.12.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch-lightning->-r code/requirements.txt (line 5)) (0.6.1)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r code/requirements.txt (line 5)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r code/requirements.txt (line 5)) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r code/requirements.txt (line 5)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning->-r code/requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning->-r code/requirements.txt (line 5)) (4.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning->-r code/requirements.txt (line 5)) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning->-r code/requirements.txt (line 5)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning->-r code/requirements.txt (line 5)) (3.1.1)\n",
            "Collecting omegaconf==2.1.*\n",
            "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
            "\u001b[K     |████████████████████████████████| 74 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[K     |████████████████████████████████| 112 kB 83.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from hydra-core->-r code/requirements.txt (line 7)) (5.4.0)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from tsfresh->-r code/requirements.txt (line 9)) (1.3.0)\n",
            "Requirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from tsfresh->-r code/requirements.txt (line 9)) (1.1.5)\n",
            "Collecting distributed>=2.11.0\n",
            "  Downloading distributed-2022.1.0-py3-none-any.whl (822 kB)\n",
            "\u001b[K     |████████████████████████████████| 822 kB 67.5 MB/s \n",
            "\u001b[?25hCollecting matrixprofile<2.0.0,>=1.1.10\n",
            "  Downloading matrixprofile-1.1.10-cp37-cp37m-manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 69.9 MB/s \n",
            "\u001b[?25hCollecting statsmodels>=0.13\n",
            "  Downloading statsmodels-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.8 MB 47.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.7/dist-packages (from tsfresh->-r code/requirements.txt (line 9)) (1.0.2)\n",
            "Requirement already satisfied: dask[dataframe]>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tsfresh->-r code/requirements.txt (line 9)) (2.12.0)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tsfresh->-r code/requirements.txt (line 9)) (0.5.2)\n",
            "Collecting partd>=0.3.10\n",
            "  Downloading partd-1.2.0-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: toolz>=0.7.3 in /usr/local/lib/python3.7/dist-packages (from dask[dataframe]>=2.9.0->tsfresh->-r code/requirements.txt (line 9)) (0.11.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.11.0->tsfresh->-r code/requirements.txt (line 9)) (2.11.3)\n",
            "Collecting cloudpickle\n",
            "  Downloading cloudpickle-2.0.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.11.0->tsfresh->-r code/requirements.txt (line 9)) (2.0.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.11.0->tsfresh->-r code/requirements.txt (line 9)) (1.7.0)\n",
            "Collecting distributed>=2.11.0\n",
            "  Downloading distributed-2021.12.0-py3-none-any.whl (802 kB)\n",
            "\u001b[K     |████████████████████████████████| 802 kB 64.1 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.11.2-py3-none-any.whl (802 kB)\n",
            "\u001b[K     |████████████████████████████████| 802 kB 77.8 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.11.1-py3-none-any.whl (793 kB)\n",
            "\u001b[K     |████████████████████████████████| 793 kB 65.1 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.11.0-py3-none-any.whl (793 kB)\n",
            "\u001b[K     |████████████████████████████████| 793 kB 43.9 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.10.0-py3-none-any.whl (791 kB)\n",
            "\u001b[K     |████████████████████████████████| 791 kB 69.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.11.0->tsfresh->-r code/requirements.txt (line 9)) (1.0.3)\n",
            "Requirement already satisfied: tornado>=5 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.11.0->tsfresh->-r code/requirements.txt (line 9)) (5.1.1)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed>=2.11.0->tsfresh->-r code/requirements.txt (line 9)) (2.4.0)\n",
            "  Downloading distributed-2021.9.1-py3-none-any.whl (786 kB)\n",
            "\u001b[K     |████████████████████████████████| 786 kB 66.9 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.9.0-py3-none-any.whl (779 kB)\n",
            "\u001b[K     |████████████████████████████████| 779 kB 63.2 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.8.1-py3-none-any.whl (778 kB)\n",
            "\u001b[K     |████████████████████████████████| 778 kB 74.4 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.8.0-py3-none-any.whl (776 kB)\n",
            "\u001b[K     |████████████████████████████████| 776 kB 79.5 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.7.2-py3-none-any.whl (769 kB)\n",
            "\u001b[K     |████████████████████████████████| 769 kB 79.8 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.7.1-py3-none-any.whl (766 kB)\n",
            "\u001b[K     |████████████████████████████████| 766 kB 60.8 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.7.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 58.7 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.6.2-py3-none-any.whl (722 kB)\n",
            "\u001b[K     |████████████████████████████████| 722 kB 69.6 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.6.1-py3-none-any.whl (722 kB)\n",
            "\u001b[K     |████████████████████████████████| 722 kB 76.3 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.6.0-py3-none-any.whl (715 kB)\n",
            "\u001b[K     |████████████████████████████████| 715 kB 71.2 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.5.1-py3-none-any.whl (705 kB)\n",
            "\u001b[K     |████████████████████████████████| 705 kB 37.3 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.5.0-py3-none-any.whl (699 kB)\n",
            "\u001b[K     |████████████████████████████████| 699 kB 80.4 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.4.1-py3-none-any.whl (696 kB)\n",
            "\u001b[K     |████████████████████████████████| 696 kB 86.5 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.4.0-py3-none-any.whl (684 kB)\n",
            "\u001b[K     |████████████████████████████████| 684 kB 73.9 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.3.1-py3-none-any.whl (679 kB)\n",
            "\u001b[K     |████████████████████████████████| 679 kB 77.3 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.3.0-py3-none-any.whl (675 kB)\n",
            "\u001b[K     |████████████████████████████████| 675 kB 76.1 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.2.0-py3-none-any.whl (675 kB)\n",
            "\u001b[K     |████████████████████████████████| 675 kB 82.2 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.1.1-py3-none-any.whl (672 kB)\n",
            "\u001b[K     |████████████████████████████████| 672 kB 61.7 MB/s \n",
            "\u001b[?25h  Downloading distributed-2021.1.0-py3-none-any.whl (671 kB)\n",
            "\u001b[K     |████████████████████████████████| 671 kB 77.7 MB/s \n",
            "\u001b[?25h  Downloading distributed-2020.12.0-py3-none-any.whl (669 kB)\n",
            "\u001b[K     |████████████████████████████████| 669 kB 74.8 MB/s \n",
            "\u001b[?25h  Downloading distributed-2.30.1-py3-none-any.whl (656 kB)\n",
            "\u001b[K     |████████████████████████████████| 656 kB 80.0 MB/s \n",
            "\u001b[?25hINFO: pip is looking at multiple versions of cloudpickle to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting cloudpickle\n",
            "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
            "  Downloading cloudpickle-1.5.0-py3-none-any.whl (22 kB)\n",
            "INFO: pip is looking at multiple versions of distributed to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting distributed>=2.11.0\n",
            "  Downloading distributed-2.30.0-py3-none-any.whl (656 kB)\n",
            "\u001b[K     |████████████████████████████████| 656 kB 71.4 MB/s \n",
            "\u001b[?25h  Downloading distributed-2.29.0-py3-none-any.whl (653 kB)\n",
            "\u001b[K     |████████████████████████████████| 653 kB 72.1 MB/s \n",
            "\u001b[?25hINFO: pip is looking at multiple versions of cloudpickle to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading distributed-2.28.0-py3-none-any.whl (652 kB)\n",
            "\u001b[K     |████████████████████████████████| 652 kB 72.4 MB/s \n",
            "\u001b[?25h  Downloading distributed-2.27.0-py3-none-any.whl (652 kB)\n",
            "\u001b[K     |████████████████████████████████| 652 kB 67.5 MB/s \n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "  Downloading distributed-2.26.0-py3-none-any.whl (652 kB)\n",
            "\u001b[K     |████████████████████████████████| 652 kB 78.1 MB/s \n",
            "\u001b[?25h  Downloading distributed-2.25.0-py3-none-any.whl (652 kB)\n",
            "\u001b[K     |████████████████████████████████| 652 kB 78.2 MB/s \n",
            "\u001b[?25h  Downloading distributed-2.24.0-py3-none-any.whl (651 kB)\n",
            "\u001b[K     |████████████████████████████████| 651 kB 74.5 MB/s \n",
            "\u001b[?25hINFO: pip is looking at multiple versions of distributed to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading distributed-2.23.0-py3-none-any.whl (650 kB)\n",
            "\u001b[K     |████████████████████████████████| 650 kB 75.0 MB/s \n",
            "\u001b[?25h  Downloading distributed-2.22.0-py3-none-any.whl (647 kB)\n",
            "\u001b[K     |████████████████████████████████| 647 kB 39.7 MB/s \n",
            "\u001b[?25h  Downloading distributed-2.21.0-py3-none-any.whl (646 kB)\n",
            "\u001b[K     |████████████████████████████████| 646 kB 58.3 MB/s \n",
            "\u001b[?25h  Downloading distributed-2.20.0-py3-none-any.whl (644 kB)\n",
            "\u001b[K     |████████████████████████████████| 644 kB 64.5 MB/s \n",
            "\u001b[?25hCollecting cloudpickle\n",
            "  Downloading cloudpickle-1.4.1-py3-none-any.whl (26 kB)\n",
            "  Downloading cloudpickle-1.4.0-py3-none-any.whl (25 kB)\n",
            "  Downloading cloudpickle-1.3.0-py2.py3-none-any.whl (26 kB)\n",
            "Collecting distributed>=2.11.0\n",
            "  Downloading distributed-2.19.0-py3-none-any.whl (643 kB)\n",
            "\u001b[K     |████████████████████████████████| 643 kB 75.9 MB/s \n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "  Downloading distributed-2.18.0-py3-none-any.whl (640 kB)\n",
            "\u001b[K     |████████████████████████████████| 640 kB 78.6 MB/s \n",
            "\u001b[?25h  Downloading distributed-2.17.0-py3-none-any.whl (638 kB)\n",
            "\u001b[K     |████████████████████████████████| 638 kB 55.6 MB/s \n",
            "\u001b[?25h  Downloading distributed-2.16.0-py3-none-any.whl (629 kB)\n",
            "\u001b[K     |████████████████████████████████| 629 kB 76.4 MB/s \n",
            "\u001b[?25hCollecting cloudpickle\n",
            "  Downloading cloudpickle-1.2.2-py2.py3-none-any.whl (25 kB)\n",
            "  Downloading cloudpickle-1.2.1-py2.py3-none-any.whl (25 kB)\n",
            "  Downloading cloudpickle-1.2.0-py2.py3-none-any.whl (24 kB)\n",
            "  Downloading cloudpickle-1.1.1-py2.py3-none-any.whl (17 kB)\n",
            "  Downloading cloudpickle-1.0.0-py2.py3-none-any.whl (16 kB)\n",
            "  Downloading cloudpickle-0.8.1-py2.py3-none-any.whl (16 kB)\n",
            "  Downloading cloudpickle-0.8.0-py2.py3-none-any.whl (16 kB)\n",
            "  Downloading cloudpickle-0.7.0-py2.py3-none-any.whl (16 kB)\n",
            "  Downloading cloudpickle-0.6.1-py2.py3-none-any.whl (14 kB)\n",
            "  Downloading cloudpickle-0.6.0-py2.py3-none-any.whl (16 kB)\n",
            "  Downloading cloudpickle-0.5.6-py2.py3-none-any.whl (16 kB)\n",
            "  Downloading cloudpickle-0.5.5-py2.py3-none-any.whl (14 kB)\n",
            "  Downloading cloudpickle-0.5.4-py2.py3-none-any.whl (14 kB)\n",
            "  Downloading cloudpickle-0.5.3-py2.py3-none-any.whl (13 kB)\n",
            "  Downloading cloudpickle-0.5.2-py2.py3-none-any.whl (16 kB)\n",
            "  Downloading cloudpickle-0.5.1-py2.py3-none-any.whl (16 kB)\n",
            "  Downloading cloudpickle-0.5.0-py2.py3-none-any.whl (16 kB)\n",
            "  Downloading cloudpickle-0.4.4-py2.py3-none-any.whl (13 kB)\n",
            "  Downloading cloudpickle-0.4.3-py2.py3-none-any.whl (15 kB)\n",
            "  Downloading cloudpickle-0.4.2-py2.py3-none-any.whl (15 kB)\n",
            "  Downloading cloudpickle-0.4.1-py2.py3-none-any.whl (15 kB)\n",
            "  Downloading cloudpickle-0.4.0-py2.py3-none-any.whl (15 kB)\n",
            "  Downloading cloudpickle-0.3.1-py2.py3-none-any.whl (14 kB)\n",
            "  Downloading cloudpickle-0.3.0-py2.py3-none-any.whl (14 kB)\n",
            "  Downloading cloudpickle-0.2.2-py2.py3-none-any.whl (13 kB)\n",
            "Collecting distributed>=2.11.0\n",
            "  Downloading distributed-2.15.2-py3-none-any.whl (625 kB)\n",
            "\u001b[K     |████████████████████████████████| 625 kB 75.7 MB/s \n",
            "\u001b[?25h  Downloading distributed-2.15.1-py3-none-any.whl (624 kB)\n",
            "\u001b[K     |████████████████████████████████| 624 kB 74.9 MB/s \n",
            "\u001b[?25h  Downloading distributed-2.15.0-py3-none-any.whl (624 kB)\n",
            "\u001b[K     |████████████████████████████████| 624 kB 72.1 MB/s \n",
            "\u001b[?25h  Downloading distributed-2.14.0-py3-none-any.whl (609 kB)\n",
            "\u001b[K     |████████████████████████████████| 609 kB 72.7 MB/s \n",
            "\u001b[?25h  Downloading distributed-2.13.0-py3-none-any.whl (603 kB)\n",
            "\u001b[K     |████████████████████████████████| 603 kB 65.2 MB/s \n",
            "\u001b[?25h  Downloading distributed-2.12.0-py3-none-any.whl (601 kB)\n",
            "\u001b[K     |████████████████████████████████| 601 kB 69.6 MB/s \n",
            "\u001b[?25h  Downloading distributed-2.11.0-py3-none-any.whl (595 kB)\n",
            "\u001b[K     |████████████████████████████████| 595 kB 70.0 MB/s \n",
            "\u001b[?25hINFO: pip is looking at multiple versions of dask to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of dask[dataframe] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting dask[dataframe]>=2.9.0\n",
            "  Downloading dask-2022.1.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 60.4 MB/s \n",
            "\u001b[?25h  Downloading dask-2021.12.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 62.9 MB/s \n",
            "\u001b[?25h  Downloading dask-2021.11.2-py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 67.0 MB/s \n",
            "\u001b[?25h  Downloading dask-2021.11.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 59.8 MB/s \n",
            "\u001b[?25h  Downloading dask-2021.11.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 61.0 MB/s \n",
            "\u001b[?25h  Downloading dask-2021.10.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 66.9 MB/s \n",
            "\u001b[?25h  Downloading dask-2021.9.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 65.2 MB/s \n",
            "\u001b[?25hINFO: pip is looking at multiple versions of dask to determine which version is compatible with other requirements. This could take a while.\n",
            "INFO: pip is looking at multiple versions of dask[dataframe] to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading dask-2021.9.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 64.5 MB/s \n",
            "\u001b[?25h  Downloading dask-2021.8.1-py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 67.7 MB/s \n",
            "\u001b[?25h  Downloading dask-2021.8.0-py3-none-any.whl (995 kB)\n",
            "\u001b[K     |████████████████████████████████| 995 kB 60.5 MB/s \n",
            "\u001b[?25h  Downloading dask-2021.7.2-py3-none-any.whl (987 kB)\n",
            "\u001b[K     |████████████████████████████████| 987 kB 66.6 MB/s \n",
            "\u001b[?25h  Downloading dask-2021.7.1-py3-none-any.whl (984 kB)\n",
            "\u001b[K     |████████████████████████████████| 984 kB 68.4 MB/s \n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. If you want to abort this run, you can press Ctrl + C to do so. To improve how pip performs, tell us what happened here: https://pip.pypa.io/surveys/backtracking\n",
            "  Downloading dask-2021.7.0-py3-none-any.whl (977 kB)\n",
            "\u001b[K     |████████████████████████████████| 977 kB 67.0 MB/s \n",
            "\u001b[?25h  Downloading dask-2021.6.2-py3-none-any.whl (973 kB)\n",
            "\u001b[K     |████████████████████████████████| 973 kB 68.6 MB/s \n",
            "\u001b[?25h  Downloading dask-2021.6.1-py3-none-any.whl (973 kB)\n",
            "\u001b[K     |████████████████████████████████| 973 kB 61.8 MB/s \n",
            "\u001b[?25h  Downloading dask-2021.6.0-py3-none-any.whl (965 kB)\n",
            "\u001b[K     |████████████████████████████████| 965 kB 59.3 MB/s \n",
            "\u001b[?25h  Downloading dask-2021.5.1-py3-none-any.whl (964 kB)\n",
            "\u001b[K     |████████████████████████████████| 964 kB 63.9 MB/s \n",
            "\u001b[?25h  Downloading dask-2021.5.0-py3-none-any.whl (960 kB)\n",
            "\u001b[K     |████████████████████████████████| 960 kB 65.5 MB/s \n",
            "\u001b[?25h  Downloading dask-2021.4.1-py3-none-any.whl (952 kB)\n",
            "\u001b[K     |████████████████████████████████| 952 kB 62.2 MB/s \n",
            "\u001b[?25h  Downloading dask-2021.4.0-py3-none-any.whl (941 kB)\n",
            "\u001b[K     |████████████████████████████████| 941 kB 67.2 MB/s \n",
            "\u001b[?25h  Downloading dask-2021.3.1-py3-none-any.whl (935 kB)\n",
            "\u001b[K     |████████████████████████████████| 935 kB 67.7 MB/s \n",
            "\u001b[?25h  Downloading dask-2021.3.0-py3-none-any.whl (925 kB)\n",
            "\u001b[K     |████████████████████████████████| 925 kB 64.9 MB/s \n",
            "\u001b[?25h  Downloading dask-2021.2.0-py3-none-any.whl (900 kB)\n",
            "\u001b[K     |████████████████████████████████| 900 kB 67.4 MB/s \n",
            "\u001b[?25h  Downloading dask-2021.1.1-py3-none-any.whl (891 kB)\n",
            "\u001b[K     |████████████████████████████████| 891 kB 56.2 MB/s \n",
            "\u001b[?25h  Downloading dask-2021.1.0-py3-none-any.whl (889 kB)\n",
            "\u001b[K     |████████████████████████████████| 889 kB 70.4 MB/s \n",
            "\u001b[?25h  Downloading dask-2020.12.0-py3-none-any.whl (884 kB)\n",
            "\u001b[K     |████████████████████████████████| 884 kB 74.1 MB/s \n",
            "\u001b[?25h  Downloading dask-2.30.0-py3-none-any.whl (848 kB)\n",
            "\u001b[K     |████████████████████████████████| 848 kB 67.7 MB/s \n",
            "\u001b[?25h  Downloading dask-2.29.0-py3-none-any.whl (847 kB)\n",
            "\u001b[K     |████████████████████████████████| 847 kB 53.2 MB/s \n",
            "\u001b[?25h  Downloading dask-2.28.0-py3-none-any.whl (848 kB)\n",
            "\u001b[K     |████████████████████████████████| 848 kB 68.3 MB/s \n",
            "\u001b[?25h  Downloading dask-2.27.0-py3-none-any.whl (843 kB)\n",
            "\u001b[K     |████████████████████████████████| 843 kB 72.8 MB/s \n",
            "\u001b[?25h  Downloading dask-2.26.0-py3-none-any.whl (843 kB)\n",
            "\u001b[K     |████████████████████████████████| 843 kB 29.4 MB/s \n",
            "\u001b[?25h  Downloading dask-2.25.0-py3-none-any.whl (834 kB)\n",
            "\u001b[K     |████████████████████████████████| 834 kB 73.4 MB/s \n",
            "\u001b[?25h  Downloading dask-2.24.0-py3-none-any.whl (834 kB)\n",
            "\u001b[K     |████████████████████████████████| 834 kB 73.8 MB/s \n",
            "\u001b[?25h  Downloading dask-2.23.0-py3-none-any.whl (831 kB)\n",
            "\u001b[K     |████████████████████████████████| 831 kB 62.0 MB/s \n",
            "\u001b[?25h  Downloading dask-2.22.0-py3-none-any.whl (828 kB)\n",
            "\u001b[K     |████████████████████████████████| 828 kB 72.6 MB/s \n",
            "\u001b[?25h  Downloading dask-2.21.0-py3-none-any.whl (826 kB)\n",
            "\u001b[K     |████████████████████████████████| 826 kB 69.5 MB/s \n",
            "\u001b[?25h  Downloading dask-2.20.0-py3-none-any.whl (826 kB)\n",
            "\u001b[K     |████████████████████████████████| 826 kB 74.9 MB/s \n",
            "\u001b[?25h  Downloading dask-2.19.0-py3-none-any.whl (824 kB)\n",
            "\u001b[K     |████████████████████████████████| 824 kB 67.6 MB/s \n",
            "\u001b[?25h  Downloading dask-2.18.1-py3-none-any.whl (823 kB)\n",
            "\u001b[K     |████████████████████████████████| 823 kB 76.4 MB/s \n",
            "\u001b[?25h  Downloading dask-2.18.0-py3-none-any.whl (822 kB)\n",
            "\u001b[K     |████████████████████████████████| 822 kB 74.0 MB/s \n",
            "\u001b[?25h  Downloading dask-2.17.2-py3-none-any.whl (813 kB)\n",
            "\u001b[K     |████████████████████████████████| 813 kB 58.3 MB/s \n",
            "\u001b[?25h  Downloading dask-2.17.1-py3-none-any.whl (813 kB)\n",
            "\u001b[K     |████████████████████████████████| 813 kB 71.3 MB/s \n",
            "\u001b[?25h  Downloading dask-2.17.0-py3-none-any.whl (812 kB)\n",
            "\u001b[K     |████████████████████████████████| 812 kB 70.9 MB/s \n",
            "\u001b[?25h  Downloading dask-2.16.0-py3-none-any.whl (802 kB)\n",
            "\u001b[K     |████████████████████████████████| 802 kB 75.2 MB/s \n",
            "\u001b[?25h  Downloading dask-2.15.0-py3-none-any.whl (799 kB)\n",
            "\u001b[K     |████████████████████████████████| 799 kB 77.5 MB/s \n",
            "\u001b[?25h  Downloading dask-2.14.0-py3-none-any.whl (794 kB)\n",
            "\u001b[K     |████████████████████████████████| 794 kB 63.2 MB/s \n",
            "\u001b[?25h  Downloading dask-2.13.0-py3-none-any.whl (791 kB)\n",
            "\u001b[K     |████████████████████████████████| 791 kB 75.1 MB/s \n",
            "\u001b[?25h  Downloading dask-2.12.0-py3-none-any.whl (789 kB)\n",
            "\u001b[K     |████████████████████████████████| 789 kB 27.2 MB/s \n",
            "\u001b[?25h  Downloading dask-2.11.0-py3-none-any.whl (785 kB)\n",
            "\u001b[K     |████████████████████████████████| 785 kB 66.9 MB/s \n",
            "\u001b[?25h  Downloading dask-2.10.1-py3-none-any.whl (783 kB)\n",
            "\u001b[K     |████████████████████████████████| 783 kB 67.6 MB/s \n",
            "\u001b[?25h  Downloading dask-2.10.0-py3-none-any.whl (783 kB)\n",
            "\u001b[K     |████████████████████████████████| 783 kB 78.0 MB/s \n",
            "\u001b[?25h  Downloading dask-2.9.2-py3-none-any.whl (780 kB)\n",
            "\u001b[K     |████████████████████████████████| 780 kB 68.8 MB/s \n",
            "\u001b[?25h  Downloading dask-2.9.1-py3-none-any.whl (772 kB)\n",
            "\u001b[K     |████████████████████████████████| 772 kB 65.6 MB/s \n",
            "\u001b[?25h  Downloading dask-2.9.0-py3-none-any.whl (770 kB)\n",
            "\u001b[K     |████████████████████████████████| 770 kB 70.2 MB/s \n",
            "\u001b[?25hINFO: pip is looking at multiple versions of tsfresh to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tsfresh\n",
            "  Downloading tsfresh-0.18.0-py2.py3-none-any.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.7/dist-packages (from tsfresh->-r code/requirements.txt (line 9)) (0.10.2)\n",
            "  Downloading tsfresh-0.17.0-py2.py3-none-any.whl (91 kB)\n",
            "\u001b[K     |████████████████████████████████| 91 kB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->tsfresh->-r code/requirements.txt (line 9)) (2018.9)\n",
            "Collecting locket\n",
            "  Downloading locket-0.2.1-py2.py3-none-any.whl (4.1 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.0->tsfresh->-r code/requirements.txt (line 9)) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.22.0->tsfresh->-r code/requirements.txt (line 9)) (3.0.0)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed>=2.11.0->tsfresh->-r code/requirements.txt (line 9)) (1.0.1)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 56.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r code/requirements.txt (line 5)) (21.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning->-r code/requirements.txt (line 5)) (2.0.10)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 69.3 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-5.2.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (160 kB)\n",
            "\u001b[K     |████████████████████████████████| 160 kB 64.7 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: subprocess32, future, antlr4-python3-runtime, pathtools\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=d70a282833b16b3683a0f6db9d7edb33db099a68d1275077de32e47dbefd8eff\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=9a2103413ff97eb61c4e596099ed8c724a3ebef3b273d3c31805ffd37e9be5a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=296a0f953d9211a2ecca029c3b9bf2fa765c4451ce5fbb8f30c27905bbea6ee0\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=6836520f5df816515544a5e91876b29b4177169db8aeb9e1efaa2aee11111ba1\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built subprocess32 future antlr4-python3-runtime pathtools\n",
            "Installing collected packages: multidict, frozenlist, yarl, smmap, PyYAML, locket, asynctest, async-timeout, antlr4-python3-runtime, aiosignal, scipy, pyDeprecate, partd, omegaconf, gitdb, fsspec, cloudpickle, aiohttp, yaspin, torchmetrics, subprocess32, shortuuid, sentry-sdk, pathtools, hydra-core, GitPython, future, docker-pycreds, distributed, configparser, colorlog, wandb, tsfresh, stumpy, pytorch-lightning, hydra-colorlog\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Attempting uninstall: future\n",
            "    Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Attempting uninstall: distributed\n",
            "    Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gym 0.17.3 requires cloudpickle<1.7.0,>=1.2.0, but you have cloudpickle 2.0.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed GitPython-3.1.26 PyYAML-6.0 aiohttp-3.8.1 aiosignal-1.2.0 antlr4-python3-runtime-4.8 async-timeout-4.0.2 asynctest-0.13.0 cloudpickle-2.0.0 colorlog-6.6.0 configparser-5.2.0 distributed-2.30.1 docker-pycreds-0.4.0 frozenlist-1.2.0 fsspec-2022.1.0 future-0.18.2 gitdb-4.0.9 hydra-colorlog-1.1.0 hydra-core-1.1.1 locket-0.2.1 multidict-5.2.0 omegaconf-2.1.1 partd-1.2.0 pathtools-0.1.2 pyDeprecate-0.3.1 pytorch-lightning-1.5.8 scipy-1.7.3 sentry-sdk-1.5.2 shortuuid-1.0.8 smmap-5.0.0 stumpy-1.10.2 subprocess32-3.5.4 torchmetrics-0.7.0 tsfresh-0.17.0 wandb-0.12.9 yarl-1.7.2 yaspin-2.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Data\n",
        "\n",
        "In order to laod the training data, you need to download the pre-extracted openface features from the drive link bellow, unzip the files and fix the paths by executing fix_path.py."
      ],
      "metadata": {
        "id": "j4FX2jXw0uRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/ED-MTT"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3NUiB5q6y_m",
        "outputId": "819f3818-9376-4233-8086-67b0a56253a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ED-MTT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "fileid=\"1EvaWCmIABOg7iHRE5rc8ZPsGGUXPBaap\"\n",
        "url = 'https://drive.google.com/uc?id={}'.format(fileid)\n",
        "output = 'OpenFace_Features.zip'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "A8xwjvSr41TR",
        "outputId": "893bc76d-a6a6-4c95-af19-1acbaf136503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1EvaWCmIABOg7iHRE5rc8ZPsGGUXPBaap\n",
            "To: /content/ED-MTT/OpenFace_Features.zip\n",
            "100%|██████████| 3.87G/3.87G [00:59<00:00, 64.5MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'OpenFace_Features.zip'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/ED-MTT/OpenFace_Features.zip -d /content/ED-MTT/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-hH2eIT66jD",
        "outputId": "c3e68ac9-231c-4ba9-df83-dd7ccc026e32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/ED-MTT/OpenFace_Features.zip\n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_26_Vid_1.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_26_Vid_2.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_26_Vid_3.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_26_Vid_4.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_26_Vid_5.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_26_Vid_5_1.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_26_Vid_5_2.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_26_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_27_Vid_1.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_29_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_29_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_30_Vid_1.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_30_Vid_2.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_30_Vid_3.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_30_Vid_4.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_30_Vid_5.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_32_Vid_1.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_32_Vid_2.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_32_Vid_3.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_32_Vid_4.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_32_Vid_5.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_32_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_32_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_33_Vid_1.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_33_Vid_2.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_33_Vid_3.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_33_Vid_4.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_33_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_34_Vid_1.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_34_Vid_2.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_34_Vid_3.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_34_Vid_4.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_34_Vid_5.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_34_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_35_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_35_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_36_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_37_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_38_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_39_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_39_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_40_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_40_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_41_Vid_2.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_41_Vid_3.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_41_Vid_4.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_41_Vid_5.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_41_Vid_5_1.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_41_Vid_5_2.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_41_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_41_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_42_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_43_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_44_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_45_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_46_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_47_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_48_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_48_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_49_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_50_Vid_1.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_50_Vid_2.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_50_Vid_3.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_50_Vid_4.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_50_Vid_5.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_50_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_51_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_52_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_53_Vid_2.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_53_Vid_3.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_53_Vid_4.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_53_Vid_5.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_54_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_55_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_56_Vid_1.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_56_Vid_2.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_56_Vid_3.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_56_Vid_4.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_56_Vid_5.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_56_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_57_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_58_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_58_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_59_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_60_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_60_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_62_Vid_1.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_62_Vid_2.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_62_Vid_3.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_62_Vid_4.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_62_Vid_5.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_62_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_62_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_63_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_64_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_64_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_65_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_66_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_66_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_67_Vid_1.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_67_Vid_2.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_67_Vid_4.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_67_Vid_5.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_67_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_68_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_68_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_69_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_69_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_70_Vid_1.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_70_Vid_2.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_70_Vid_3.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_70_Vid_4.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_70_Vid_5.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_70_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_72_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_73_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_73_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_74_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_75_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_76_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_76_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_77_Vid_1.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_77_Vid_2.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_77_Vid_3.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_77_Vid_4.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_77_Vid_5.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_77_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_77_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_78_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_79_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_80_Vid_1.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_80_Vid_2.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_80_Vid_3.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_80_Vid_4.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_80_Vid_5.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_80_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_81_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_82_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_83_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_84_Vid_1.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_84_Vid_2.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_84_Vid_3.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_84_Vid_4.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_84_Vid_5.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_84_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_85_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_86_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/train/subject_87_Vid_3.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_1_Vid_1.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_1_Vid_2.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_1_Vid_3.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_1_Vid_4.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_1_Vid_5.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_2_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_3_Vid_1.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_3_Vid_2.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_3_Vid_3.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_3_Vid_4.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_3_Vid_5.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_3_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_3_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_4_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_5_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_6_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_7_Vid_1.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_7_Vid_2.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_7_Vid_3.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_7_Vid_4.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_7_Vid_5.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_8_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_9_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_10_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_11_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_12_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_13_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_14_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_15_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_16_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_17_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_18_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_19_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_20_Vid_1.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_20_Vid_2.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_20_Vid_3.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_20_Vid_4.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_20_Vid_5.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_20_Vid_5_1.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_20_Vid_5_2.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_20_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_20_Vid_7.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_21_Vid_5.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_22_Vid_5.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_23_Vid_5.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_24_Vid_5.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_25_Vid_5.mat  \n",
            " extracting: /content/ED-MTT/data/LBPTOP_Full_Video/validation/subject_31_Vid_6.mat  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_26_Vid_1.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_26_Vid_2.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_26_Vid_3.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_26_Vid_4.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_26_Vid_5.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_26_Vid_5_1.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_26_Vid_5_2.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_26_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_27_Vid_1.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_29_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_29_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_30_Vid_1.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_30_Vid_2.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_30_Vid_3  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_30_Vid_4.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_30_Vid_5.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_32_Vid_1.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_32_Vid_2.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_32_Vid_3.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_32_Vid_4.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_32_Vid_5.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_32_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_32_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_33_Vid_1.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_33_Vid_2.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_33_Vid_3.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_33_Vid_4  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_33_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_34_Vid_1.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_34_Vid_2.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_34_Vid_3.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_34_Vid_4.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_34_Vid_5.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_34_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_35_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_35_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_36_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_37_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_38_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_39_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_39_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_40_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_40_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_41_Vid_2.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_41_Vid_3.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_41_Vid_4  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_41_Vid_5  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_41_Vid_5_1.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_41_Vid_5_2.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_41_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_41_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_42_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_43_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_44_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_45_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_46_Vid_6  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_47_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_48_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_48_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_49_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_50_Vid_1.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_50_Vid_2.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_50_Vid_3.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_50_Vid_4.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_50_Vid_5.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_50_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_51_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_52_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_53_Vid_2.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_53_Vid_3.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_53_Vid_4.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_53_Vid_5.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_54_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_55_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_56_Vid_1  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_56_Vid_2  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_56_Vid_3  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_56_Vid_4.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_56_Vid_5.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_56_Vid_6  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_57_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_58_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_58_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_59_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_60_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_60_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_62_Vid_1  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_62_Vid_2.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_62_Vid_3.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_62_Vid_4.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_62_Vid_5.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_62_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_62_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_63_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_64_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_64_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_65_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_66_Vid_6  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_66_Vid_7  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_67_Vid_1.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_67_Vid_2.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_67_Vid_4.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_67_Vid_5.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_67_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_68_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_68_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_69_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_69_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_70_Vid_1.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_70_Vid_2.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_70_Vid_3.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_70_Vid_4.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_70_Vid_5.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_70_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_72_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_73_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_73_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_74_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_75_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_76_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_76_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_77_Vid_1.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_77_Vid_2.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_77_Vid_3.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_77_Vid_4.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_77_Vid_5.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_77_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_77_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_78_Vid_6  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_79_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_80_Vid_1.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_80_Vid_2.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_80_Vid_3.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_80_Vid_4  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_80_Vid_5.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_80_Vid_6  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_81_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_82_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_83_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_84_Vid_1.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_84_Vid_2.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_84_Vid_3.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_84_Vid_4  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_84_Vid_5.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_84_Vid_6  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_85_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_86_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/Train/subject_87_Vid_3.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_1_Vid_1.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_1_Vid_2.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_1_Vid_3.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_1_Vid_4.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_1_Vid_5.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_2_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_3_Vid_1.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_3_Vid_2.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_3_Vid_3.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_3_Vid_4.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_3_Vid_5.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_3_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_3_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_4_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_5_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_6_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_7_Vid_1.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_7_Vid_2.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_7_Vid_3.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_7_Vid_4.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_7_Vid_5.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_8_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_9_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_10_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_11_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_12_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_13_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_14_Vid_6  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_15_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_16_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_17_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_18_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_19_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_20_Vid_1.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_20_Vid_2.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_20_Vid_3.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_20_Vid_4  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_20_Vid_5  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_20_Vid_5_1.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_20_Vid_5_2.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_20_Vid_6.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_20_Vid_7.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_21_Vid_5.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_22_Vid_5.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_23_Vid_5.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_24_Vid_5.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_25_Vid_5.txt  \n",
            " extracting: /content/ED-MTT/data/OpenFace_features/validation/subject_31_Vid_6.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python code/fix_path.py"
      ],
      "metadata": {
        "id": "evlvppey7x7q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training\n",
        "To start traning and reproducing the experiments, first you need to login to your wandb account and run the train.py script. If you want to change the hyperparameter settings, you can modify batchnorm_default.yaml file."
      ],
      "metadata": {
        "id": "KliRrmF3F7C3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "MhX3-GO99m5J",
        "outputId": "2c16b8a3-f410-48d9-addd-64963d93c0e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python code/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVjFlzP_9uW5",
        "outputId": "958c910a-cd55-4363-96b3-d3830f43bdd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33monurcopur\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "/usr/local/lib/python3.7/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'batchnorm_default': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/hydra/_internal/defaults_list.py:412: UserWarning: In batchnorm_default: Invalid overriding of hydra/job_logging:\n",
            "Default list overrides requires 'override' keyword.\n",
            "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/defaults_list_override for more information.\n",
            "\n",
            "  deprecation_warning(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/hydra/_internal/defaults_list.py:412: UserWarning: In batchnorm_default: Invalid overriding of hydra/hydra_logging:\n",
            "Default list overrides requires 'override' keyword.\n",
            "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/defaults_list_override for more information.\n",
            "\n",
            "  deprecation_warning(msg)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.12.9\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdecent-water-106\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/onurcopur/Engagement%20Detection\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/onurcopur/Engagement%20Detection/runs/1i19dcz5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in /content/ED-MTT/outputs/2022-01-18/15-08-30/wandb/run-20220118_150830-1i19dcz5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb offline` to turn off syncing.\n",
            "\n",
            "[\u001b[36m2022-01-18 15:08:35,049\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - data:\n",
            "  root: /content/ED-MTT/data/OpenFace_features/\n",
            "  l_dir: /content/ED-MTT/Engagement_Labels.xlsx\n",
            "  level:\n",
            "  - 0.0\n",
            "  - 0.33\n",
            "  - 0.66\n",
            "  - 1.0\n",
            "  frame_size: 100\n",
            "  step_size: 1.2\n",
            "  gaze_range:\n",
            "  - 4\n",
            "  - 10\n",
            "  head_range:\n",
            "  - 10\n",
            "  - 13\n",
            "  rot_range:\n",
            "  - 13\n",
            "  - 16\n",
            "  aus_range:\n",
            "  - -35\n",
            "  - -18\n",
            "  attributes:\n",
            "  - gaze_seg\n",
            "  - head_seg\n",
            "  - aus_seg\n",
            "  functions:\n",
            "  - length\n",
            "  - maximum\n",
            "  - minimum\n",
            "  - variance\n",
            "  cols:\n",
            "  - gaze_cols\n",
            "  - head_cols\n",
            "  - aus_cols\n",
            "  batch_size: 16\n",
            "model:\n",
            "  lstm:\n",
            "    n_hidden: 1024\n",
            "    n_layers: 2\n",
            "  mlp:\n",
            "    h1: 64\n",
            "    h2: 32\n",
            "    out: 2\n",
            "  train:\n",
            "    dropout: 0\n",
            "    n_epochs: 450\n",
            "    lr: 5.0e-05\n",
            "    triplet_margin: 1\n",
            "    threshold: 2.5\n",
            "  seed: 214\n",
            "\u001b[0m\n",
            "Global seed set to 214\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:474: DtypeWarning: Columns (10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:474: DtypeWarning: Columns (4,5,6,7,8,9) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:474: DtypeWarning: Columns (4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  fn(*args, **kwargs)\n",
            "Global seed set to 214\n",
            "Global seed set to 214\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/callback_connector.py:91: LightningDeprecationWarning: Setting `Trainer(progress_bar_refresh_rate=30)` is deprecated in v1.5 and will be removed in v1.7. Please pass `pytorch_lightning.callbacks.progress.TQDMProgressBar` with `refresh_rate` directly to the Trainer's `callbacks` argument instead. Or, to disable the progress bar pass `enable_progress_bar = False` to the Trainer.\n",
            "  f\"Setting `Trainer(progress_bar_refresh_rate={progress_bar_refresh_rate})` is deprecated in v1.5 and\"\n",
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:470: LightningDeprecationWarning: DataModule.setup has already been called, so it will not be called again. In v1.6 this behavior will change to always call DataModule.setup.\n",
            "  f\"DataModule.{name} has already been called, so it will not be called again. \"\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loggers/wandb.py:342: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
            "  \"There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse\"\n",
            "\n",
            "  | Name              | Type                          | Params\n",
            "--------------------------------------------------------------------\n",
            "0 | model             | SequenceModel                 | 34.6 M\n",
            "1 | criterion_reg     | MSELoss                       | 0     \n",
            "2 | criterion_triplet | TripletMarginWithDistanceLoss | 0     \n",
            "3 | batch_norm        | BatchNorm1d                   | 208   \n",
            "--------------------------------------------------------------------\n",
            "34.6 M    Trainable params\n",
            "0         Non-trainable params\n",
            "34.6 M    Total params\n",
            "138.291   Total estimated model params size (MB)\n",
            "Validation sanity check:   0% 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([1, 1])) that is different to the input size (torch.Size([1, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Global seed set to 214\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py:429: UserWarning: The number of training samples (10) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
            "  f\"The number of training samples ({self.num_training_batches}) is smaller than the logging interval\"\n",
            "Epoch 0:   0% 0/58 [00:00<?, ?it/s] /usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([16, 1])) that is different to the input size (torch.Size([16, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py:520: UserWarning: Using a target size (torch.Size([3, 1])) that is different to the input size (torch.Size([3, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "  return F.mse_loss(input, target, reduction=self.reduction)\n",
            "Epoch 0:  52% 30/58 [00:04<00:04,  6.32it/s]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 29.70it/s]\u001b[A\n",
            "Epoch 0: 100% 58/58 [00:06<00:00,  9.08it/s, loss=1.36, v_num=dcz5, train_loss=1.060, train_loss_reg=0.0721, validation_loss=0.503]\n",
            "Epoch 0: 100% 58/58 [00:06<00:00,  9.07it/s, loss=1.36, v_num=dcz5, train_loss=1.060, train_loss_reg=0.0721, validation_loss=0.503]Epoch 0, global step 9: validation_loss reached 0.50339 (best 0.50339), saving model to \"/content/ED-MTT/checkpoints/best-checkpoint.ckpt\" as top 1\n",
            "Epoch 1:  52% 30/58 [00:04<00:04,  6.66it/s, loss=1.36, v_num=dcz5, train_loss=1.060, train_loss_reg=0.0721, validation_loss=0.503]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 27.93it/s]\u001b[A\n",
            "Epoch 1: 100% 58/58 [00:06<00:00,  9.29it/s, loss=1.32, v_num=dcz5, train_loss=0.988, train_loss_reg=0.0353, validation_loss=0.495]\n",
            "Epoch 1: 100% 58/58 [00:06<00:00,  9.29it/s, loss=1.32, v_num=dcz5, train_loss=0.988, train_loss_reg=0.0353, validation_loss=0.495]Epoch 1, global step 19: validation_loss reached 0.49486 (best 0.49486), saving model to \"/content/ED-MTT/checkpoints/best-checkpoint.ckpt\" as top 1\n",
            "Epoch 2:  52% 30/58 [00:04<00:04,  6.66it/s, loss=1.32, v_num=dcz5, train_loss=0.988, train_loss_reg=0.0353, validation_loss=0.495]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.97it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.82it/s]\u001b[AEpoch 2, global step 29: validation_loss reached 0.48588 (best 0.48588), saving model to \"/content/ED-MTT/checkpoints/best-checkpoint.ckpt\" as top 1\n",
            "Epoch 2: 100% 58/58 [00:06<00:00,  9.36it/s, loss=1.33, v_num=dcz5, train_loss=1.570, train_loss_reg=0.679, validation_loss=0.486] \n",
            "Epoch 3:  52% 30/58 [00:04<00:04,  6.55it/s, loss=1.33, v_num=dcz5, train_loss=1.570, train_loss_reg=0.679, validation_loss=0.486]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.85it/s]\u001b[A\n",
            "Epoch 3: 100% 58/58 [00:06<00:00,  9.22it/s, loss=1.33, v_num=dcz5, train_loss=1.080, train_loss_reg=0.135, validation_loss=0.476]\n",
            "Epoch 3: 100% 58/58 [00:06<00:00,  9.21it/s, loss=1.33, v_num=dcz5, train_loss=1.080, train_loss_reg=0.135, validation_loss=0.476]Epoch 3, global step 39: validation_loss reached 0.47616 (best 0.47616), saving model to \"/content/ED-MTT/checkpoints/best-checkpoint.ckpt\" as top 1\n",
            "Epoch 4:  52% 30/58 [00:04<00:04,  6.50it/s, loss=1.33, v_num=dcz5, train_loss=1.080, train_loss_reg=0.135, validation_loss=0.476]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.60it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.36it/s]\u001b[AEpoch 4, global step 49: validation_loss reached 0.46351 (best 0.46351), saving model to \"/content/ED-MTT/checkpoints/best-checkpoint.ckpt\" as top 1\n",
            "Epoch 4: 100% 58/58 [00:06<00:00,  9.16it/s, loss=1.28, v_num=dcz5, train_loss=1.480, train_loss_reg=0.128, validation_loss=0.464]\n",
            "Epoch 5:  52% 30/58 [00:04<00:04,  6.55it/s, loss=1.28, v_num=dcz5, train_loss=1.480, train_loss_reg=0.128, validation_loss=0.464]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.81it/s]\u001b[A\n",
            "Epoch 5: 100% 58/58 [00:06<00:00,  9.21it/s, loss=1.27, v_num=dcz5, train_loss=0.816, train_loss_reg=0.0326, validation_loss=0.450]\n",
            "Epoch 5: 100% 58/58 [00:06<00:00,  9.21it/s, loss=1.27, v_num=dcz5, train_loss=0.816, train_loss_reg=0.0326, validation_loss=0.450]Epoch 5, global step 59: validation_loss reached 0.45014 (best 0.45014), saving model to \"/content/ED-MTT/checkpoints/best-checkpoint.ckpt\" as top 1\n",
            "Epoch 6:  52% 30/58 [00:04<00:04,  6.43it/s, loss=1.27, v_num=dcz5, train_loss=0.816, train_loss_reg=0.0326, validation_loss=0.450]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.35it/s]\u001b[A\n",
            "Epoch 6: 100% 58/58 [00:06<00:00,  9.08it/s, loss=1.2, v_num=dcz5, train_loss=0.697, train_loss_reg=0.274, validation_loss=0.437]  \n",
            "Epoch 6: 100% 58/58 [00:06<00:00,  9.08it/s, loss=1.2, v_num=dcz5, train_loss=0.697, train_loss_reg=0.274, validation_loss=0.437]Epoch 6, global step 69: validation_loss reached 0.43653 (best 0.43653), saving model to \"/content/ED-MTT/checkpoints/best-checkpoint.ckpt\" as top 1\n",
            "Epoch 7:  52% 30/58 [00:04<00:04,  6.33it/s, loss=1.2, v_num=dcz5, train_loss=0.697, train_loss_reg=0.274, validation_loss=0.437]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.66it/s]\u001b[A\n",
            "Epoch 7: 100% 58/58 [00:06<00:00,  9.00it/s, loss=1.19, v_num=dcz5, train_loss=1.470, train_loss_reg=0.430, validation_loss=0.421]Epoch 7, global step 79: validation_loss reached 0.42104 (best 0.42104), saving model to \"/content/ED-MTT/checkpoints/best-checkpoint.ckpt\" as top 1\n",
            "\n",
            "Epoch 8:  52% 30/58 [00:04<00:04,  6.31it/s, loss=1.19, v_num=dcz5, train_loss=1.470, train_loss_reg=0.430, validation_loss=0.421]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.84it/s]\u001b[A\n",
            "Epoch 8: 100% 58/58 [00:06<00:00,  8.97it/s, loss=1.22, v_num=dcz5, train_loss=1.980, train_loss_reg=0.828, validation_loss=0.398]\n",
            "Epoch 8: 100% 58/58 [00:06<00:00,  8.97it/s, loss=1.22, v_num=dcz5, train_loss=1.980, train_loss_reg=0.828, validation_loss=0.398]Epoch 8, global step 89: validation_loss reached 0.39770 (best 0.39770), saving model to \"/content/ED-MTT/checkpoints/best-checkpoint.ckpt\" as top 1\n",
            "Epoch 9:  52% 30/58 [00:04<00:04,  6.25it/s, loss=1.22, v_num=dcz5, train_loss=1.980, train_loss_reg=0.828, validation_loss=0.398]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.71it/s]\u001b[A\n",
            "Epoch 9: 100% 58/58 [00:06<00:00,  8.91it/s, loss=1.15, v_num=dcz5, train_loss=1.360, train_loss_reg=0.358, validation_loss=0.367]\n",
            "Epoch 9: 100% 58/58 [00:06<00:00,  8.91it/s, loss=1.15, v_num=dcz5, train_loss=1.360, train_loss_reg=0.358, validation_loss=0.367]Epoch 9, global step 99: validation_loss reached 0.36710 (best 0.36710), saving model to \"/content/ED-MTT/checkpoints/best-checkpoint.ckpt\" as top 1\n",
            "Epoch 10:  52% 30/58 [00:04<00:04,  6.20it/s, loss=1.15, v_num=dcz5, train_loss=1.360, train_loss_reg=0.358, validation_loss=0.367]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.87it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.53it/s]\u001b[AEpoch 10, global step 109: validation_loss reached 0.31138 (best 0.31138), saving model to \"/content/ED-MTT/checkpoints/best-checkpoint.ckpt\" as top 1\n",
            "Epoch 10: 100% 58/58 [00:06<00:00,  8.86it/s, loss=1.1, v_num=dcz5, train_loss=0.681, train_loss_reg=0.279, validation_loss=0.311] \n",
            "Epoch 11:  52% 30/58 [00:04<00:04,  6.12it/s, loss=1.1, v_num=dcz5, train_loss=0.681, train_loss_reg=0.279, validation_loss=0.311]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.71it/s]\u001b[A\n",
            "Epoch 11: 100% 58/58 [00:06<00:00,  8.77it/s, loss=1.03, v_num=dcz5, train_loss=0.864, train_loss_reg=0.114, validation_loss=0.192]\n",
            "Epoch 11: 100% 58/58 [00:06<00:00,  8.77it/s, loss=1.03, v_num=dcz5, train_loss=0.864, train_loss_reg=0.114, validation_loss=0.192]Epoch 11, global step 119: validation_loss reached 0.19238 (best 0.19238), saving model to \"/content/ED-MTT/checkpoints/best-checkpoint.ckpt\" as top 1\n",
            "Epoch 12:  52% 30/58 [00:04<00:04,  6.07it/s, loss=1.03, v_num=dcz5, train_loss=0.864, train_loss_reg=0.114, validation_loss=0.192]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.63it/s]\u001b[A\n",
            "Epoch 12: 100% 58/58 [00:06<00:00,  8.72it/s, loss=0.95, v_num=dcz5, train_loss=0.788, train_loss_reg=0.0692, validation_loss=0.127]\n",
            "Epoch 12: 100% 58/58 [00:06<00:00,  8.72it/s, loss=0.95, v_num=dcz5, train_loss=0.788, train_loss_reg=0.0692, validation_loss=0.127]Epoch 12, global step 129: validation_loss reached 0.12652 (best 0.12652), saving model to \"/content/ED-MTT/checkpoints/best-checkpoint.ckpt\" as top 1\n",
            "Epoch 13:  52% 30/58 [00:04<00:04,  6.09it/s, loss=0.95, v_num=dcz5, train_loss=0.788, train_loss_reg=0.0692, validation_loss=0.127]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.68it/s]\u001b[A\n",
            "Epoch 13: 100% 58/58 [00:06<00:00,  8.74it/s, loss=0.899, v_num=dcz5, train_loss=0.341, train_loss_reg=0.102, validation_loss=0.131]Epoch 13, global step 139: validation_loss was not in top 1\n",
            "\n",
            "Epoch 14:  52% 30/58 [00:04<00:04,  6.13it/s, loss=0.899, v_num=dcz5, train_loss=0.341, train_loss_reg=0.102, validation_loss=0.131]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.79it/s]\u001b[A\n",
            "Epoch 14: 100% 58/58 [00:06<00:00,  8.78it/s, loss=0.917, v_num=dcz5, train_loss=1.470, train_loss_reg=0.264, validation_loss=0.160]\n",
            "Epoch 14: 100% 58/58 [00:06<00:00,  8.78it/s, loss=0.917, v_num=dcz5, train_loss=1.470, train_loss_reg=0.264, validation_loss=0.160]Epoch 14, global step 149: validation_loss was not in top 1\n",
            "Epoch 15:  52% 30/58 [00:04<00:04,  6.01it/s, loss=0.917, v_num=dcz5, train_loss=1.470, train_loss_reg=0.264, validation_loss=0.160]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.95it/s]\u001b[A\n",
            "Epoch 15: 100% 58/58 [00:06<00:00,  8.66it/s, loss=0.923, v_num=dcz5, train_loss=0.888, train_loss_reg=0.0984, validation_loss=0.118]Epoch 15, global step 159: validation_loss reached 0.11818 (best 0.11818), saving model to \"/content/ED-MTT/checkpoints/best-checkpoint.ckpt\" as top 1\n",
            "\n",
            "Epoch 16:  52% 30/58 [00:05<00:04,  5.82it/s, loss=0.923, v_num=dcz5, train_loss=0.888, train_loss_reg=0.0984, validation_loss=0.118]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.71it/s]\u001b[A\n",
            "Epoch 16: 100% 58/58 [00:06<00:00,  8.43it/s, loss=0.789, v_num=dcz5, train_loss=0.430, train_loss_reg=0.0825, validation_loss=0.0917]Epoch 16, global step 169: validation_loss reached 0.09172 (best 0.09172), saving model to \"/content/ED-MTT/checkpoints/best-checkpoint.ckpt\" as top 1\n",
            "\n",
            "Epoch 17:  52% 30/58 [00:05<00:04,  5.83it/s, loss=0.789, v_num=dcz5, train_loss=0.430, train_loss_reg=0.0825, validation_loss=0.0917]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.63it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.34it/s]\u001b[AEpoch 17, global step 179: validation_loss reached 0.08337 (best 0.08337), saving model to \"/content/ED-MTT/checkpoints/best-checkpoint.ckpt\" as top 1\n",
            "Epoch 17: 100% 58/58 [00:06<00:00,  8.45it/s, loss=0.785, v_num=dcz5, train_loss=2.100, train_loss_reg=0.124, validation_loss=0.0834] \n",
            "Epoch 18:  52% 30/58 [00:05<00:04,  5.77it/s, loss=0.785, v_num=dcz5, train_loss=2.100, train_loss_reg=0.124, validation_loss=0.0834]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.76it/s]\u001b[A\n",
            "Epoch 18: 100% 58/58 [00:06<00:00,  8.38it/s, loss=0.801, v_num=dcz5, train_loss=0.926, train_loss_reg=0.120, validation_loss=0.0994]\n",
            "Epoch 18: 100% 58/58 [00:06<00:00,  8.38it/s, loss=0.801, v_num=dcz5, train_loss=0.926, train_loss_reg=0.120, validation_loss=0.0994]Epoch 18, global step 189: validation_loss was not in top 1\n",
            "Epoch 19:  52% 30/58 [00:05<00:04,  5.75it/s, loss=0.801, v_num=dcz5, train_loss=0.926, train_loss_reg=0.120, validation_loss=0.0994]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.60it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 24.73it/s]\u001b[AEpoch 19, global step 199: validation_loss was not in top 1\n",
            "Epoch 19: 100% 58/58 [00:07<00:00,  8.12it/s, loss=0.83, v_num=dcz5, train_loss=0.770, train_loss_reg=0.126, validation_loss=0.136]  \n",
            "Epoch 20:  52% 30/58 [00:05<00:04,  5.61it/s, loss=0.83, v_num=dcz5, train_loss=0.770, train_loss_reg=0.126, validation_loss=0.136]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.64it/s]\u001b[A\n",
            "Epoch 20: 100% 58/58 [00:07<00:00,  7.76it/s, loss=0.871, v_num=dcz5, train_loss=1.040, train_loss_reg=0.0416, validation_loss=0.0971]Epoch 20, global step 209: validation_loss was not in top 1\n",
            "\n",
            "Epoch 21:  52% 30/58 [00:05<00:05,  5.51it/s, loss=0.871, v_num=dcz5, train_loss=1.040, train_loss_reg=0.0416, validation_loss=0.0971]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.54it/s]\u001b[A\n",
            "Epoch 21: 100% 58/58 [00:07<00:00,  7.66it/s, loss=0.768, v_num=dcz5, train_loss=1.110, train_loss_reg=0.0747, validation_loss=0.0774]Epoch 21, global step 219: validation_loss reached 0.07745 (best 0.07745), saving model to \"/content/ED-MTT/checkpoints/best-checkpoint.ckpt\" as top 1\n",
            "\n",
            "Epoch 22:  52% 30/58 [00:05<00:05,  5.58it/s, loss=0.768, v_num=dcz5, train_loss=1.110, train_loss_reg=0.0747, validation_loss=0.0774]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.65it/s]\u001b[A\n",
            "Epoch 22: 100% 58/58 [00:07<00:00,  7.74it/s, loss=0.756, v_num=dcz5, train_loss=0.808, train_loss_reg=0.0352, validation_loss=0.0948]Epoch 22, global step 229: validation_loss was not in top 1\n",
            "\n",
            "Epoch 23:  52% 30/58 [00:05<00:04,  5.64it/s, loss=0.756, v_num=dcz5, train_loss=0.808, train_loss_reg=0.0352, validation_loss=0.0948]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.54it/s]\u001b[A\n",
            "Epoch 23: 100% 58/58 [00:07<00:00,  7.81it/s, loss=0.782, v_num=dcz5, train_loss=1.260, train_loss_reg=0.209, validation_loss=0.0933] Epoch 23, global step 239: validation_loss was not in top 1\n",
            "\n",
            "Epoch 24:  52% 30/58 [00:05<00:04,  5.63it/s, loss=0.782, v_num=dcz5, train_loss=1.260, train_loss_reg=0.209, validation_loss=0.0933]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.56it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 21.80it/s]\u001b[AEpoch 24, global step 249: validation_loss reached 0.07386 (best 0.07386), saving model to \"/content/ED-MTT/checkpoints/best-checkpoint.ckpt\" as top 1\n",
            "Epoch 24: 100% 58/58 [00:07<00:00,  7.78it/s, loss=0.734, v_num=dcz5, train_loss=1.950, train_loss_reg=0.0932, validation_loss=0.0739]\n",
            "Epoch 25:  52% 30/58 [00:05<00:05,  5.43it/s, loss=0.734, v_num=dcz5, train_loss=1.950, train_loss_reg=0.0932, validation_loss=0.0739]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.75it/s]\u001b[A\n",
            "Epoch 25: 100% 58/58 [00:07<00:00,  8.02it/s, loss=0.664, v_num=dcz5, train_loss=0.573, train_loss_reg=0.0225, validation_loss=0.0863]Epoch 25, global step 259: validation_loss was not in top 1\n",
            "\n",
            "Epoch 26:  52% 30/58 [00:05<00:04,  5.70it/s, loss=0.664, v_num=dcz5, train_loss=0.573, train_loss_reg=0.0225, validation_loss=0.0863]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.91it/s]\u001b[A\n",
            "Epoch 26: 100% 58/58 [00:06<00:00,  8.32it/s, loss=0.646, v_num=dcz5, train_loss=1.530, train_loss_reg=0.00736, validation_loss=0.0786]Epoch 26, global step 269: validation_loss was not in top 1\n",
            "\n",
            "Epoch 27:  52% 30/58 [00:05<00:04,  5.67it/s, loss=0.646, v_num=dcz5, train_loss=1.530, train_loss_reg=0.00736, validation_loss=0.0786]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.47it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 21.88it/s]\u001b[AEpoch 27, global step 279: validation_loss was not in top 1\n",
            "Epoch 27: 100% 58/58 [00:07<00:00,  7.82it/s, loss=0.608, v_num=dcz5, train_loss=0.480, train_loss_reg=0.0606, validation_loss=0.0946] \n",
            "Epoch 28:  52% 30/58 [00:05<00:04,  5.64it/s, loss=0.608, v_num=dcz5, train_loss=0.480, train_loss_reg=0.0606, validation_loss=0.0946]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.50it/s]\u001b[A\n",
            "Epoch 28: 100% 58/58 [00:07<00:00,  7.80it/s, loss=0.571, v_num=dcz5, train_loss=0.136, train_loss_reg=0.0309, validation_loss=0.0808]Epoch 28, global step 289: validation_loss was not in top 1\n",
            "\n",
            "Epoch 29:  52% 30/58 [00:05<00:04,  5.67it/s, loss=0.571, v_num=dcz5, train_loss=0.136, train_loss_reg=0.0309, validation_loss=0.0808]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.75it/s]\u001b[A\n",
            "Epoch 29: 100% 58/58 [00:07<00:00,  7.84it/s, loss=0.591, v_num=dcz5, train_loss=0.738, train_loss_reg=0.0913, validation_loss=0.0759]Epoch 29, global step 299: validation_loss was not in top 1\n",
            "\n",
            "Epoch 30:  52% 30/58 [00:05<00:04,  5.69it/s, loss=0.591, v_num=dcz5, train_loss=0.738, train_loss_reg=0.0913, validation_loss=0.0759]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.46it/s]\u001b[A\n",
            "Epoch 30: 100% 58/58 [00:06<00:00,  8.29it/s, loss=0.574, v_num=dcz5, train_loss=0.538, train_loss_reg=0.0879, validation_loss=0.0724]\n",
            "Epoch 30: 100% 58/58 [00:07<00:00,  8.28it/s, loss=0.574, v_num=dcz5, train_loss=0.538, train_loss_reg=0.0879, validation_loss=0.0724]Epoch 30, global step 309: validation_loss reached 0.07244 (best 0.07244), saving model to \"/content/ED-MTT/checkpoints/best-checkpoint.ckpt\" as top 1\n",
            "Epoch 31:  52% 30/58 [00:05<00:04,  5.61it/s, loss=0.574, v_num=dcz5, train_loss=0.538, train_loss_reg=0.0879, validation_loss=0.0724]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.44it/s]\u001b[A\n",
            "Epoch 31: 100% 58/58 [00:07<00:00,  7.77it/s, loss=0.57, v_num=dcz5, train_loss=0.410, train_loss_reg=0.110, validation_loss=0.0771]  Epoch 31, global step 319: validation_loss was not in top 1\n",
            "\n",
            "Epoch 32:  52% 30/58 [00:05<00:04,  5.72it/s, loss=0.57, v_num=dcz5, train_loss=0.410, train_loss_reg=0.110, validation_loss=0.0771]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.61it/s]\u001b[A\n",
            "Epoch 32: 100% 58/58 [00:07<00:00,  7.88it/s, loss=0.526, v_num=dcz5, train_loss=0.742, train_loss_reg=0.0588, validation_loss=0.0722]Epoch 32, global step 329: validation_loss reached 0.07215 (best 0.07215), saving model to \"/content/ED-MTT/checkpoints/best-checkpoint.ckpt\" as top 1\n",
            "\n",
            "Epoch 33:  52% 30/58 [00:05<00:04,  5.71it/s, loss=0.526, v_num=dcz5, train_loss=0.742, train_loss_reg=0.0588, validation_loss=0.0722]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.69it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.22it/s]\u001b[AEpoch 33, global step 339: validation_loss was not in top 1\n",
            "Epoch 33: 100% 58/58 [00:06<00:00,  8.31it/s, loss=0.452, v_num=dcz5, train_loss=0.0573, train_loss_reg=0.044, validation_loss=0.0729]\n",
            "Epoch 34:  52% 30/58 [00:05<00:04,  5.69it/s, loss=0.452, v_num=dcz5, train_loss=0.0573, train_loss_reg=0.044, validation_loss=0.0729]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.29it/s]\u001b[A\n",
            "Epoch 34: 100% 58/58 [00:07<00:00,  7.81it/s, loss=0.511, v_num=dcz5, train_loss=1.050, train_loss_reg=0.0185, validation_loss=0.0676]Epoch 34, global step 349: validation_loss reached 0.06762 (best 0.06762), saving model to \"/content/ED-MTT/checkpoints/best-checkpoint.ckpt\" as top 1\n",
            "\n",
            "Epoch 35:  52% 30/58 [00:05<00:04,  5.64it/s, loss=0.511, v_num=dcz5, train_loss=1.050, train_loss_reg=0.0185, validation_loss=0.0676]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.54it/s]\u001b[A\n",
            "Epoch 35: 100% 58/58 [00:07<00:00,  8.23it/s, loss=0.565, v_num=dcz5, train_loss=0.193, train_loss_reg=0.0675, validation_loss=0.110] Epoch 35, global step 359: validation_loss was not in top 1\n",
            "\n",
            "Epoch 36:  52% 30/58 [00:05<00:04,  5.65it/s, loss=0.565, v_num=dcz5, train_loss=0.193, train_loss_reg=0.0675, validation_loss=0.110]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.44it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 21.79it/s]\u001b[AEpoch 36, global step 369: validation_loss was not in top 1\n",
            "Epoch 36: 100% 58/58 [00:07<00:00,  7.79it/s, loss=0.492, v_num=dcz5, train_loss=0.727, train_loss_reg=0.015, validation_loss=0.0727]\n",
            "Epoch 37:  52% 30/58 [00:05<00:04,  5.63it/s, loss=0.492, v_num=dcz5, train_loss=0.727, train_loss_reg=0.015, validation_loss=0.0727]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.63it/s]\u001b[A\n",
            "Epoch 37: 100% 58/58 [00:07<00:00,  7.79it/s, loss=0.488, v_num=dcz5, train_loss=0.283, train_loss_reg=0.0299, validation_loss=0.0756]Epoch 37, global step 379: validation_loss was not in top 1\n",
            "\n",
            "Epoch 38:  52% 30/58 [00:05<00:04,  5.63it/s, loss=0.488, v_num=dcz5, train_loss=0.283, train_loss_reg=0.0299, validation_loss=0.0756]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.29it/s]\u001b[A\n",
            "Epoch 38: 100% 58/58 [00:07<00:00,  7.78it/s, loss=0.556, v_num=dcz5, train_loss=1.250, train_loss_reg=0.0946, validation_loss=0.0737]\n",
            "Epoch 38: 100% 58/58 [00:07<00:00,  7.78it/s, loss=0.556, v_num=dcz5, train_loss=1.250, train_loss_reg=0.0946, validation_loss=0.0737]Epoch 38, global step 389: validation_loss was not in top 1\n",
            "Epoch 39:  52% 30/58 [00:05<00:04,  5.65it/s, loss=0.556, v_num=dcz5, train_loss=1.250, train_loss_reg=0.0946, validation_loss=0.0737]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.41it/s]\u001b[A\n",
            "Epoch 39: 100% 58/58 [00:07<00:00,  7.81it/s, loss=0.487, v_num=dcz5, train_loss=0.295, train_loss_reg=0.0271, validation_loss=0.0627]Epoch 39, global step 399: validation_loss reached 0.06268 (best 0.06268), saving model to \"/content/ED-MTT/checkpoints/best-checkpoint.ckpt\" as top 1\n",
            "\n",
            "Epoch 40:  52% 30/58 [00:05<00:04,  5.75it/s, loss=0.487, v_num=dcz5, train_loss=0.295, train_loss_reg=0.0271, validation_loss=0.0627]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.89it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 24.33it/s]\u001b[AEpoch 40, global step 409: validation_loss was not in top 1\n",
            "Epoch 40: 100% 58/58 [00:07<00:00,  8.11it/s, loss=0.408, v_num=dcz5, train_loss=1.010, train_loss_reg=0.0224, validation_loss=0.086] \n",
            "Epoch 41:  52% 30/58 [00:05<00:04,  5.79it/s, loss=0.408, v_num=dcz5, train_loss=1.010, train_loss_reg=0.0224, validation_loss=0.086]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.43it/s]\u001b[A\n",
            "Epoch 41: 100% 58/58 [00:07<00:00,  8.10it/s, loss=0.46, v_num=dcz5, train_loss=0.0644, train_loss_reg=0.0151, validation_loss=0.0807]Epoch 41, global step 419: validation_loss was not in top 1\n",
            "\n",
            "Epoch 42:  52% 30/58 [00:05<00:04,  5.72it/s, loss=0.46, v_num=dcz5, train_loss=0.0644, train_loss_reg=0.0151, validation_loss=0.0807]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.67it/s]\u001b[A\n",
            "Epoch 42: 100% 58/58 [00:06<00:00,  8.33it/s, loss=0.468, v_num=dcz5, train_loss=0.415, train_loss_reg=0.0885, validation_loss=0.0985]Epoch 42, global step 429: validation_loss was not in top 1\n",
            "\n",
            "Epoch 43:  52% 30/58 [00:05<00:04,  5.75it/s, loss=0.468, v_num=dcz5, train_loss=0.415, train_loss_reg=0.0885, validation_loss=0.0985]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.72it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 21.94it/s]\u001b[AEpoch 43, global step 439: validation_loss was not in top 1\n",
            "Epoch 43: 100% 58/58 [00:07<00:00,  7.91it/s, loss=0.41, v_num=dcz5, train_loss=0.787, train_loss_reg=0.0312, validation_loss=0.0743] \n",
            "Epoch 44:  52% 30/58 [00:05<00:04,  5.74it/s, loss=0.41, v_num=dcz5, train_loss=0.787, train_loss_reg=0.0312, validation_loss=0.0743]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.29it/s]\u001b[A\n",
            "Epoch 44: 100% 58/58 [00:06<00:00,  8.33it/s, loss=0.43, v_num=dcz5, train_loss=1.250, train_loss_reg=0.137, validation_loss=0.0878] Epoch 44, global step 449: validation_loss was not in top 1\n",
            "\n",
            "Epoch 45:  52% 30/58 [00:05<00:04,  5.78it/s, loss=0.43, v_num=dcz5, train_loss=1.250, train_loss_reg=0.137, validation_loss=0.0878]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.17it/s]\u001b[A\n",
            "Epoch 45: 100% 58/58 [00:07<00:00,  7.92it/s, loss=0.444, v_num=dcz5, train_loss=0.288, train_loss_reg=0.0608, validation_loss=0.082]Epoch 45, global step 459: validation_loss was not in top 1\n",
            "\n",
            "Epoch 46:  52% 30/58 [00:05<00:04,  5.69it/s, loss=0.444, v_num=dcz5, train_loss=0.288, train_loss_reg=0.0608, validation_loss=0.082]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.27it/s]\u001b[A\n",
            "Epoch 46: 100% 58/58 [00:07<00:00,  7.84it/s, loss=0.454, v_num=dcz5, train_loss=0.482, train_loss_reg=0.0512, validation_loss=0.0815]Epoch 46, global step 469: validation_loss was not in top 1\n",
            "\n",
            "Epoch 47:  52% 30/58 [00:05<00:04,  5.75it/s, loss=0.454, v_num=dcz5, train_loss=0.482, train_loss_reg=0.0512, validation_loss=0.0815]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.81it/s]\u001b[A\n",
            "Epoch 47: 100% 58/58 [00:06<00:00,  8.37it/s, loss=0.421, v_num=dcz5, train_loss=0.323, train_loss_reg=0.0419, validation_loss=0.0836]Epoch 47, global step 479: validation_loss was not in top 1\n",
            "\n",
            "Epoch 48:  52% 30/58 [00:05<00:04,  5.77it/s, loss=0.421, v_num=dcz5, train_loss=0.323, train_loss_reg=0.0419, validation_loss=0.0836]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.58it/s]\u001b[A\n",
            "Epoch 48: 100% 58/58 [00:06<00:00,  8.38it/s, loss=0.389, v_num=dcz5, train_loss=0.332, train_loss_reg=0.0496, validation_loss=0.105] \n",
            "Epoch 48: 100% 58/58 [00:06<00:00,  8.38it/s, loss=0.389, v_num=dcz5, train_loss=0.332, train_loss_reg=0.0496, validation_loss=0.105]Epoch 48, global step 489: validation_loss was not in top 1\n",
            "Epoch 49:  52% 30/58 [00:05<00:04,  5.80it/s, loss=0.389, v_num=dcz5, train_loss=0.332, train_loss_reg=0.0496, validation_loss=0.105]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.28it/s]\u001b[A\n",
            "Epoch 49: 100% 58/58 [00:07<00:00,  7.95it/s, loss=0.389, v_num=dcz5, train_loss=0.0968, train_loss_reg=0.0211, validation_loss=0.0751]Epoch 49, global step 499: validation_loss was not in top 1\n",
            "\n",
            "Epoch 50:  52% 30/58 [00:05<00:04,  5.77it/s, loss=0.389, v_num=dcz5, train_loss=0.0968, train_loss_reg=0.0211, validation_loss=0.0751]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.73it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.36it/s]\u001b[AEpoch 50, global step 509: validation_loss was not in top 1\n",
            "Epoch 50: 100% 58/58 [00:06<00:00,  8.39it/s, loss=0.387, v_num=dcz5, train_loss=1.500, train_loss_reg=0.0816, validation_loss=0.0806] \n",
            "Epoch 51:  52% 30/58 [00:05<00:04,  5.81it/s, loss=0.387, v_num=dcz5, train_loss=1.500, train_loss_reg=0.0816, validation_loss=0.0806]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.51it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 22.04it/s]\u001b[AEpoch 51, global step 519: validation_loss was not in top 1\n",
            "Epoch 51: 100% 58/58 [00:07<00:00,  7.97it/s, loss=0.387, v_num=dcz5, train_loss=0.644, train_loss_reg=0.0203, validation_loss=0.0741]\n",
            "Epoch 52:  52% 30/58 [00:05<00:04,  5.75it/s, loss=0.387, v_num=dcz5, train_loss=0.644, train_loss_reg=0.0203, validation_loss=0.0741]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.85it/s]\u001b[A\n",
            "Epoch 52: 100% 58/58 [00:06<00:00,  8.37it/s, loss=0.351, v_num=dcz5, train_loss=0.518, train_loss_reg=0.0275, validation_loss=0.0807]\n",
            "Epoch 52:   0% 0/58 [00:00<?, ?it/s, loss=0.351, v_num=dcz5, train_loss=0.518, train_loss_reg=0.0275, validation_loss=0.0807]         Epoch 52, global step 529: validation_loss was not in top 1\n",
            "Epoch 53:  52% 30/58 [00:05<00:04,  5.84it/s, loss=0.351, v_num=dcz5, train_loss=0.518, train_loss_reg=0.0275, validation_loss=0.0807]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.57it/s]\u001b[A\n",
            "Epoch 53: 100% 58/58 [00:06<00:00,  8.30it/s, loss=0.29, v_num=dcz5, train_loss=0.133, train_loss_reg=0.0237, validation_loss=0.0776] \n",
            "Epoch 53:   0% 0/58 [00:00<?, ?it/s, loss=0.29, v_num=dcz5, train_loss=0.133, train_loss_reg=0.0237, validation_loss=0.0776]         Epoch 53, global step 539: validation_loss was not in top 1\n",
            "Epoch 54:  52% 30/58 [00:05<00:04,  5.83it/s, loss=0.29, v_num=dcz5, train_loss=0.133, train_loss_reg=0.0237, validation_loss=0.0776]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.69it/s]\u001b[A\n",
            "Epoch 54: 100% 58/58 [00:07<00:00,  8.00it/s, loss=0.235, v_num=dcz5, train_loss=0.668, train_loss_reg=0.0135, validation_loss=0.0727]\n",
            "Epoch 54:   0% 0/58 [00:00<?, ?it/s, loss=0.235, v_num=dcz5, train_loss=0.668, train_loss_reg=0.0135, validation_loss=0.0727]         Epoch 54, global step 549: validation_loss was not in top 1\n",
            "Epoch 55:  52% 30/58 [00:05<00:04,  5.77it/s, loss=0.235, v_num=dcz5, train_loss=0.668, train_loss_reg=0.0135, validation_loss=0.0727]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.42it/s]\u001b[A\n",
            "Epoch 55: 100% 58/58 [00:07<00:00,  7.93it/s, loss=0.333, v_num=dcz5, train_loss=0.318, train_loss_reg=0.0237, validation_loss=0.0716]\n",
            "Epoch 55:   0% 0/58 [00:00<?, ?it/s, loss=0.333, v_num=dcz5, train_loss=0.318, train_loss_reg=0.0237, validation_loss=0.0716]         Epoch 55, global step 559: validation_loss was not in top 1\n",
            "Epoch 56:  52% 30/58 [00:05<00:04,  5.77it/s, loss=0.333, v_num=dcz5, train_loss=0.318, train_loss_reg=0.0237, validation_loss=0.0716]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.32it/s]\u001b[A\n",
            "Epoch 56: 100% 58/58 [00:07<00:00,  7.93it/s, loss=0.43, v_num=dcz5, train_loss=1.230, train_loss_reg=0.0302, validation_loss=0.0719] Epoch 56, global step 569: validation_loss was not in top 1\n",
            "\n",
            "Epoch 57:  52% 30/58 [00:05<00:04,  5.72it/s, loss=0.43, v_num=dcz5, train_loss=1.230, train_loss_reg=0.0302, validation_loss=0.0719]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.62it/s]\u001b[A\n",
            "Epoch 57: 100% 58/58 [00:07<00:00,  7.88it/s, loss=0.445, v_num=dcz5, train_loss=0.472, train_loss_reg=0.0245, validation_loss=0.0996]Epoch 57, global step 579: validation_loss was not in top 1\n",
            "\n",
            "Epoch 58:  52% 30/58 [00:05<00:04,  5.71it/s, loss=0.445, v_num=dcz5, train_loss=0.472, train_loss_reg=0.0245, validation_loss=0.0996]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.24it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 21.79it/s]\u001b[AEpoch 58, global step 589: validation_loss was not in top 1\n",
            "Epoch 58: 100% 58/58 [00:07<00:00,  7.85it/s, loss=0.442, v_num=dcz5, train_loss=0.663, train_loss_reg=0.095, validation_loss=0.0671] \n",
            "Epoch 59:  52% 30/58 [00:05<00:04,  5.77it/s, loss=0.442, v_num=dcz5, train_loss=0.663, train_loss_reg=0.095, validation_loss=0.0671]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.71it/s]\u001b[A\n",
            "Epoch 59: 100% 58/58 [00:07<00:00,  7.92it/s, loss=0.319, v_num=dcz5, train_loss=0.0206, train_loss_reg=0.0206, validation_loss=0.070]\n",
            "Epoch 60:   0% 0/58 [00:00<?, ?it/s, loss=0.319, v_num=dcz5, train_loss=0.0206, train_loss_reg=0.0206, validation_loss=0.070]Epoch 59, global step 599: validation_loss was not in top 1\n",
            "Epoch 60:  52% 30/58 [00:05<00:04,  5.79it/s, loss=0.319, v_num=dcz5, train_loss=0.0206, train_loss_reg=0.0206, validation_loss=0.070]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.50it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 21.91it/s]\u001b[AEpoch 60, global step 609: validation_loss was not in top 1\n",
            "Epoch 60: 100% 58/58 [00:07<00:00,  7.94it/s, loss=0.237, v_num=dcz5, train_loss=0.348, train_loss_reg=0.0143, validation_loss=0.0734]\n",
            "Epoch 61:  52% 30/58 [00:05<00:04,  5.77it/s, loss=0.237, v_num=dcz5, train_loss=0.348, train_loss_reg=0.0143, validation_loss=0.0734]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.44it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 21.82it/s]\u001b[AEpoch 61, global step 619: validation_loss was not in top 1\n",
            "Epoch 61: 100% 58/58 [00:07<00:00,  7.92it/s, loss=0.321, v_num=dcz5, train_loss=1.230, train_loss_reg=0.216, validation_loss=0.071]  \n",
            "Epoch 62:  52% 30/58 [00:05<00:04,  5.69it/s, loss=0.321, v_num=dcz5, train_loss=1.230, train_loss_reg=0.216, validation_loss=0.071]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.63it/s]\u001b[A\n",
            "Epoch 62: 100% 58/58 [00:07<00:00,  7.84it/s, loss=0.44, v_num=dcz5, train_loss=1.700, train_loss_reg=0.180, validation_loss=0.0868]Epoch 62, global step 629: validation_loss was not in top 1\n",
            "\n",
            "Epoch 63:  52% 30/58 [00:05<00:04,  5.67it/s, loss=0.44, v_num=dcz5, train_loss=1.700, train_loss_reg=0.180, validation_loss=0.0868]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.36it/s]\u001b[A\n",
            "Epoch 63: 100% 58/58 [00:07<00:00,  7.82it/s, loss=0.458, v_num=dcz5, train_loss=0.765, train_loss_reg=0.0157, validation_loss=0.0579]\n",
            "Epoch 63: 100% 58/58 [00:07<00:00,  7.82it/s, loss=0.458, v_num=dcz5, train_loss=0.765, train_loss_reg=0.0157, validation_loss=0.0579]Epoch 63, global step 639: validation_loss reached 0.05794 (best 0.05794), saving model to \"/content/ED-MTT/checkpoints/best-checkpoint.ckpt\" as top 1\n",
            "Epoch 64:  52% 30/58 [00:05<00:04,  5.73it/s, loss=0.458, v_num=dcz5, train_loss=0.765, train_loss_reg=0.0157, validation_loss=0.0579]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.74it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 26.79it/s]\u001b[AEpoch 64, global step 649: validation_loss was not in top 1\n",
            "Epoch 64: 100% 58/58 [00:07<00:00,  8.25it/s, loss=0.431, v_num=dcz5, train_loss=0.647, train_loss_reg=0.00842, validation_loss=0.072]\n",
            "Epoch 65:  52% 30/58 [00:05<00:04,  5.73it/s, loss=0.431, v_num=dcz5, train_loss=0.647, train_loss_reg=0.00842, validation_loss=0.072]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.12it/s]\u001b[A\n",
            "Epoch 65: 100% 58/58 [00:07<00:00,  8.28it/s, loss=0.359, v_num=dcz5, train_loss=0.483, train_loss_reg=0.0385, validation_loss=0.0717]Epoch 65, global step 659: validation_loss was not in top 1\n",
            "\n",
            "Epoch 66:  52% 30/58 [00:05<00:04,  5.70it/s, loss=0.359, v_num=dcz5, train_loss=0.483, train_loss_reg=0.0385, validation_loss=0.0717]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.16it/s]\u001b[A\n",
            "Epoch 66: 100% 58/58 [00:07<00:00,  7.83it/s, loss=0.285, v_num=dcz5, train_loss=0.311, train_loss_reg=0.00975, validation_loss=0.0652]\n",
            "Epoch 66:   0% 0/58 [00:00<?, ?it/s, loss=0.285, v_num=dcz5, train_loss=0.311, train_loss_reg=0.00975, validation_loss=0.0652]         Epoch 66, global step 669: validation_loss was not in top 1\n",
            "Epoch 67:  52% 30/58 [00:05<00:04,  5.69it/s, loss=0.285, v_num=dcz5, train_loss=0.311, train_loss_reg=0.00975, validation_loss=0.0652]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.45it/s]\u001b[A\n",
            "Epoch 67: 100% 58/58 [00:07<00:00,  7.84it/s, loss=0.479, v_num=dcz5, train_loss=0.394, train_loss_reg=0.0249, validation_loss=0.075]  \n",
            "Epoch 68:   0% 0/58 [00:00<?, ?it/s, loss=0.479, v_num=dcz5, train_loss=0.394, train_loss_reg=0.0249, validation_loss=0.075]Epoch 67, global step 679: validation_loss was not in top 1\n",
            "Epoch 68:  52% 30/58 [00:05<00:04,  5.68it/s, loss=0.479, v_num=dcz5, train_loss=0.394, train_loss_reg=0.0249, validation_loss=0.075]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.14it/s]\u001b[A\n",
            "Epoch 68: 100% 58/58 [00:07<00:00,  8.01it/s, loss=0.581, v_num=dcz5, train_loss=0.409, train_loss_reg=0.0217, validation_loss=0.0667]Epoch 68, global step 689: validation_loss was not in top 1\n",
            "\n",
            "Epoch 69:  52% 30/58 [00:05<00:04,  5.75it/s, loss=0.581, v_num=dcz5, train_loss=0.409, train_loss_reg=0.0217, validation_loss=0.0667]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.68it/s]\u001b[A\n",
            "Epoch 69: 100% 58/58 [00:06<00:00,  8.35it/s, loss=0.434, v_num=dcz5, train_loss=0.0893, train_loss_reg=0.0106, validation_loss=0.0793]Epoch 69, global step 699: validation_loss was not in top 1\n",
            "\n",
            "Epoch 70:  52% 30/58 [00:05<00:04,  5.73it/s, loss=0.434, v_num=dcz5, train_loss=0.0893, train_loss_reg=0.0106, validation_loss=0.0793]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.75it/s]\u001b[A\n",
            "Epoch 70: 100% 58/58 [00:06<00:00,  8.34it/s, loss=0.414, v_num=dcz5, train_loss=1.210, train_loss_reg=0.00212, validation_loss=0.0812]Epoch 70, global step 709: validation_loss was not in top 1\n",
            "\n",
            "Epoch 71:  52% 30/58 [00:05<00:04,  5.75it/s, loss=0.414, v_num=dcz5, train_loss=1.210, train_loss_reg=0.00212, validation_loss=0.0812]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.39it/s]\u001b[A\n",
            "Epoch 71: 100% 58/58 [00:07<00:00,  7.90it/s, loss=0.342, v_num=dcz5, train_loss=0.0468, train_loss_reg=0.0291, validation_loss=0.0727]Epoch 71, global step 719: validation_loss was not in top 1\n",
            "\n",
            "Epoch 72:  52% 30/58 [00:05<00:04,  5.73it/s, loss=0.342, v_num=dcz5, train_loss=0.0468, train_loss_reg=0.0291, validation_loss=0.0727]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.66it/s]\u001b[A\n",
            "Epoch 72: 100% 58/58 [00:06<00:00,  8.34it/s, loss=0.423, v_num=dcz5, train_loss=3.170, train_loss_reg=0.0599, validation_loss=0.060]  Epoch 72, global step 729: validation_loss was not in top 1\n",
            "\n",
            "Epoch 73:  52% 30/58 [00:05<00:04,  5.77it/s, loss=0.423, v_num=dcz5, train_loss=3.170, train_loss_reg=0.0599, validation_loss=0.060]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.35it/s]\u001b[A\n",
            "Epoch 73: 100% 58/58 [00:07<00:00,  8.17it/s, loss=0.534, v_num=dcz5, train_loss=1.660, train_loss_reg=0.115, validation_loss=0.0783]\n",
            "Epoch 73: 100% 58/58 [00:07<00:00,  8.17it/s, loss=0.534, v_num=dcz5, train_loss=1.660, train_loss_reg=0.115, validation_loss=0.0783]Epoch 73, global step 739: validation_loss was not in top 1\n",
            "Epoch 74:  52% 30/58 [00:05<00:04,  5.76it/s, loss=0.534, v_num=dcz5, train_loss=1.660, train_loss_reg=0.115, validation_loss=0.0783]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.79it/s]\u001b[A\n",
            "Epoch 74: 100% 58/58 [00:07<00:00,  7.92it/s, loss=0.375, v_num=dcz5, train_loss=0.315, train_loss_reg=0.0726, validation_loss=0.0623]Epoch 74, global step 749: validation_loss was not in top 1\n",
            "\n",
            "Epoch 75:  52% 30/58 [00:05<00:04,  5.79it/s, loss=0.375, v_num=dcz5, train_loss=0.315, train_loss_reg=0.0726, validation_loss=0.0623]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.28it/s]\u001b[A\n",
            "Epoch 75: 100% 58/58 [00:07<00:00,  7.95it/s, loss=0.268, v_num=dcz5, train_loss=0.449, train_loss_reg=0.0242, validation_loss=0.0785]\n",
            "Epoch 75: 100% 58/58 [00:07<00:00,  7.95it/s, loss=0.268, v_num=dcz5, train_loss=0.449, train_loss_reg=0.0242, validation_loss=0.0785]Epoch 75, global step 759: validation_loss was not in top 1\n",
            "Epoch 76:  52% 30/58 [00:05<00:04,  5.83it/s, loss=0.268, v_num=dcz5, train_loss=0.449, train_loss_reg=0.0242, validation_loss=0.0785]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.69it/s]\u001b[A\n",
            "Epoch 76: 100% 58/58 [00:07<00:00,  8.16it/s, loss=0.2, v_num=dcz5, train_loss=0.0603, train_loss_reg=0.0498, validation_loss=0.068]  \n",
            "                                               \u001b[AEpoch 76, global step 769: validation_loss was not in top 1\n",
            "Epoch 77:  52% 30/58 [00:05<00:04,  5.79it/s, loss=0.2, v_num=dcz5, train_loss=0.0603, train_loss_reg=0.0498, validation_loss=0.068]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.49it/s]\u001b[A\n",
            "Epoch 77: 100% 58/58 [00:06<00:00,  8.30it/s, loss=0.236, v_num=dcz5, train_loss=0.855, train_loss_reg=0.0169, validation_loss=0.0693]Epoch 77, global step 779: validation_loss was not in top 1\n",
            "\n",
            "Epoch 78:  52% 30/58 [00:05<00:04,  5.72it/s, loss=0.236, v_num=dcz5, train_loss=0.855, train_loss_reg=0.0169, validation_loss=0.0693]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.58it/s]\u001b[A\n",
            "Epoch 78: 100% 58/58 [00:07<00:00,  7.87it/s, loss=0.324, v_num=dcz5, train_loss=0.364, train_loss_reg=0.00521, validation_loss=0.0676]Epoch 78, global step 789: validation_loss was not in top 1\n",
            "\n",
            "Epoch 79:  52% 30/58 [00:05<00:04,  5.69it/s, loss=0.324, v_num=dcz5, train_loss=0.364, train_loss_reg=0.00521, validation_loss=0.0676]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.58it/s]\u001b[A\n",
            "Epoch 79: 100% 58/58 [00:07<00:00,  8.09it/s, loss=0.301, v_num=dcz5, train_loss=0.349, train_loss_reg=0.0511, validation_loss=0.0649] Epoch 79, global step 799: validation_loss was not in top 1\n",
            "\n",
            "Epoch 80:  52% 30/58 [00:05<00:04,  5.76it/s, loss=0.301, v_num=dcz5, train_loss=0.349, train_loss_reg=0.0511, validation_loss=0.0649]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.60it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 23.62it/s]\u001b[AEpoch 80, global step 809: validation_loss was not in top 1\n",
            "Epoch 80: 100% 58/58 [00:07<00:00,  8.06it/s, loss=0.262, v_num=dcz5, train_loss=0.795, train_loss_reg=0.0549, validation_loss=0.0637]\n",
            "Epoch 81:  52% 30/58 [00:05<00:04,  5.81it/s, loss=0.262, v_num=dcz5, train_loss=0.795, train_loss_reg=0.0549, validation_loss=0.0637]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.53it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 21.96it/s]\u001b[AEpoch 81, global step 819: validation_loss was not in top 1\n",
            "Epoch 81: 100% 58/58 [00:07<00:00,  7.97it/s, loss=0.205, v_num=dcz5, train_loss=0.277, train_loss_reg=0.0787, validation_loss=0.0662]\n",
            "Epoch 82:  52% 30/58 [00:05<00:04,  5.81it/s, loss=0.205, v_num=dcz5, train_loss=0.277, train_loss_reg=0.0787, validation_loss=0.0662]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.69it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.16it/s]\u001b[AEpoch 82, global step 829: validation_loss was not in top 1\n",
            "Epoch 82: 100% 58/58 [00:06<00:00,  8.42it/s, loss=0.205, v_num=dcz5, train_loss=0.632, train_loss_reg=0.0444, validation_loss=0.062] \n",
            "Epoch 83:  52% 30/58 [00:05<00:04,  5.80it/s, loss=0.205, v_num=dcz5, train_loss=0.632, train_loss_reg=0.0444, validation_loss=0.062]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.69it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 21.98it/s]\u001b[AEpoch 83, global step 839: validation_loss was not in top 1\n",
            "Epoch 83: 100% 58/58 [00:07<00:00,  7.96it/s, loss=0.31, v_num=dcz5, train_loss=0.358, train_loss_reg=0.0593, validation_loss=0.0685]\n",
            "Epoch 84:  52% 30/58 [00:05<00:04,  5.80it/s, loss=0.31, v_num=dcz5, train_loss=0.358, train_loss_reg=0.0593, validation_loss=0.0685]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.56it/s]\u001b[A\n",
            "Epoch 84: 100% 58/58 [00:07<00:00,  8.08it/s, loss=0.26, v_num=dcz5, train_loss=0.0818, train_loss_reg=0.0255, validation_loss=0.0714]\n",
            "Epoch 84: 100% 58/58 [00:07<00:00,  8.08it/s, loss=0.26, v_num=dcz5, train_loss=0.0818, train_loss_reg=0.0255, validation_loss=0.0714]Epoch 84, global step 849: validation_loss was not in top 1\n",
            "Epoch 85:  52% 30/58 [00:05<00:04,  5.90it/s, loss=0.26, v_num=dcz5, train_loss=0.0818, train_loss_reg=0.0255, validation_loss=0.0714]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.70it/s]\u001b[A\n",
            "Epoch 85: 100% 58/58 [00:06<00:00,  8.52it/s, loss=0.168, v_num=dcz5, train_loss=0.452, train_loss_reg=0.0128, validation_loss=0.0559]\n",
            "Epoch 85: 100% 58/58 [00:06<00:00,  8.52it/s, loss=0.168, v_num=dcz5, train_loss=0.452, train_loss_reg=0.0128, validation_loss=0.0559]Epoch 85, global step 859: validation_loss reached 0.05593 (best 0.05593), saving model to \"/content/ED-MTT/checkpoints/best-checkpoint.ckpt\" as top 1\n",
            "Epoch 86:  52% 30/58 [00:05<00:04,  5.83it/s, loss=0.168, v_num=dcz5, train_loss=0.452, train_loss_reg=0.0128, validation_loss=0.0559]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.62it/s]\u001b[A\n",
            "Epoch 86: 100% 58/58 [00:06<00:00,  8.44it/s, loss=0.178, v_num=dcz5, train_loss=0.150, train_loss_reg=0.0308, validation_loss=0.0626]\n",
            "Epoch 86: 100% 58/58 [00:06<00:00,  8.43it/s, loss=0.178, v_num=dcz5, train_loss=0.150, train_loss_reg=0.0308, validation_loss=0.0626]Epoch 86, global step 869: validation_loss was not in top 1\n",
            "Epoch 87:  52% 30/58 [00:05<00:04,  5.85it/s, loss=0.178, v_num=dcz5, train_loss=0.150, train_loss_reg=0.0308, validation_loss=0.0626]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.65it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.27it/s]\u001b[AEpoch 87, global step 879: validation_loss was not in top 1\n",
            "Epoch 87: 100% 58/58 [00:06<00:00,  8.47it/s, loss=0.189, v_num=dcz5, train_loss=0.0192, train_loss_reg=0.019, validation_loss=0.0712]\n",
            "Epoch 88:  52% 30/58 [00:05<00:04,  5.85it/s, loss=0.189, v_num=dcz5, train_loss=0.0192, train_loss_reg=0.019, validation_loss=0.0712]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.56it/s]\u001b[A\n",
            "Epoch 88: 100% 58/58 [00:07<00:00,  8.00it/s, loss=0.177, v_num=dcz5, train_loss=0.0587, train_loss_reg=0.0479, validation_loss=0.0665]Epoch 88, global step 889: validation_loss was not in top 1\n",
            "\n",
            "Epoch 89:  52% 30/58 [00:05<00:04,  5.88it/s, loss=0.177, v_num=dcz5, train_loss=0.0587, train_loss_reg=0.0479, validation_loss=0.0665]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.52it/s]\u001b[A\n",
            "Epoch 89: 100% 58/58 [00:06<00:00,  8.49it/s, loss=0.117, v_num=dcz5, train_loss=0.00614, train_loss_reg=0.00614, validation_loss=0.0661]Epoch 89, global step 899: validation_loss was not in top 1\n",
            "\n",
            "Epoch 90:  52% 30/58 [00:05<00:04,  5.85it/s, loss=0.117, v_num=dcz5, train_loss=0.00614, train_loss_reg=0.00614, validation_loss=0.0661]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.69it/s]\u001b[A\n",
            "Epoch 90: 100% 58/58 [00:07<00:00,  8.03it/s, loss=0.0916, v_num=dcz5, train_loss=0.104, train_loss_reg=0.0597, validation_loss=0.0613]  Epoch 90, global step 909: validation_loss was not in top 1\n",
            "\n",
            "Epoch 91:  52% 30/58 [00:05<00:04,  5.83it/s, loss=0.0916, v_num=dcz5, train_loss=0.104, train_loss_reg=0.0597, validation_loss=0.0613]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 27.90it/s]\u001b[A\n",
            "Epoch 91: 100% 58/58 [00:07<00:00,  7.96it/s, loss=0.0959, v_num=dcz5, train_loss=0.301, train_loss_reg=0.0278, validation_loss=0.0621]Epoch 91, global step 919: validation_loss was not in top 1\n",
            "\n",
            "Epoch 92:  52% 30/58 [00:05<00:04,  5.84it/s, loss=0.0959, v_num=dcz5, train_loss=0.301, train_loss_reg=0.0278, validation_loss=0.0621]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.38it/s]\u001b[A\n",
            "Epoch 92: 100% 58/58 [00:06<00:00,  8.44it/s, loss=0.13, v_num=dcz5, train_loss=0.703, train_loss_reg=0.0095, validation_loss=0.0631]  Epoch 92, global step 929: validation_loss was not in top 1\n",
            "\n",
            "Epoch 93:  52% 30/58 [00:05<00:04,  5.81it/s, loss=0.13, v_num=dcz5, train_loss=0.703, train_loss_reg=0.0095, validation_loss=0.0631]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.41it/s]\u001b[A\n",
            "Epoch 93: 100% 58/58 [00:06<00:00,  8.41it/s, loss=0.28, v_num=dcz5, train_loss=0.723, train_loss_reg=0.0268, validation_loss=0.0649]Epoch 93, global step 939: validation_loss was not in top 1\n",
            "\n",
            "Epoch 94:  52% 30/58 [00:05<00:04,  5.84it/s, loss=0.28, v_num=dcz5, train_loss=0.723, train_loss_reg=0.0268, validation_loss=0.0649]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.48it/s]\u001b[A\n",
            "Epoch 94: 100% 58/58 [00:07<00:00,  8.21it/s, loss=0.298, v_num=dcz5, train_loss=0.103, train_loss_reg=0.0286, validation_loss=0.0679]\n",
            "Epoch 94:   0% 0/58 [00:00<?, ?it/s, loss=0.298, v_num=dcz5, train_loss=0.103, train_loss_reg=0.0286, validation_loss=0.0679]         Epoch 94, global step 949: validation_loss was not in top 1\n",
            "Epoch 95:  52% 30/58 [00:05<00:04,  5.80it/s, loss=0.298, v_num=dcz5, train_loss=0.103, train_loss_reg=0.0286, validation_loss=0.0679]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.63it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.10it/s]\u001b[AEpoch 95, global step 959: validation_loss was not in top 1\n",
            "Epoch 95: 100% 58/58 [00:06<00:00,  8.41it/s, loss=0.264, v_num=dcz5, train_loss=0.197, train_loss_reg=0.00412, validation_loss=0.0706]\n",
            "Epoch 96:  52% 30/58 [00:05<00:04,  5.82it/s, loss=0.264, v_num=dcz5, train_loss=0.197, train_loss_reg=0.00412, validation_loss=0.0706]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.71it/s]\u001b[A\n",
            "Epoch 96: 100% 58/58 [00:07<00:00,  8.06it/s, loss=0.281, v_num=dcz5, train_loss=0.155, train_loss_reg=0.0149, validation_loss=0.0609] \n",
            "Epoch 96, global step 969: validation_loss was not in top 1\n",
            "Epoch 97:  52% 30/58 [00:05<00:04,  5.85it/s, loss=0.281, v_num=dcz5, train_loss=0.155, train_loss_reg=0.0149, validation_loss=0.0609]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.47it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 21.95it/s]\u001b[AEpoch 97, global step 979: validation_loss was not in top 1\n",
            "Epoch 97: 100% 58/58 [00:07<00:00,  8.01it/s, loss=0.306, v_num=dcz5, train_loss=1.500, train_loss_reg=0.0725, validation_loss=0.0622]\n",
            "Epoch 98:  52% 30/58 [00:05<00:04,  5.74it/s, loss=0.306, v_num=dcz5, train_loss=1.500, train_loss_reg=0.0725, validation_loss=0.0622]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.54it/s]\u001b[A\n",
            "Epoch 98: 100% 58/58 [00:07<00:00,  8.14it/s, loss=0.326, v_num=dcz5, train_loss=0.438, train_loss_reg=0.0157, validation_loss=0.107] \n",
            "Epoch 98:   0% 0/58 [00:00<?, ?it/s, loss=0.326, v_num=dcz5, train_loss=0.438, train_loss_reg=0.0157, validation_loss=0.107]         Epoch 98, global step 989: validation_loss was not in top 1\n",
            "Epoch 99:  52% 30/58 [00:05<00:04,  5.83it/s, loss=0.326, v_num=dcz5, train_loss=0.438, train_loss_reg=0.0157, validation_loss=0.107]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.66it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.19it/s]\u001b[AEpoch 99, global step 999: validation_loss was not in top 1\n",
            "Epoch 99: 100% 58/58 [00:06<00:00,  8.45it/s, loss=0.258, v_num=dcz5, train_loss=0.641, train_loss_reg=0.0481, validation_loss=0.0638]\n",
            "Epoch 100:  52% 30/58 [00:05<00:04,  5.82it/s, loss=0.258, v_num=dcz5, train_loss=0.641, train_loss_reg=0.0481, validation_loss=0.0638]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.54it/s]\u001b[A\n",
            "Epoch 100: 100% 58/58 [00:07<00:00,  8.05it/s, loss=0.204, v_num=dcz5, train_loss=0.00505, train_loss_reg=0.00505, validation_loss=0.0546]Epoch 100, global step 1009: validation_loss reached 0.05464 (best 0.05464), saving model to \"/content/ED-MTT/checkpoints/best-checkpoint.ckpt\" as top 1\n",
            "\n",
            "Epoch 101:  52% 30/58 [00:05<00:04,  5.81it/s, loss=0.204, v_num=dcz5, train_loss=0.00505, train_loss_reg=0.00505, validation_loss=0.0546]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.63it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 27.88it/s]\u001b[AEpoch 101, global step 1019: validation_loss reached 0.05273 (best 0.05273), saving model to \"/content/ED-MTT/checkpoints/best-checkpoint.ckpt\" as top 1\n",
            "Epoch 101: 100% 58/58 [00:06<00:00,  8.40it/s, loss=0.166, v_num=dcz5, train_loss=0.0221, train_loss_reg=0.0208, validation_loss=0.0527]  \n",
            "Epoch 102:  52% 30/58 [00:05<00:04,  5.84it/s, loss=0.166, v_num=dcz5, train_loss=0.0221, train_loss_reg=0.0208, validation_loss=0.0527]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.97it/s]\u001b[A\n",
            "Epoch 102: 100% 58/58 [00:06<00:00,  8.48it/s, loss=0.134, v_num=dcz5, train_loss=0.109, train_loss_reg=0.0181, validation_loss=0.054]  Epoch 102, global step 1029: validation_loss was not in top 1\n",
            "\n",
            "Epoch 103:  52% 30/58 [00:05<00:04,  5.89it/s, loss=0.134, v_num=dcz5, train_loss=0.109, train_loss_reg=0.0181, validation_loss=0.054]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.00it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 21.81it/s]\u001b[AEpoch 103, global step 1039: validation_loss was not in top 1\n",
            "Epoch 103: 100% 58/58 [00:07<00:00,  8.02it/s, loss=0.116, v_num=dcz5, train_loss=0.00711, train_loss_reg=0.00711, validation_loss=0.0534]\n",
            "Epoch 104:  52% 30/58 [00:05<00:04,  5.83it/s, loss=0.116, v_num=dcz5, train_loss=0.00711, train_loss_reg=0.00711, validation_loss=0.0534]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.73it/s]\u001b[A\n",
            "Epoch 104: 100% 58/58 [00:07<00:00,  7.99it/s, loss=0.201, v_num=dcz5, train_loss=2.120, train_loss_reg=0.0521, validation_loss=0.0487]   Epoch 104, global step 1049: validation_loss reached 0.04873 (best 0.04873), saving model to \"/content/ED-MTT/checkpoints/best-checkpoint.ckpt\" as top 1\n",
            "\n",
            "Epoch 105:  52% 30/58 [00:05<00:04,  5.75it/s, loss=0.201, v_num=dcz5, train_loss=2.120, train_loss_reg=0.0521, validation_loss=0.0487]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.26it/s]\u001b[A\n",
            "Epoch 105: 100% 58/58 [00:07<00:00,  7.89it/s, loss=0.333, v_num=dcz5, train_loss=2.280, train_loss_reg=0.0631, validation_loss=0.0658]Epoch 105, global step 1059: validation_loss was not in top 1\n",
            "\n",
            "Epoch 106:  52% 30/58 [00:05<00:04,  5.80it/s, loss=0.333, v_num=dcz5, train_loss=2.280, train_loss_reg=0.0631, validation_loss=0.0658]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.42it/s]\u001b[A\n",
            "Epoch 106: 100% 58/58 [00:07<00:00,  7.95it/s, loss=0.355, v_num=dcz5, train_loss=2.230, train_loss_reg=0.0578, validation_loss=0.0794]\n",
            "Epoch 106: 100% 58/58 [00:07<00:00,  7.95it/s, loss=0.355, v_num=dcz5, train_loss=2.230, train_loss_reg=0.0578, validation_loss=0.0794]Epoch 106, global step 1069: validation_loss was not in top 1\n",
            "Epoch 107:  52% 30/58 [00:05<00:04,  5.73it/s, loss=0.355, v_num=dcz5, train_loss=2.230, train_loss_reg=0.0578, validation_loss=0.0794]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.40it/s]\u001b[A\n",
            "Epoch 107: 100% 58/58 [00:07<00:00,  7.87it/s, loss=0.284, v_num=dcz5, train_loss=0.105, train_loss_reg=0.0171, validation_loss=0.084] Epoch 107, global step 1079: validation_loss was not in top 1\n",
            "\n",
            "Epoch 108:  52% 30/58 [00:05<00:04,  5.76it/s, loss=0.284, v_num=dcz5, train_loss=0.105, train_loss_reg=0.0171, validation_loss=0.084]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.84it/s]\u001b[A\n",
            "Epoch 108: 100% 58/58 [00:06<00:00,  8.37it/s, loss=0.191, v_num=dcz5, train_loss=0.169, train_loss_reg=0.00302, validation_loss=0.0763]\n",
            "Epoch 109:   0% 0/58 [00:00<?, ?it/s, loss=0.191, v_num=dcz5, train_loss=0.169, train_loss_reg=0.00302, validation_loss=0.0763]Epoch 108, global step 1089: validation_loss was not in top 1\n",
            "Epoch 109:  52% 30/58 [00:05<00:04,  5.83it/s, loss=0.191, v_num=dcz5, train_loss=0.169, train_loss_reg=0.00302, validation_loss=0.0763]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.07it/s]\u001b[A\n",
            "Epoch 109: 100% 58/58 [00:07<00:00,  8.03it/s, loss=0.115, v_num=dcz5, train_loss=0.0531, train_loss_reg=0.00821, validation_loss=0.0657]Epoch 109, global step 1099: validation_loss was not in top 1\n",
            "\n",
            "Epoch 110:  52% 30/58 [00:05<00:04,  5.94it/s, loss=0.115, v_num=dcz5, train_loss=0.0531, train_loss_reg=0.00821, validation_loss=0.0657]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.84it/s]\u001b[A\n",
            "Epoch 110: 100% 58/58 [00:07<00:00,  8.14it/s, loss=0.0825, v_num=dcz5, train_loss=0.0548, train_loss_reg=0.0165, validation_loss=0.063] Epoch 110, global step 1109: validation_loss was not in top 1\n",
            "\n",
            "Epoch 111:  52% 30/58 [00:05<00:04,  5.90it/s, loss=0.0825, v_num=dcz5, train_loss=0.0548, train_loss_reg=0.0165, validation_loss=0.063]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.85it/s]\u001b[A\n",
            "Epoch 111: 100% 58/58 [00:06<00:00,  8.53it/s, loss=0.0903, v_num=dcz5, train_loss=0.0267, train_loss_reg=0.0219, validation_loss=0.0608]Epoch 111, global step 1119: validation_loss was not in top 1\n",
            "\n",
            "Epoch 112:  52% 30/58 [00:05<00:04,  5.94it/s, loss=0.0903, v_num=dcz5, train_loss=0.0267, train_loss_reg=0.0219, validation_loss=0.0608]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.22it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.15it/s]\u001b[AEpoch 112, global step 1129: validation_loss was not in top 1\n",
            "Epoch 112: 100% 58/58 [00:06<00:00,  8.56it/s, loss=0.137, v_num=dcz5, train_loss=1.210, train_loss_reg=0.0428, validation_loss=0.0622]  \n",
            "Epoch 113:  52% 30/58 [00:05<00:04,  5.92it/s, loss=0.137, v_num=dcz5, train_loss=1.210, train_loss_reg=0.0428, validation_loss=0.0622]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.79it/s]\u001b[A\n",
            "Epoch 113: 100% 58/58 [00:06<00:00,  8.40it/s, loss=0.26, v_num=dcz5, train_loss=0.944, train_loss_reg=0.0464, validation_loss=0.0608] \n",
            "Epoch 114:   0% 0/58 [00:00<?, ?it/s, loss=0.26, v_num=dcz5, train_loss=0.944, train_loss_reg=0.0464, validation_loss=0.0608]Epoch 113, global step 1139: validation_loss was not in top 1\n",
            "Epoch 114:  52% 30/58 [00:05<00:04,  5.89it/s, loss=0.26, v_num=dcz5, train_loss=0.944, train_loss_reg=0.0464, validation_loss=0.0608]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.49it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 25.08it/s]\u001b[AEpoch 114, global step 1149: validation_loss was not in top 1\n",
            "Epoch 114: 100% 58/58 [00:06<00:00,  8.30it/s, loss=0.261, v_num=dcz5, train_loss=0.104, train_loss_reg=0.00142, validation_loss=0.102]\n",
            "Epoch 115:  52% 30/58 [00:05<00:04,  5.87it/s, loss=0.261, v_num=dcz5, train_loss=0.104, train_loss_reg=0.00142, validation_loss=0.102]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.55it/s]\u001b[A\n",
            "Epoch 115: 100% 58/58 [00:06<00:00,  8.49it/s, loss=0.168, v_num=dcz5, train_loss=0.00781, train_loss_reg=0.00781, validation_loss=0.0707]Epoch 115, global step 1159: validation_loss was not in top 1\n",
            "\n",
            "Epoch 116:  52% 30/58 [00:05<00:04,  5.87it/s, loss=0.168, v_num=dcz5, train_loss=0.00781, train_loss_reg=0.00781, validation_loss=0.0707]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.40it/s]\u001b[A\n",
            "Epoch 116: 100% 58/58 [00:07<00:00,  8.02it/s, loss=0.167, v_num=dcz5, train_loss=0.154, train_loss_reg=0.00115, validation_loss=0.058]   Epoch 116, global step 1169: validation_loss was not in top 1\n",
            "\n",
            "Epoch 117:  52% 30/58 [00:05<00:04,  5.90it/s, loss=0.167, v_num=dcz5, train_loss=0.154, train_loss_reg=0.00115, validation_loss=0.058]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.55it/s]\u001b[A\n",
            "Epoch 117: 100% 58/58 [00:06<00:00,  8.52it/s, loss=0.17, v_num=dcz5, train_loss=0.454, train_loss_reg=0.0378, validation_loss=0.0605] Epoch 117, global step 1179: validation_loss was not in top 1\n",
            "\n",
            "Epoch 118:  52% 30/58 [00:05<00:04,  5.90it/s, loss=0.17, v_num=dcz5, train_loss=0.454, train_loss_reg=0.0378, validation_loss=0.0605]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.32it/s]\u001b[A\n",
            "Epoch 118: 100% 58/58 [00:06<00:00,  8.36it/s, loss=0.169, v_num=dcz5, train_loss=0.261, train_loss_reg=0.0244, validation_loss=0.0585]Epoch 118, global step 1189: validation_loss was not in top 1\n",
            "\n",
            "Epoch 119:  52% 30/58 [00:05<00:04,  5.86it/s, loss=0.169, v_num=dcz5, train_loss=0.261, train_loss_reg=0.0244, validation_loss=0.0585]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.85it/s]\u001b[A\n",
            "Epoch 119: 100% 58/58 [00:06<00:00,  8.49it/s, loss=0.212, v_num=dcz5, train_loss=0.282, train_loss_reg=0.0141, validation_loss=0.0621]\n",
            "Epoch 119:   0% 0/58 [00:00<?, ?it/s, loss=0.212, v_num=dcz5, train_loss=0.282, train_loss_reg=0.0141, validation_loss=0.0621]         Epoch 119, global step 1199: validation_loss was not in top 1\n",
            "Epoch 120:  52% 30/58 [00:05<00:04,  5.85it/s, loss=0.212, v_num=dcz5, train_loss=0.282, train_loss_reg=0.0141, validation_loss=0.0621]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.65it/s]\u001b[A\n",
            "Epoch 120: 100% 58/58 [00:06<00:00,  8.47it/s, loss=0.336, v_num=dcz5, train_loss=0.964, train_loss_reg=0.0187, validation_loss=0.0639]Epoch 120, global step 1209: validation_loss was not in top 1\n",
            "\n",
            "Epoch 121:  52% 30/58 [00:05<00:04,  5.82it/s, loss=0.336, v_num=dcz5, train_loss=0.964, train_loss_reg=0.0187, validation_loss=0.0639]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.30it/s]\u001b[A\n",
            "Epoch 121: 100% 58/58 [00:07<00:00,  7.96it/s, loss=0.305, v_num=dcz5, train_loss=0.530, train_loss_reg=0.104, validation_loss=0.054]  Epoch 121, global step 1219: validation_loss was not in top 1\n",
            "\n",
            "Epoch 122:  52% 30/58 [00:05<00:04,  5.83it/s, loss=0.305, v_num=dcz5, train_loss=0.530, train_loss_reg=0.104, validation_loss=0.054]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.28it/s]\u001b[A\n",
            "Epoch 122: 100% 58/58 [00:07<00:00,  7.95it/s, loss=0.135, v_num=dcz5, train_loss=0.0147, train_loss_reg=0.00625, validation_loss=0.0559]\n",
            "Epoch 122: 100% 58/58 [00:07<00:00,  7.95it/s, loss=0.135, v_num=dcz5, train_loss=0.0147, train_loss_reg=0.00625, validation_loss=0.0559]Epoch 122, global step 1229: validation_loss was not in top 1\n",
            "Epoch 123:  52% 30/58 [00:05<00:04,  5.87it/s, loss=0.135, v_num=dcz5, train_loss=0.0147, train_loss_reg=0.00625, validation_loss=0.0559]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.56it/s]\u001b[A\n",
            "Epoch 123: 100% 58/58 [00:06<00:00,  8.49it/s, loss=0.0912, v_num=dcz5, train_loss=0.0396, train_loss_reg=0.0163, validation_loss=0.0547]Epoch 123, global step 1239: validation_loss was not in top 1\n",
            "\n",
            "Epoch 124:  52% 30/58 [00:05<00:04,  5.88it/s, loss=0.0912, v_num=dcz5, train_loss=0.0396, train_loss_reg=0.0163, validation_loss=0.0547]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.66it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.40it/s]\u001b[AEpoch 124, global step 1249: validation_loss was not in top 1\n",
            "Epoch 124: 100% 58/58 [00:06<00:00,  8.51it/s, loss=0.116, v_num=dcz5, train_loss=0.199, train_loss_reg=0.0159, validation_loss=0.059]   \n",
            "Epoch 125:  52% 30/58 [00:05<00:04,  5.89it/s, loss=0.116, v_num=dcz5, train_loss=0.199, train_loss_reg=0.0159, validation_loss=0.059]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.38it/s]\u001b[A\n",
            "Epoch 125: 100% 58/58 [00:06<00:00,  8.29it/s, loss=0.107, v_num=dcz5, train_loss=0.028, train_loss_reg=0.028, validation_loss=0.0588]Epoch 125, global step 1259: validation_loss was not in top 1\n",
            "\n",
            "Epoch 126:  52% 30/58 [00:05<00:04,  5.86it/s, loss=0.107, v_num=dcz5, train_loss=0.028, train_loss_reg=0.028, validation_loss=0.0588]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.65it/s]\u001b[A\n",
            "Epoch 126: 100% 58/58 [00:06<00:00,  8.47it/s, loss=0.164, v_num=dcz5, train_loss=1.130, train_loss_reg=0.00123, validation_loss=0.0564]\n",
            "Epoch 126: 100% 58/58 [00:06<00:00,  8.47it/s, loss=0.164, v_num=dcz5, train_loss=1.130, train_loss_reg=0.00123, validation_loss=0.0564]Epoch 126, global step 1269: validation_loss was not in top 1\n",
            "Epoch 127:  52% 30/58 [00:05<00:04,  5.88it/s, loss=0.164, v_num=dcz5, train_loss=1.130, train_loss_reg=0.00123, validation_loss=0.0564]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.52it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.22it/s]\u001b[AEpoch 127, global step 1279: validation_loss was not in top 1\n",
            "Epoch 127: 100% 58/58 [00:06<00:00,  8.50it/s, loss=0.206, v_num=dcz5, train_loss=0.390, train_loss_reg=0.0464, validation_loss=0.0561] \n",
            "Epoch 128:  52% 30/58 [00:05<00:04,  5.88it/s, loss=0.206, v_num=dcz5, train_loss=0.390, train_loss_reg=0.0464, validation_loss=0.0561]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.73it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 22.00it/s]\u001b[AEpoch 128, global step 1289: validation_loss was not in top 1\n",
            "Epoch 128: 100% 58/58 [00:07<00:00,  8.04it/s, loss=0.166, v_num=dcz5, train_loss=0.402, train_loss_reg=0.0368, validation_loss=0.0652]\n",
            "Epoch 129:  52% 30/58 [00:05<00:04,  5.88it/s, loss=0.166, v_num=dcz5, train_loss=0.402, train_loss_reg=0.0368, validation_loss=0.0652]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.46it/s]\u001b[A\n",
            "Epoch 129: 100% 58/58 [00:07<00:00,  8.05it/s, loss=0.153, v_num=dcz5, train_loss=0.120, train_loss_reg=0.0294, validation_loss=0.0566]Epoch 129, global step 1299: validation_loss was not in top 1\n",
            "\n",
            "Epoch 130:  52% 30/58 [00:05<00:04,  5.92it/s, loss=0.153, v_num=dcz5, train_loss=0.120, train_loss_reg=0.0294, validation_loss=0.0566]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.24it/s]\u001b[A\n",
            "Epoch 130: 100% 58/58 [00:07<00:00,  8.24it/s, loss=0.144, v_num=dcz5, train_loss=0.596, train_loss_reg=0.0739, validation_loss=0.0509]Epoch 130, global step 1309: validation_loss was not in top 1\n",
            "\n",
            "Epoch 131:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.144, v_num=dcz5, train_loss=0.596, train_loss_reg=0.0739, validation_loss=0.0509]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.11it/s]\u001b[A\n",
            "Epoch 131: 100% 58/58 [00:07<00:00,  8.05it/s, loss=0.198, v_num=dcz5, train_loss=0.381, train_loss_reg=0.0324, validation_loss=0.052] Epoch 131, global step 1319: validation_loss was not in top 1\n",
            "\n",
            "Epoch 132:  52% 30/58 [00:05<00:04,  5.88it/s, loss=0.198, v_num=dcz5, train_loss=0.381, train_loss_reg=0.0324, validation_loss=0.052]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.55it/s]\u001b[A\n",
            "Epoch 132: 100% 58/58 [00:06<00:00,  8.50it/s, loss=0.206, v_num=dcz5, train_loss=0.401, train_loss_reg=0.00184, validation_loss=0.0559]Epoch 132, global step 1329: validation_loss was not in top 1\n",
            "\n",
            "Epoch 133:  52% 30/58 [00:05<00:04,  5.88it/s, loss=0.206, v_num=dcz5, train_loss=0.401, train_loss_reg=0.00184, validation_loss=0.0559]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.59it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 22.05it/s]\u001b[AEpoch 133, global step 1339: validation_loss was not in top 1\n",
            "Epoch 133: 100% 58/58 [00:07<00:00,  8.04it/s, loss=0.128, v_num=dcz5, train_loss=0.00691, train_loss_reg=0.00691, validation_loss=0.062]\n",
            "Epoch 134:  52% 30/58 [00:05<00:04,  5.81it/s, loss=0.128, v_num=dcz5, train_loss=0.00691, train_loss_reg=0.00691, validation_loss=0.062]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.29it/s]\u001b[A\n",
            "Epoch 134: 100% 58/58 [00:07<00:00,  7.95it/s, loss=0.157, v_num=dcz5, train_loss=1.100, train_loss_reg=0.0105, validation_loss=0.0576]  \n",
            "Epoch 134: 100% 58/58 [00:07<00:00,  7.95it/s, loss=0.157, v_num=dcz5, train_loss=1.100, train_loss_reg=0.0105, validation_loss=0.0576]Epoch 134, global step 1349: validation_loss was not in top 1\n",
            "Epoch 135:  52% 30/58 [00:05<00:04,  5.77it/s, loss=0.157, v_num=dcz5, train_loss=1.100, train_loss_reg=0.0105, validation_loss=0.0576]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.75it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.29it/s]\u001b[AEpoch 135, global step 1359: validation_loss was not in top 1\n",
            "Epoch 135: 100% 58/58 [00:06<00:00,  8.39it/s, loss=0.168, v_num=dcz5, train_loss=0.156, train_loss_reg=0.00539, validation_loss=0.060]\n",
            "Epoch 136:  52% 30/58 [00:05<00:04,  5.81it/s, loss=0.168, v_num=dcz5, train_loss=0.156, train_loss_reg=0.00539, validation_loss=0.060]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.24it/s]\u001b[A\n",
            "Epoch 136: 100% 58/58 [00:07<00:00,  7.95it/s, loss=0.137, v_num=dcz5, train_loss=0.191, train_loss_reg=0.0296, validation_loss=0.060] Epoch 136, global step 1369: validation_loss was not in top 1\n",
            "\n",
            "Epoch 137:  52% 30/58 [00:05<00:04,  5.83it/s, loss=0.137, v_num=dcz5, train_loss=0.191, train_loss_reg=0.0296, validation_loss=0.060]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.65it/s]\u001b[A\n",
            "Epoch 137: 100% 58/58 [00:07<00:00,  7.99it/s, loss=0.176, v_num=dcz5, train_loss=1.250, train_loss_reg=0.0397, validation_loss=0.0562]\n",
            "Epoch 137: 100% 58/58 [00:07<00:00,  7.99it/s, loss=0.176, v_num=dcz5, train_loss=1.250, train_loss_reg=0.0397, validation_loss=0.0562]Epoch 137, global step 1379: validation_loss was not in top 1\n",
            "Epoch 138:  52% 30/58 [00:05<00:04,  5.83it/s, loss=0.176, v_num=dcz5, train_loss=1.250, train_loss_reg=0.0397, validation_loss=0.0562]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.80it/s]\u001b[A\n",
            "Epoch 138: 100% 58/58 [00:06<00:00,  8.45it/s, loss=0.158, v_num=dcz5, train_loss=0.466, train_loss_reg=0.0145, validation_loss=0.0552]\n",
            "                                               \u001b[AEpoch 138, global step 1389: validation_loss was not in top 1\n",
            "Epoch 139:  52% 30/58 [00:05<00:04,  5.80it/s, loss=0.158, v_num=dcz5, train_loss=0.466, train_loss_reg=0.0145, validation_loss=0.0552]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.37it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 23.02it/s]\u001b[AEpoch 139, global step 1399: validation_loss was not in top 1\n",
            "Epoch 139: 100% 58/58 [00:07<00:00,  8.05it/s, loss=0.182, v_num=dcz5, train_loss=1.350, train_loss_reg=0.0729, validation_loss=0.0567]\n",
            "Epoch 140:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.182, v_num=dcz5, train_loss=1.350, train_loss_reg=0.0729, validation_loss=0.0567]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.57it/s]\u001b[A\n",
            "Epoch 140: 100% 58/58 [00:06<00:00,  8.32it/s, loss=0.15, v_num=dcz5, train_loss=0.00919, train_loss_reg=0.00542, validation_loss=0.0573]Epoch 140, global step 1409: validation_loss was not in top 1\n",
            "\n",
            "Epoch 141:  52% 30/58 [00:05<00:04,  5.88it/s, loss=0.15, v_num=dcz5, train_loss=0.00919, train_loss_reg=0.00542, validation_loss=0.0573]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.46it/s]\u001b[A\n",
            "Epoch 141: 100% 58/58 [00:06<00:00,  8.48it/s, loss=0.0778, v_num=dcz5, train_loss=0.125, train_loss_reg=0.000786, validation_loss=0.0566]\n",
            "Epoch 141: 100% 58/58 [00:06<00:00,  8.48it/s, loss=0.0778, v_num=dcz5, train_loss=0.125, train_loss_reg=0.000786, validation_loss=0.0566]Epoch 141, global step 1419: validation_loss was not in top 1\n",
            "Epoch 142:  52% 30/58 [00:05<00:04,  5.84it/s, loss=0.0778, v_num=dcz5, train_loss=0.125, train_loss_reg=0.000786, validation_loss=0.0566]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.81it/s]\u001b[A\n",
            "Epoch 142: 100% 58/58 [00:06<00:00,  8.47it/s, loss=0.145, v_num=dcz5, train_loss=0.596, train_loss_reg=0.0172, validation_loss=0.0641]   \n",
            "Epoch 142: 100% 58/58 [00:06<00:00,  8.47it/s, loss=0.145, v_num=dcz5, train_loss=0.596, train_loss_reg=0.0172, validation_loss=0.0641]Epoch 142, global step 1429: validation_loss was not in top 1\n",
            "Epoch 143:  52% 30/58 [00:05<00:04,  5.80it/s, loss=0.145, v_num=dcz5, train_loss=0.596, train_loss_reg=0.0172, validation_loss=0.0641]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.34it/s]\u001b[A\n",
            "Epoch 143: 100% 58/58 [00:06<00:00,  8.40it/s, loss=0.273, v_num=dcz5, train_loss=0.559, train_loss_reg=0.00497, validation_loss=0.0695]Epoch 143, global step 1439: validation_loss was not in top 1\n",
            "\n",
            "Epoch 144:  52% 30/58 [00:05<00:04,  5.82it/s, loss=0.273, v_num=dcz5, train_loss=0.559, train_loss_reg=0.00497, validation_loss=0.0695]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.62it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.18it/s]\u001b[AEpoch 144, global step 1449: validation_loss was not in top 1\n",
            "Epoch 144: 100% 58/58 [00:06<00:00,  8.44it/s, loss=0.305, v_num=dcz5, train_loss=1.040, train_loss_reg=0.0874, validation_loss=0.0693] \n",
            "Epoch 145:  52% 30/58 [00:05<00:04,  5.81it/s, loss=0.305, v_num=dcz5, train_loss=1.040, train_loss_reg=0.0874, validation_loss=0.0693]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.53it/s]\u001b[A\n",
            "Epoch 145: 100% 58/58 [00:07<00:00,  7.98it/s, loss=0.248, v_num=dcz5, train_loss=0.157, train_loss_reg=0.00608, validation_loss=0.0785]Epoch 145, global step 1459: validation_loss was not in top 1\n",
            "\n",
            "Epoch 146:  52% 30/58 [00:05<00:04,  5.84it/s, loss=0.248, v_num=dcz5, train_loss=0.157, train_loss_reg=0.00608, validation_loss=0.0785]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.78it/s]\u001b[A\n",
            "Epoch 146: 100% 58/58 [00:07<00:00,  8.01it/s, loss=0.276, v_num=dcz5, train_loss=0.402, train_loss_reg=0.0118, validation_loss=0.0718] Epoch 146, global step 1469: validation_loss was not in top 1\n",
            "\n",
            "Epoch 147:  52% 30/58 [00:05<00:04,  5.81it/s, loss=0.276, v_num=dcz5, train_loss=0.402, train_loss_reg=0.0118, validation_loss=0.0718]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.37it/s]\u001b[A\n",
            "Epoch 147: 100% 58/58 [00:07<00:00,  7.96it/s, loss=0.282, v_num=dcz5, train_loss=0.647, train_loss_reg=0.0158, validation_loss=0.0705]Epoch 147, global step 1479: validation_loss was not in top 1\n",
            "\n",
            "Epoch 148:  52% 30/58 [00:05<00:04,  5.79it/s, loss=0.282, v_num=dcz5, train_loss=0.647, train_loss_reg=0.0158, validation_loss=0.0705]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.47it/s]\u001b[A\n",
            "Epoch 148: 100% 58/58 [00:06<00:00,  8.38it/s, loss=0.277, v_num=dcz5, train_loss=1.090, train_loss_reg=0.126, validation_loss=0.0722] Epoch 148, global step 1489: validation_loss was not in top 1\n",
            "\n",
            "Epoch 149:  52% 30/58 [00:05<00:04,  5.77it/s, loss=0.277, v_num=dcz5, train_loss=1.090, train_loss_reg=0.126, validation_loss=0.0722]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.39it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.18it/s]\u001b[AEpoch 149, global step 1499: validation_loss was not in top 1\n",
            "Epoch 149: 100% 58/58 [00:06<00:00,  8.38it/s, loss=0.286, v_num=dcz5, train_loss=0.840, train_loss_reg=0.182, validation_loss=0.0651]\n",
            "Epoch 150:  52% 30/58 [00:05<00:04,  5.84it/s, loss=0.286, v_num=dcz5, train_loss=0.840, train_loss_reg=0.182, validation_loss=0.0651]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.67it/s]\u001b[A\n",
            "Epoch 150: 100% 58/58 [00:07<00:00,  8.00it/s, loss=0.188, v_num=dcz5, train_loss=0.017, train_loss_reg=0.00667, validation_loss=0.0663]\n",
            "Epoch 150: 100% 58/58 [00:07<00:00,  7.99it/s, loss=0.188, v_num=dcz5, train_loss=0.017, train_loss_reg=0.00667, validation_loss=0.0663]Epoch 150, global step 1509: validation_loss was not in top 1\n",
            "Epoch 151:  52% 30/58 [00:05<00:04,  5.80it/s, loss=0.188, v_num=dcz5, train_loss=0.017, train_loss_reg=0.00667, validation_loss=0.0663]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.34it/s]\u001b[A\n",
            "Epoch 151: 100% 58/58 [00:07<00:00,  7.95it/s, loss=0.143, v_num=dcz5, train_loss=0.685, train_loss_reg=0.0197, validation_loss=0.0712] Epoch 151, global step 1519: validation_loss was not in top 1\n",
            "\n",
            "Epoch 152:  52% 30/58 [00:05<00:04,  5.89it/s, loss=0.143, v_num=dcz5, train_loss=0.685, train_loss_reg=0.0197, validation_loss=0.0712]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.61it/s]\u001b[A\n",
            "Epoch 152: 100% 58/58 [00:07<00:00,  8.04it/s, loss=0.117, v_num=dcz5, train_loss=0.0534, train_loss_reg=0.0258, validation_loss=0.0744]Epoch 152, global step 1529: validation_loss was not in top 1\n",
            "\n",
            "Epoch 153:  52% 30/58 [00:05<00:04,  5.88it/s, loss=0.117, v_num=dcz5, train_loss=0.0534, train_loss_reg=0.0258, validation_loss=0.0744]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.60it/s]\u001b[A\n",
            "Epoch 153: 100% 58/58 [00:06<00:00,  8.49it/s, loss=0.0627, v_num=dcz5, train_loss=0.00162, train_loss_reg=0.00162, validation_loss=0.0708]\n",
            "Epoch 153:   0% 0/58 [00:00<?, ?it/s, loss=0.0627, v_num=dcz5, train_loss=0.00162, train_loss_reg=0.00162, validation_loss=0.0708]         Epoch 153, global step 1539: validation_loss was not in top 1\n",
            "Epoch 154:  52% 30/58 [00:05<00:04,  5.92it/s, loss=0.0627, v_num=dcz5, train_loss=0.00162, train_loss_reg=0.00162, validation_loss=0.0708]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.62it/s]\u001b[A\n",
            "Epoch 154: 100% 58/58 [00:07<00:00,  8.08it/s, loss=0.155, v_num=dcz5, train_loss=1.640, train_loss_reg=0.0818, validation_loss=0.0667]    \n",
            "Epoch 154: 100% 58/58 [00:07<00:00,  8.08it/s, loss=0.155, v_num=dcz5, train_loss=1.640, train_loss_reg=0.0818, validation_loss=0.0667]Epoch 154, global step 1549: validation_loss was not in top 1\n",
            "Epoch 155:  52% 30/58 [00:05<00:04,  5.85it/s, loss=0.155, v_num=dcz5, train_loss=1.640, train_loss_reg=0.0818, validation_loss=0.0667]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.63it/s]\u001b[A\n",
            "Epoch 155: 100% 58/58 [00:06<00:00,  8.46it/s, loss=0.193, v_num=dcz5, train_loss=0.407, train_loss_reg=0.017, validation_loss=0.0844] Epoch 155, global step 1559: validation_loss was not in top 1\n",
            "\n",
            "Epoch 156:  52% 30/58 [00:05<00:04,  5.87it/s, loss=0.193, v_num=dcz5, train_loss=0.407, train_loss_reg=0.017, validation_loss=0.0844]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.58it/s]\u001b[A\n",
            "Epoch 156: 100% 58/58 [00:07<00:00,  8.03it/s, loss=0.143, v_num=dcz5, train_loss=0.0421, train_loss_reg=0.00751, validation_loss=0.0627]Epoch 156, global step 1569: validation_loss was not in top 1\n",
            "\n",
            "Epoch 157:  52% 30/58 [00:05<00:04,  5.90it/s, loss=0.143, v_num=dcz5, train_loss=0.0421, train_loss_reg=0.00751, validation_loss=0.0627]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.76it/s]\u001b[A\n",
            "Epoch 157: 100% 58/58 [00:06<00:00,  8.51it/s, loss=0.0866, v_num=dcz5, train_loss=0.00476, train_loss_reg=0.00476, validation_loss=0.0608]\n",
            "Epoch 158:   0% 0/58 [00:00<?, ?it/s, loss=0.0866, v_num=dcz5, train_loss=0.00476, train_loss_reg=0.00476, validation_loss=0.0608]Epoch 157, global step 1579: validation_loss was not in top 1\n",
            "Epoch 158:  52% 30/58 [00:05<00:04,  5.88it/s, loss=0.0866, v_num=dcz5, train_loss=0.00476, train_loss_reg=0.00476, validation_loss=0.0608]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.41it/s]\u001b[A\n",
            "Epoch 158: 100% 58/58 [00:06<00:00,  8.49it/s, loss=0.0669, v_num=dcz5, train_loss=0.0117, train_loss_reg=0.00414, validation_loss=0.0585] Epoch 158, global step 1589: validation_loss was not in top 1\n",
            "\n",
            "Epoch 159:  52% 30/58 [00:05<00:04,  5.89it/s, loss=0.0669, v_num=dcz5, train_loss=0.0117, train_loss_reg=0.00414, validation_loss=0.0585]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.22it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 22.21it/s]\u001b[AEpoch 159, global step 1599: validation_loss was not in top 1\n",
            "Epoch 159: 100% 58/58 [00:07<00:00,  8.06it/s, loss=0.126, v_num=dcz5, train_loss=0.674, train_loss_reg=0.0231, validation_loss=0.0584]   \n",
            "Epoch 160:  52% 30/58 [00:05<00:04,  5.89it/s, loss=0.126, v_num=dcz5, train_loss=0.674, train_loss_reg=0.0231, validation_loss=0.0584]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.63it/s]\u001b[A\n",
            "Epoch 160: 100% 58/58 [00:06<00:00,  8.51it/s, loss=0.137, v_num=dcz5, train_loss=0.513, train_loss_reg=0.012, validation_loss=0.0884] \n",
            "Epoch 161:   0% 0/58 [00:00<?, ?it/s, loss=0.137, v_num=dcz5, train_loss=0.513, train_loss_reg=0.012, validation_loss=0.0884]Epoch 160, global step 1609: validation_loss was not in top 1\n",
            "Epoch 161:  52% 30/58 [00:05<00:04,  5.88it/s, loss=0.137, v_num=dcz5, train_loss=0.513, train_loss_reg=0.012, validation_loss=0.0884]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.53it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.29it/s]\u001b[AEpoch 161, global step 1619: validation_loss was not in top 1\n",
            "Epoch 161: 100% 58/58 [00:06<00:00,  8.51it/s, loss=0.163, v_num=dcz5, train_loss=0.518, train_loss_reg=0.0101, validation_loss=0.0629]\n",
            "Epoch 162:  52% 30/58 [00:05<00:04,  5.92it/s, loss=0.163, v_num=dcz5, train_loss=0.518, train_loss_reg=0.0101, validation_loss=0.0629]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.82it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.38it/s]\u001b[AEpoch 162, global step 1629: validation_loss was not in top 1\n",
            "Epoch 162: 100% 58/58 [00:06<00:00,  8.56it/s, loss=0.146, v_num=dcz5, train_loss=0.116, train_loss_reg=0.0203, validation_loss=0.0631]\n",
            "Epoch 163:  52% 30/58 [00:05<00:04,  5.94it/s, loss=0.146, v_num=dcz5, train_loss=0.116, train_loss_reg=0.0203, validation_loss=0.0631]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.49it/s]\u001b[A\n",
            "Epoch 163: 100% 58/58 [00:06<00:00,  8.56it/s, loss=0.127, v_num=dcz5, train_loss=1.130, train_loss_reg=0.0587, validation_loss=0.0568]Epoch 163, global step 1639: validation_loss was not in top 1\n",
            "\n",
            "Epoch 164:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.127, v_num=dcz5, train_loss=1.130, train_loss_reg=0.0587, validation_loss=0.0568]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.61it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 22.09it/s]\u001b[AEpoch 164, global step 1649: validation_loss was not in top 1\n",
            "Epoch 164: 100% 58/58 [00:07<00:00,  8.08it/s, loss=0.105, v_num=dcz5, train_loss=0.0264, train_loss_reg=0.0198, validation_loss=0.0578]\n",
            "Epoch 165:  52% 30/58 [00:05<00:04,  5.88it/s, loss=0.105, v_num=dcz5, train_loss=0.0264, train_loss_reg=0.0198, validation_loss=0.0578]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.54it/s]\u001b[A\n",
            "Epoch 165: 100% 58/58 [00:06<00:00,  8.50it/s, loss=0.107, v_num=dcz5, train_loss=0.202, train_loss_reg=0.00645, validation_loss=0.0579]Epoch 165, global step 1659: validation_loss was not in top 1\n",
            "\n",
            "Epoch 166:  52% 30/58 [00:05<00:04,  5.93it/s, loss=0.107, v_num=dcz5, train_loss=0.202, train_loss_reg=0.00645, validation_loss=0.0579]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.72it/s]\u001b[A\n",
            "Epoch 166: 100% 58/58 [00:06<00:00,  8.57it/s, loss=0.104, v_num=dcz5, train_loss=0.266, train_loss_reg=0.0016, validation_loss=0.0617] Epoch 166, global step 1669: validation_loss was not in top 1\n",
            "\n",
            "Epoch 167:  52% 30/58 [00:05<00:04,  5.94it/s, loss=0.104, v_num=dcz5, train_loss=0.266, train_loss_reg=0.0016, validation_loss=0.0617]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.56it/s]\u001b[A\n",
            "Epoch 167: 100% 58/58 [00:06<00:00,  8.56it/s, loss=0.0474, v_num=dcz5, train_loss=0.291, train_loss_reg=0.0173, validation_loss=0.0579]\n",
            "Epoch 167:   0% 0/58 [00:00<?, ?it/s, loss=0.0474, v_num=dcz5, train_loss=0.291, train_loss_reg=0.0173, validation_loss=0.0579]         Epoch 167, global step 1679: validation_loss was not in top 1\n",
            "Epoch 168:  52% 30/58 [00:05<00:04,  5.98it/s, loss=0.0474, v_num=dcz5, train_loss=0.291, train_loss_reg=0.0173, validation_loss=0.0579]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.72it/s]\u001b[A\n",
            "Epoch 168: 100% 58/58 [00:06<00:00,  8.61it/s, loss=0.0457, v_num=dcz5, train_loss=0.0395, train_loss_reg=0.00605, validation_loss=0.061]Epoch 168, global step 1689: validation_loss was not in top 1\n",
            "\n",
            "Epoch 169:  52% 30/58 [00:05<00:04,  5.97it/s, loss=0.0457, v_num=dcz5, train_loss=0.0395, train_loss_reg=0.00605, validation_loss=0.061]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.31it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 21.97it/s]\u001b[AEpoch 169, global step 1699: validation_loss was not in top 1\n",
            "Epoch 169: 100% 58/58 [00:07<00:00,  8.12it/s, loss=0.076, v_num=dcz5, train_loss=0.0788, train_loss_reg=0.00851, validation_loss=0.0584]\n",
            "Epoch 170:  52% 30/58 [00:05<00:04,  5.94it/s, loss=0.076, v_num=dcz5, train_loss=0.0788, train_loss_reg=0.00851, validation_loss=0.0584]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.56it/s]\u001b[A\n",
            "Epoch 170: 100% 58/58 [00:06<00:00,  8.57it/s, loss=0.0838, v_num=dcz5, train_loss=0.188, train_loss_reg=0.0134, validation_loss=0.0573] Epoch 170, global step 1709: validation_loss was not in top 1\n",
            "\n",
            "Epoch 171:  52% 30/58 [00:05<00:04,  5.93it/s, loss=0.0838, v_num=dcz5, train_loss=0.188, train_loss_reg=0.0134, validation_loss=0.0573]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.36it/s]\u001b[A\n",
            "Epoch 171: 100% 58/58 [00:07<00:00,  8.08it/s, loss=0.0589, v_num=dcz5, train_loss=0.0437, train_loss_reg=0.00961, validation_loss=0.0609]Epoch 171, global step 1719: validation_loss was not in top 1\n",
            "\n",
            "Epoch 172:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.0589, v_num=dcz5, train_loss=0.0437, train_loss_reg=0.00961, validation_loss=0.0609]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.44it/s]\u001b[A\n",
            "Epoch 172: 100% 58/58 [00:06<00:00,  8.52it/s, loss=0.06, v_num=dcz5, train_loss=0.00838, train_loss_reg=0.00838, validation_loss=0.0594] \n",
            "Epoch 172: 100% 58/58 [00:06<00:00,  8.52it/s, loss=0.06, v_num=dcz5, train_loss=0.00838, train_loss_reg=0.00838, validation_loss=0.0594]Epoch 172, global step 1729: validation_loss was not in top 1\n",
            "Epoch 173:  52% 30/58 [00:05<00:04,  5.92it/s, loss=0.06, v_num=dcz5, train_loss=0.00838, train_loss_reg=0.00838, validation_loss=0.0594]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.72it/s]\u001b[A\n",
            "Epoch 173: 100% 58/58 [00:06<00:00,  8.54it/s, loss=0.0547, v_num=dcz5, train_loss=0.0813, train_loss_reg=0.0113, validation_loss=0.0582]\n",
            "Epoch 173: 100% 58/58 [00:06<00:00,  8.54it/s, loss=0.0547, v_num=dcz5, train_loss=0.0813, train_loss_reg=0.0113, validation_loss=0.0582]Epoch 173, global step 1739: validation_loss was not in top 1\n",
            "Epoch 174:  52% 30/58 [00:05<00:04,  5.92it/s, loss=0.0547, v_num=dcz5, train_loss=0.0813, train_loss_reg=0.0113, validation_loss=0.0582]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.53it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.01it/s]\u001b[AEpoch 174, global step 1749: validation_loss was not in top 1\n",
            "Epoch 174: 100% 58/58 [00:06<00:00,  8.53it/s, loss=0.0439, v_num=dcz5, train_loss=0.0366, train_loss_reg=0.0165, validation_loss=0.0564]\n",
            "Epoch 175:  52% 30/58 [00:05<00:04,  5.92it/s, loss=0.0439, v_num=dcz5, train_loss=0.0366, train_loss_reg=0.0165, validation_loss=0.0564]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.39it/s]\u001b[A\n",
            "Epoch 175: 100% 58/58 [00:06<00:00,  8.53it/s, loss=0.0809, v_num=dcz5, train_loss=0.775, train_loss_reg=0.0692, validation_loss=0.0659] Epoch 175, global step 1759: validation_loss was not in top 1\n",
            "\n",
            "Epoch 176:  52% 30/58 [00:05<00:04,  5.81it/s, loss=0.0809, v_num=dcz5, train_loss=0.775, train_loss_reg=0.0692, validation_loss=0.0659]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.54it/s]\u001b[A\n",
            "Epoch 176: 100% 58/58 [00:07<00:00,  7.97it/s, loss=0.201, v_num=dcz5, train_loss=0.564, train_loss_reg=0.0133, validation_loss=0.0728] \n",
            "Epoch 176: 100% 58/58 [00:07<00:00,  7.97it/s, loss=0.201, v_num=dcz5, train_loss=0.564, train_loss_reg=0.0133, validation_loss=0.0728]Epoch 176, global step 1769: validation_loss was not in top 1\n",
            "Epoch 177:  52% 30/58 [00:05<00:04,  5.76it/s, loss=0.201, v_num=dcz5, train_loss=0.564, train_loss_reg=0.0133, validation_loss=0.0728]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.50it/s]\u001b[A\n",
            "Epoch 177: 100% 58/58 [00:07<00:00,  7.91it/s, loss=0.356, v_num=dcz5, train_loss=0.841, train_loss_reg=0.0774, validation_loss=0.106] Epoch 177, global step 1779: validation_loss was not in top 1\n",
            "\n",
            "Epoch 178:  52% 30/58 [00:05<00:04,  5.74it/s, loss=0.356, v_num=dcz5, train_loss=0.841, train_loss_reg=0.0774, validation_loss=0.106]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.95it/s]\u001b[A\n",
            "Epoch 178: 100% 58/58 [00:06<00:00,  8.37it/s, loss=0.413, v_num=dcz5, train_loss=1.310, train_loss_reg=0.0599, validation_loss=0.087]Epoch 178, global step 1789: validation_loss was not in top 1\n",
            "\n",
            "Epoch 179:  52% 30/58 [00:05<00:04,  5.82it/s, loss=0.413, v_num=dcz5, train_loss=1.310, train_loss_reg=0.0599, validation_loss=0.087]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.19it/s]\u001b[A\n",
            "Epoch 179: 100% 58/58 [00:06<00:00,  8.32it/s, loss=0.396, v_num=dcz5, train_loss=0.999, train_loss_reg=0.0257, validation_loss=0.0829]Epoch 179, global step 1799: validation_loss was not in top 1\n",
            "\n",
            "Epoch 180:  52% 30/58 [00:05<00:04,  5.85it/s, loss=0.396, v_num=dcz5, train_loss=0.999, train_loss_reg=0.0257, validation_loss=0.0829]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.73it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 25.81it/s]\u001b[AEpoch 180, global step 1809: validation_loss was not in top 1\n",
            "Epoch 180: 100% 58/58 [00:06<00:00,  8.31it/s, loss=0.272, v_num=dcz5, train_loss=0.0462, train_loss_reg=0.0461, validation_loss=0.0694]\n",
            "Epoch 181:  52% 30/58 [00:05<00:04,  5.90it/s, loss=0.272, v_num=dcz5, train_loss=0.0462, train_loss_reg=0.0461, validation_loss=0.0694]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.60it/s]\u001b[A\n",
            "Epoch 181: 100% 58/58 [00:06<00:00,  8.32it/s, loss=0.137, v_num=dcz5, train_loss=0.130, train_loss_reg=0.00948, validation_loss=0.0782]\n",
            "Epoch 181:   0% 0/58 [00:00<?, ?it/s, loss=0.137, v_num=dcz5, train_loss=0.130, train_loss_reg=0.00948, validation_loss=0.0782]         Epoch 181, global step 1819: validation_loss was not in top 1\n",
            "Epoch 182:  52% 30/58 [00:05<00:04,  5.86it/s, loss=0.137, v_num=dcz5, train_loss=0.130, train_loss_reg=0.00948, validation_loss=0.0782]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.59it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 27.95it/s]\u001b[AEpoch 182, global step 1829: validation_loss was not in top 1\n",
            "Epoch 182: 100% 58/58 [00:06<00:00,  8.46it/s, loss=0.14, v_num=dcz5, train_loss=0.435, train_loss_reg=0.0024, validation_loss=0.0788]  \n",
            "Epoch 183:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.14, v_num=dcz5, train_loss=0.435, train_loss_reg=0.0024, validation_loss=0.0788]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.51it/s]\u001b[A\n",
            "Epoch 183: 100% 58/58 [00:06<00:00,  8.35it/s, loss=0.126, v_num=dcz5, train_loss=0.153, train_loss_reg=0.00259, validation_loss=0.0682]Epoch 183, global step 1839: validation_loss was not in top 1\n",
            "\n",
            "Epoch 184:  52% 30/58 [00:05<00:04,  5.95it/s, loss=0.126, v_num=dcz5, train_loss=0.153, train_loss_reg=0.00259, validation_loss=0.0682]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.24it/s]\u001b[A\n",
            "Epoch 184: 100% 58/58 [00:07<00:00,  8.10it/s, loss=0.106, v_num=dcz5, train_loss=0.942, train_loss_reg=0.0117, validation_loss=0.0626] Epoch 184, global step 1849: validation_loss was not in top 1\n",
            "\n",
            "Epoch 185:  52% 30/58 [00:05<00:04,  5.84it/s, loss=0.106, v_num=dcz5, train_loss=0.942, train_loss_reg=0.0117, validation_loss=0.0626]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.41it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.18it/s]\u001b[AEpoch 185, global step 1859: validation_loss was not in top 1\n",
            "Epoch 185: 100% 58/58 [00:06<00:00,  8.45it/s, loss=0.208, v_num=dcz5, train_loss=0.907, train_loss_reg=0.00074, validation_loss=0.0652]\n",
            "Epoch 186:  52% 30/58 [00:05<00:04,  5.87it/s, loss=0.208, v_num=dcz5, train_loss=0.907, train_loss_reg=0.00074, validation_loss=0.0652]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.53it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 21.96it/s]\u001b[AEpoch 186, global step 1869: validation_loss was not in top 1\n",
            "Epoch 186: 100% 58/58 [00:07<00:00,  8.02it/s, loss=0.212, v_num=dcz5, train_loss=0.0658, train_loss_reg=0.00602, validation_loss=0.0647]\n",
            "Epoch 187:  52% 30/58 [00:05<00:04,  5.89it/s, loss=0.212, v_num=dcz5, train_loss=0.0658, train_loss_reg=0.00602, validation_loss=0.0647]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.67it/s]\u001b[A\n",
            "Epoch 187: 100% 58/58 [00:06<00:00,  8.51it/s, loss=0.113, v_num=dcz5, train_loss=0.559, train_loss_reg=0.0447, validation_loss=0.065]   Epoch 187, global step 1879: validation_loss was not in top 1\n",
            "\n",
            "Epoch 188:  52% 30/58 [00:05<00:04,  5.93it/s, loss=0.113, v_num=dcz5, train_loss=0.559, train_loss_reg=0.0447, validation_loss=0.065]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.73it/s]\u001b[A\n",
            "Epoch 188: 100% 58/58 [00:06<00:00,  8.55it/s, loss=0.0895, v_num=dcz5, train_loss=0.00114, train_loss_reg=0.00114, validation_loss=0.0598]Epoch 188, global step 1889: validation_loss was not in top 1\n",
            "\n",
            "Epoch 189:  52% 30/58 [00:05<00:04,  5.88it/s, loss=0.0895, v_num=dcz5, train_loss=0.00114, train_loss_reg=0.00114, validation_loss=0.0598]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.56it/s]\u001b[A\n",
            "Epoch 189: 100% 58/58 [00:07<00:00,  8.04it/s, loss=0.0937, v_num=dcz5, train_loss=0.523, train_loss_reg=0.00576, validation_loss=0.0568]  Epoch 189, global step 1899: validation_loss was not in top 1\n",
            "\n",
            "Epoch 190:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.0937, v_num=dcz5, train_loss=0.523, train_loss_reg=0.00576, validation_loss=0.0568]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.45it/s]\u001b[A\n",
            "Epoch 190: 100% 58/58 [00:07<00:00,  8.06it/s, loss=0.1, v_num=dcz5, train_loss=0.0345, train_loss_reg=0.0345, validation_loss=0.056]    Epoch 190, global step 1909: validation_loss was not in top 1\n",
            "\n",
            "Epoch 191:  52% 30/58 [00:05<00:04,  5.84it/s, loss=0.1, v_num=dcz5, train_loss=0.0345, train_loss_reg=0.0345, validation_loss=0.056]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.81it/s]\u001b[A\n",
            "Epoch 191: 100% 58/58 [00:06<00:00,  8.47it/s, loss=0.0739, v_num=dcz5, train_loss=0.151, train_loss_reg=0.00467, validation_loss=0.0567]Epoch 191, global step 1919: validation_loss was not in top 1\n",
            "\n",
            "Epoch 192:  52% 30/58 [00:05<00:04,  5.90it/s, loss=0.0739, v_num=dcz5, train_loss=0.151, train_loss_reg=0.00467, validation_loss=0.0567]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.52it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.18it/s]\u001b[AEpoch 192, global step 1929: validation_loss was not in top 1\n",
            "Epoch 192: 100% 58/58 [00:06<00:00,  8.52it/s, loss=0.0518, v_num=dcz5, train_loss=0.108, train_loss_reg=0.0223, validation_loss=0.057]  \n",
            "Epoch 193:  52% 30/58 [00:05<00:04,  5.96it/s, loss=0.0518, v_num=dcz5, train_loss=0.108, train_loss_reg=0.0223, validation_loss=0.057]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.40it/s]\u001b[A\n",
            "Epoch 193: 100% 58/58 [00:07<00:00,  8.10it/s, loss=0.0475, v_num=dcz5, train_loss=0.134, train_loss_reg=0.0163, validation_loss=0.0626]Epoch 193, global step 1939: validation_loss was not in top 1\n",
            "\n",
            "Epoch 194:  52% 30/58 [00:05<00:04,  5.94it/s, loss=0.0475, v_num=dcz5, train_loss=0.134, train_loss_reg=0.0163, validation_loss=0.0626]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.62it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 23.06it/s]\u001b[AEpoch 194, global step 1949: validation_loss was not in top 1\n",
            "Epoch 194: 100% 58/58 [00:07<00:00,  8.19it/s, loss=0.0551, v_num=dcz5, train_loss=0.268, train_loss_reg=0.00378, validation_loss=0.0649]\n",
            "Epoch 195:  52% 30/58 [00:04<00:04,  6.01it/s, loss=0.0551, v_num=dcz5, train_loss=0.268, train_loss_reg=0.00378, validation_loss=0.0649]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.65it/s]\u001b[A\n",
            "Epoch 195: 100% 58/58 [00:07<00:00,  8.17it/s, loss=0.0629, v_num=dcz5, train_loss=0.0222, train_loss_reg=0.0222, validation_loss=0.0599]\n",
            "Epoch 195:   0% 0/58 [00:00<?, ?it/s, loss=0.0629, v_num=dcz5, train_loss=0.0222, train_loss_reg=0.0222, validation_loss=0.0599]         Epoch 195, global step 1959: validation_loss was not in top 1\n",
            "Epoch 196:  52% 30/58 [00:05<00:04,  5.95it/s, loss=0.0629, v_num=dcz5, train_loss=0.0222, train_loss_reg=0.0222, validation_loss=0.0599]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.49it/s]\u001b[A\n",
            "Epoch 196: 100% 58/58 [00:06<00:00,  8.57it/s, loss=0.082, v_num=dcz5, train_loss=0.522, train_loss_reg=0.0408, validation_loss=0.061]   Epoch 196, global step 1969: validation_loss was not in top 1\n",
            "\n",
            "Epoch 197:  52% 30/58 [00:05<00:04,  5.87it/s, loss=0.082, v_num=dcz5, train_loss=0.522, train_loss_reg=0.0408, validation_loss=0.061]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.73it/s]\u001b[A\n",
            "Epoch 197: 100% 58/58 [00:06<00:00,  8.49it/s, loss=0.142, v_num=dcz5, train_loss=0.330, train_loss_reg=0.038, validation_loss=0.0598]Epoch 197, global step 1979: validation_loss was not in top 1\n",
            "\n",
            "Epoch 198:  52% 30/58 [00:05<00:04,  5.84it/s, loss=0.142, v_num=dcz5, train_loss=0.330, train_loss_reg=0.038, validation_loss=0.0598]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.72it/s]\u001b[A\n",
            "Epoch 198: 100% 58/58 [00:07<00:00,  8.00it/s, loss=0.192, v_num=dcz5, train_loss=0.396, train_loss_reg=0.00648, validation_loss=0.0564]\n",
            "Epoch 198: 100% 58/58 [00:07<00:00,  8.00it/s, loss=0.192, v_num=dcz5, train_loss=0.396, train_loss_reg=0.00648, validation_loss=0.0564]Epoch 198, global step 1989: validation_loss was not in top 1\n",
            "Epoch 199:  52% 30/58 [00:05<00:04,  5.85it/s, loss=0.192, v_num=dcz5, train_loss=0.396, train_loss_reg=0.00648, validation_loss=0.0564]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.21it/s]\u001b[A\n",
            "Epoch 199: 100% 58/58 [00:07<00:00,  8.00it/s, loss=0.181, v_num=dcz5, train_loss=0.863, train_loss_reg=0.0384, validation_loss=0.0495] Epoch 199, global step 1999: validation_loss was not in top 1\n",
            "\n",
            "Epoch 200:  52% 30/58 [00:05<00:04,  5.87it/s, loss=0.181, v_num=dcz5, train_loss=0.863, train_loss_reg=0.0384, validation_loss=0.0495]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.29it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 21.94it/s]\u001b[AEpoch 200, global step 2009: validation_loss was not in top 1\n",
            "Epoch 200: 100% 58/58 [00:07<00:00,  8.02it/s, loss=0.258, v_num=dcz5, train_loss=2.880, train_loss_reg=0.0611, validation_loss=0.0544]\n",
            "Epoch 201:  52% 30/58 [00:05<00:04,  5.85it/s, loss=0.258, v_num=dcz5, train_loss=2.880, train_loss_reg=0.0611, validation_loss=0.0544]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.27it/s]\u001b[A\n",
            "Epoch 201: 100% 58/58 [00:06<00:00,  8.46it/s, loss=0.25, v_num=dcz5, train_loss=0.438, train_loss_reg=0.0331, validation_loss=0.0501] Epoch 201, global step 2019: validation_loss was not in top 1\n",
            "\n",
            "Epoch 202:  52% 30/58 [00:05<00:04,  5.92it/s, loss=0.25, v_num=dcz5, train_loss=0.438, train_loss_reg=0.0331, validation_loss=0.0501]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.64it/s]\u001b[A\n",
            "Epoch 202: 100% 58/58 [00:07<00:00,  8.08it/s, loss=0.152, v_num=dcz5, train_loss=0.673, train_loss_reg=0.0395, validation_loss=0.0591]Epoch 202, global step 2029: validation_loss was not in top 1\n",
            "\n",
            "Epoch 203:  52% 30/58 [00:05<00:04,  5.88it/s, loss=0.152, v_num=dcz5, train_loss=0.673, train_loss_reg=0.0395, validation_loss=0.0591]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.13it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 26.11it/s]\u001b[AEpoch 203, global step 2039: validation_loss was not in top 1\n",
            "Epoch 203: 100% 58/58 [00:06<00:00,  8.35it/s, loss=0.118, v_num=dcz5, train_loss=0.354, train_loss_reg=0.0306, validation_loss=0.0622]\n",
            "Epoch 204:  52% 30/58 [00:05<00:04,  5.89it/s, loss=0.118, v_num=dcz5, train_loss=0.354, train_loss_reg=0.0306, validation_loss=0.0622]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.62it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 21.96it/s]\u001b[AEpoch 204, global step 2049: validation_loss was not in top 1\n",
            "Epoch 204: 100% 58/58 [00:07<00:00,  8.04it/s, loss=0.0864, v_num=dcz5, train_loss=0.141, train_loss_reg=0.0148, validation_loss=0.0603]\n",
            "Epoch 205:  52% 30/58 [00:05<00:04,  5.87it/s, loss=0.0864, v_num=dcz5, train_loss=0.141, train_loss_reg=0.0148, validation_loss=0.0603]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.52it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 25.04it/s]\u001b[AEpoch 205, global step 2059: validation_loss was not in top 1\n",
            "Epoch 205: 100% 58/58 [00:07<00:00,  8.28it/s, loss=0.0723, v_num=dcz5, train_loss=0.00681, train_loss_reg=0.00681, validation_loss=0.0582]\n",
            "Epoch 206:  52% 30/58 [00:05<00:04,  5.92it/s, loss=0.0723, v_num=dcz5, train_loss=0.00681, train_loss_reg=0.00681, validation_loss=0.0582]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.74it/s]\u001b[A\n",
            "Epoch 206: 100% 58/58 [00:07<00:00,  8.07it/s, loss=0.0441, v_num=dcz5, train_loss=0.000535, train_loss_reg=0.000535, validation_loss=0.0534]Epoch 206, global step 2069: validation_loss was not in top 1\n",
            "\n",
            "Epoch 207:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.0441, v_num=dcz5, train_loss=0.000535, train_loss_reg=0.000535, validation_loss=0.0534]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.53it/s]\u001b[A\n",
            "Epoch 207: 100% 58/58 [00:06<00:00,  8.53it/s, loss=0.0295, v_num=dcz5, train_loss=0.00177, train_loss_reg=0.00177, validation_loss=0.0528]  Epoch 207, global step 2079: validation_loss was not in top 1\n",
            "\n",
            "Epoch 208:  52% 30/58 [00:05<00:04,  5.95it/s, loss=0.0295, v_num=dcz5, train_loss=0.00177, train_loss_reg=0.00177, validation_loss=0.0528]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.47it/s]\u001b[A\n",
            "Epoch 208: 100% 58/58 [00:07<00:00,  8.10it/s, loss=0.0432, v_num=dcz5, train_loss=0.00363, train_loss_reg=0.00363, validation_loss=0.057] \n",
            "Epoch 208: 100% 58/58 [00:07<00:00,  8.10it/s, loss=0.0432, v_num=dcz5, train_loss=0.00363, train_loss_reg=0.00363, validation_loss=0.057]Epoch 208, global step 2089: validation_loss was not in top 1\n",
            "Epoch 209:  52% 30/58 [00:05<00:04,  5.90it/s, loss=0.0432, v_num=dcz5, train_loss=0.00363, train_loss_reg=0.00363, validation_loss=0.057]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.47it/s]\u001b[A\n",
            "Epoch 209: 100% 58/58 [00:06<00:00,  8.41it/s, loss=0.0999, v_num=dcz5, train_loss=0.404, train_loss_reg=0.00527, validation_loss=0.0523] Epoch 209, global step 2099: validation_loss was not in top 1\n",
            "\n",
            "Epoch 210:  52% 30/58 [00:05<00:04,  5.94it/s, loss=0.0999, v_num=dcz5, train_loss=0.404, train_loss_reg=0.00527, validation_loss=0.0523]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.56it/s]\u001b[A\n",
            "Epoch 210: 100% 58/58 [00:06<00:00,  8.57it/s, loss=0.108, v_num=dcz5, train_loss=0.497, train_loss_reg=0.00284, validation_loss=0.0559] Epoch 210, global step 2109: validation_loss was not in top 1\n",
            "\n",
            "Epoch 211:  52% 30/58 [00:05<00:04,  5.93it/s, loss=0.108, v_num=dcz5, train_loss=0.497, train_loss_reg=0.00284, validation_loss=0.0559]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.46it/s]\u001b[A\n",
            "Epoch 211: 100% 58/58 [00:06<00:00,  8.39it/s, loss=0.0665, v_num=dcz5, train_loss=0.00677, train_loss_reg=0.00429, validation_loss=0.059]Epoch 211, global step 2119: validation_loss was not in top 1\n",
            "\n",
            "Epoch 212:  52% 30/58 [00:05<00:04,  5.88it/s, loss=0.0665, v_num=dcz5, train_loss=0.00677, train_loss_reg=0.00429, validation_loss=0.059]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.41it/s]\u001b[A\n",
            "Epoch 212: 100% 58/58 [00:06<00:00,  8.49it/s, loss=0.0813, v_num=dcz5, train_loss=0.00548, train_loss_reg=0.000192, validation_loss=0.0575]\n",
            "Epoch 212: 100% 58/58 [00:06<00:00,  8.49it/s, loss=0.0813, v_num=dcz5, train_loss=0.00548, train_loss_reg=0.000192, validation_loss=0.0575]Epoch 212, global step 2129: validation_loss was not in top 1\n",
            "Epoch 213:  52% 30/58 [00:05<00:04,  5.92it/s, loss=0.0813, v_num=dcz5, train_loss=0.00548, train_loss_reg=0.000192, validation_loss=0.0575]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.34it/s]\u001b[A\n",
            "Epoch 213: 100% 58/58 [00:06<00:00,  8.53it/s, loss=0.0804, v_num=dcz5, train_loss=0.356, train_loss_reg=0.0281, validation_loss=0.0512]    \n",
            "Epoch 213:   0% 0/58 [00:00<?, ?it/s, loss=0.0804, v_num=dcz5, train_loss=0.356, train_loss_reg=0.0281, validation_loss=0.0512]         Epoch 213, global step 2139: validation_loss was not in top 1\n",
            "Epoch 214:  52% 30/58 [00:05<00:04,  5.93it/s, loss=0.0804, v_num=dcz5, train_loss=0.356, train_loss_reg=0.0281, validation_loss=0.0512]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.67it/s]\u001b[A\n",
            "Epoch 214: 100% 58/58 [00:06<00:00,  8.56it/s, loss=0.0733, v_num=dcz5, train_loss=0.659, train_loss_reg=0.0334, validation_loss=0.051] Epoch 214, global step 2149: validation_loss was not in top 1\n",
            "\n",
            "Epoch 215:  52% 30/58 [00:05<00:04,  5.95it/s, loss=0.0733, v_num=dcz5, train_loss=0.659, train_loss_reg=0.0334, validation_loss=0.051]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.63it/s]\u001b[A\n",
            "Epoch 215: 100% 58/58 [00:06<00:00,  8.58it/s, loss=0.0867, v_num=dcz5, train_loss=0.180, train_loss_reg=0.0269, validation_loss=0.0706]\n",
            "Epoch 215:   0% 0/58 [00:00<?, ?it/s, loss=0.0867, v_num=dcz5, train_loss=0.180, train_loss_reg=0.0269, validation_loss=0.0706]         Epoch 215, global step 2159: validation_loss was not in top 1\n",
            "Epoch 216:  52% 30/58 [00:05<00:04,  5.95it/s, loss=0.0867, v_num=dcz5, train_loss=0.180, train_loss_reg=0.0269, validation_loss=0.0706]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.73it/s]\u001b[A\n",
            "Epoch 216: 100% 58/58 [00:06<00:00,  8.58it/s, loss=0.0599, v_num=dcz5, train_loss=0.0106, train_loss_reg=0.0106, validation_loss=0.0641]Epoch 216, global step 2169: validation_loss was not in top 1\n",
            "\n",
            "Epoch 217:  52% 30/58 [00:05<00:04,  5.98it/s, loss=0.0599, v_num=dcz5, train_loss=0.0106, train_loss_reg=0.0106, validation_loss=0.0641]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.47it/s]\u001b[A\n",
            "Epoch 217: 100% 58/58 [00:07<00:00,  8.15it/s, loss=0.0592, v_num=dcz5, train_loss=0.128, train_loss_reg=0.0202, validation_loss=0.0618] \n",
            "Epoch 217:   0% 0/58 [00:00<?, ?it/s, loss=0.0592, v_num=dcz5, train_loss=0.128, train_loss_reg=0.0202, validation_loss=0.0618]         Epoch 217, global step 2179: validation_loss was not in top 1\n",
            "Epoch 218:  52% 30/58 [00:05<00:04,  5.90it/s, loss=0.0592, v_num=dcz5, train_loss=0.128, train_loss_reg=0.0202, validation_loss=0.0618]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.79it/s]\u001b[A\n",
            "Epoch 218: 100% 58/58 [00:06<00:00,  8.52it/s, loss=0.0894, v_num=dcz5, train_loss=0.137, train_loss_reg=0.0015, validation_loss=0.0612]\n",
            "Epoch 218:   0% 0/58 [00:00<?, ?it/s, loss=0.0894, v_num=dcz5, train_loss=0.137, train_loss_reg=0.0015, validation_loss=0.0612]         Epoch 218, global step 2189: validation_loss was not in top 1\n",
            "Epoch 219:  52% 30/58 [00:04<00:04,  6.03it/s, loss=0.0894, v_num=dcz5, train_loss=0.137, train_loss_reg=0.0015, validation_loss=0.0612]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.75it/s]\u001b[A\n",
            "Epoch 219: 100% 58/58 [00:06<00:00,  8.66it/s, loss=0.071, v_num=dcz5, train_loss=0.156, train_loss_reg=0.00462, validation_loss=0.0605]Epoch 219, global step 2199: validation_loss was not in top 1\n",
            "\n",
            "Epoch 220:  52% 30/58 [00:04<00:04,  6.01it/s, loss=0.071, v_num=dcz5, train_loss=0.156, train_loss_reg=0.00462, validation_loss=0.0605]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.60it/s]\u001b[A\n",
            "Epoch 220: 100% 58/58 [00:06<00:00,  8.64it/s, loss=0.0623, v_num=dcz5, train_loss=0.426, train_loss_reg=0.00389, validation_loss=0.0591]Epoch 220, global step 2209: validation_loss was not in top 1\n",
            "\n",
            "Epoch 221:  52% 30/58 [00:05<00:04,  5.99it/s, loss=0.0623, v_num=dcz5, train_loss=0.426, train_loss_reg=0.00389, validation_loss=0.0591]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.67it/s]\u001b[A\n",
            "Epoch 221: 100% 58/58 [00:06<00:00,  8.62it/s, loss=0.114, v_num=dcz5, train_loss=1.090, train_loss_reg=0.0573, validation_loss=0.0655]  Epoch 221, global step 2219: validation_loss was not in top 1\n",
            "\n",
            "Epoch 222:  52% 30/58 [00:05<00:04,  5.95it/s, loss=0.114, v_num=dcz5, train_loss=1.090, train_loss_reg=0.0573, validation_loss=0.0655]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.40it/s]\u001b[A\n",
            "Epoch 222: 100% 58/58 [00:07<00:00,  8.10it/s, loss=0.11, v_num=dcz5, train_loss=0.120, train_loss_reg=0.0342, validation_loss=0.0689] \n",
            "Epoch 223:   0% 0/58 [00:00<?, ?it/s, loss=0.11, v_num=dcz5, train_loss=0.120, train_loss_reg=0.0342, validation_loss=0.0689]Epoch 222, global step 2229: validation_loss was not in top 1\n",
            "Epoch 223:  52% 30/58 [00:05<00:04,  5.90it/s, loss=0.11, v_num=dcz5, train_loss=0.120, train_loss_reg=0.0342, validation_loss=0.0689]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.57it/s]\u001b[A\n",
            "Epoch 223: 100% 58/58 [00:07<00:00,  8.06it/s, loss=0.113, v_num=dcz5, train_loss=1.010, train_loss_reg=0.0512, validation_loss=0.0659]\n",
            "Epoch 223:   0% 0/58 [00:00<?, ?it/s, loss=0.113, v_num=dcz5, train_loss=1.010, train_loss_reg=0.0512, validation_loss=0.0659]         Epoch 223, global step 2239: validation_loss was not in top 1\n",
            "Epoch 224:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.113, v_num=dcz5, train_loss=1.010, train_loss_reg=0.0512, validation_loss=0.0659]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.35it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 21.87it/s]\u001b[AEpoch 224, global step 2249: validation_loss was not in top 1\n",
            "Epoch 224: 100% 58/58 [00:07<00:00,  8.05it/s, loss=0.221, v_num=dcz5, train_loss=2.030, train_loss_reg=0.092, validation_loss=0.0609] \n",
            "Epoch 225:  52% 30/58 [00:05<00:04,  5.85it/s, loss=0.221, v_num=dcz5, train_loss=2.030, train_loss_reg=0.092, validation_loss=0.0609]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.40it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 21.92it/s]\u001b[AEpoch 225, global step 2259: validation_loss was not in top 1\n",
            "Epoch 225: 100% 58/58 [00:07<00:00,  8.00it/s, loss=0.193, v_num=dcz5, train_loss=0.351, train_loss_reg=0.0516, validation_loss=0.059]\n",
            "Epoch 226:  52% 30/58 [00:05<00:04,  5.84it/s, loss=0.193, v_num=dcz5, train_loss=0.351, train_loss_reg=0.0516, validation_loss=0.059]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.45it/s]\u001b[A\n",
            "Epoch 226: 100% 58/58 [00:07<00:00,  8.00it/s, loss=0.175, v_num=dcz5, train_loss=1.530, train_loss_reg=0.0331, validation_loss=0.0531]\n",
            "Epoch 227:   0% 0/58 [00:00<?, ?it/s, loss=0.175, v_num=dcz5, train_loss=1.530, train_loss_reg=0.0331, validation_loss=0.0531]Epoch 226, global step 2269: validation_loss was not in top 1\n",
            "Epoch 227:  52% 30/58 [00:05<00:04,  5.90it/s, loss=0.175, v_num=dcz5, train_loss=1.530, train_loss_reg=0.0331, validation_loss=0.0531]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.55it/s]\u001b[A\n",
            "Epoch 227: 100% 58/58 [00:07<00:00,  8.10it/s, loss=0.163, v_num=dcz5, train_loss=0.00437, train_loss_reg=0.00437, validation_loss=0.0501]Epoch 227, global step 2279: validation_loss was not in top 1\n",
            "\n",
            "Epoch 228:  52% 30/58 [00:05<00:04,  5.93it/s, loss=0.163, v_num=dcz5, train_loss=0.00437, train_loss_reg=0.00437, validation_loss=0.0501]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.52it/s]\u001b[A\n",
            "Epoch 228: 100% 58/58 [00:06<00:00,  8.56it/s, loss=0.0532, v_num=dcz5, train_loss=0.0435, train_loss_reg=0.0435, validation_loss=0.0585] Epoch 228, global step 2289: validation_loss was not in top 1\n",
            "\n",
            "Epoch 229:  52% 30/58 [00:05<00:04,  5.94it/s, loss=0.0532, v_num=dcz5, train_loss=0.0435, train_loss_reg=0.0435, validation_loss=0.0585]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.22it/s]\u001b[A\n",
            "Epoch 229: 100% 58/58 [00:06<00:00,  8.54it/s, loss=0.0318, v_num=dcz5, train_loss=0.00037, train_loss_reg=0.00037, validation_loss=0.0691]\n",
            "Epoch 229:   0% 0/58 [00:00<?, ?it/s, loss=0.0318, v_num=dcz5, train_loss=0.00037, train_loss_reg=0.00037, validation_loss=0.0691]         Epoch 229, global step 2299: validation_loss was not in top 1\n",
            "Epoch 230:  52% 30/58 [00:05<00:04,  5.93it/s, loss=0.0318, v_num=dcz5, train_loss=0.00037, train_loss_reg=0.00037, validation_loss=0.0691]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.71it/s]\u001b[A\n",
            "Epoch 230: 100% 58/58 [00:07<00:00,  8.21it/s, loss=0.0317, v_num=dcz5, train_loss=0.0788, train_loss_reg=0.0772, validation_loss=0.0574]  \n",
            "Epoch 230:   0% 0/58 [00:00<?, ?it/s, loss=0.0317, v_num=dcz5, train_loss=0.0788, train_loss_reg=0.0772, validation_loss=0.0574]         Epoch 230, global step 2309: validation_loss was not in top 1\n",
            "Epoch 231:  52% 30/58 [00:05<00:04,  5.94it/s, loss=0.0317, v_num=dcz5, train_loss=0.0788, train_loss_reg=0.0772, validation_loss=0.0574]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.42it/s]\u001b[A\n",
            "Epoch 231: 100% 58/58 [00:07<00:00,  8.06it/s, loss=0.0619, v_num=dcz5, train_loss=0.755, train_loss_reg=0.00515, validation_loss=0.0612]Epoch 231, global step 2319: validation_loss was not in top 1\n",
            "\n",
            "Epoch 232:  52% 30/58 [00:05<00:04,  5.93it/s, loss=0.0619, v_num=dcz5, train_loss=0.755, train_loss_reg=0.00515, validation_loss=0.0612]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.67it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 21.99it/s]\u001b[AEpoch 232, global step 2329: validation_loss was not in top 1\n",
            "Epoch 232: 100% 58/58 [00:07<00:00,  8.09it/s, loss=0.0587, v_num=dcz5, train_loss=0.0461, train_loss_reg=0.0461, validation_loss=0.0653]\n",
            "Epoch 233:  52% 30/58 [00:05<00:04,  5.96it/s, loss=0.0587, v_num=dcz5, train_loss=0.0461, train_loss_reg=0.0461, validation_loss=0.0653]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.20it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 26.54it/s]\u001b[AEpoch 233, global step 2339: validation_loss was not in top 1\n",
            "Epoch 233: 100% 58/58 [00:06<00:00,  8.46it/s, loss=0.0236, v_num=dcz5, train_loss=0.00189, train_loss_reg=0.00189, validation_loss=0.0685]\n",
            "Epoch 234:  52% 30/58 [00:05<00:04,  5.96it/s, loss=0.0236, v_num=dcz5, train_loss=0.00189, train_loss_reg=0.00189, validation_loss=0.0685]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.55it/s]\u001b[A\n",
            "Epoch 234: 100% 58/58 [00:06<00:00,  8.58it/s, loss=0.0882, v_num=dcz5, train_loss=0.787, train_loss_reg=0.004, validation_loss=0.0646]    \n",
            "Epoch 234:   0% 0/58 [00:00<?, ?it/s, loss=0.0882, v_num=dcz5, train_loss=0.787, train_loss_reg=0.004, validation_loss=0.0646]         Epoch 234, global step 2349: validation_loss was not in top 1\n",
            "Epoch 235:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.0882, v_num=dcz5, train_loss=0.787, train_loss_reg=0.004, validation_loss=0.0646]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.71it/s]\u001b[A\n",
            "Epoch 235: 100% 58/58 [00:06<00:00,  8.54it/s, loss=0.14, v_num=dcz5, train_loss=0.385, train_loss_reg=0.00324, validation_loss=0.067] \n",
            "Epoch 236:   0% 0/58 [00:00<?, ?it/s, loss=0.14, v_num=dcz5, train_loss=0.385, train_loss_reg=0.00324, validation_loss=0.067]Epoch 235, global step 2359: validation_loss was not in top 1\n",
            "Epoch 236:  52% 30/58 [00:05<00:04,  5.90it/s, loss=0.14, v_num=dcz5, train_loss=0.385, train_loss_reg=0.00324, validation_loss=0.067]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.55it/s]\u001b[A\n",
            "Epoch 236: 100% 58/58 [00:06<00:00,  8.52it/s, loss=0.151, v_num=dcz5, train_loss=0.00419, train_loss_reg=0.00419, validation_loss=0.0631]Epoch 236, global step 2369: validation_loss was not in top 1\n",
            "\n",
            "Epoch 237:  52% 30/58 [00:05<00:04,  5.93it/s, loss=0.151, v_num=dcz5, train_loss=0.00419, train_loss_reg=0.00419, validation_loss=0.0631]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.27it/s]\u001b[A\n",
            "Epoch 237: 100% 58/58 [00:06<00:00,  8.42it/s, loss=0.13, v_num=dcz5, train_loss=0.151, train_loss_reg=0.0134, validation_loss=0.0659]    Epoch 237, global step 2379: validation_loss was not in top 1\n",
            "\n",
            "Epoch 238:  52% 30/58 [00:05<00:04,  5.99it/s, loss=0.13, v_num=dcz5, train_loss=0.151, train_loss_reg=0.0134, validation_loss=0.0659]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.42it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 25.89it/s]\u001b[AEpoch 238, global step 2389: validation_loss was not in top 1\n",
            "Epoch 238: 100% 58/58 [00:06<00:00,  8.45it/s, loss=0.0693, v_num=dcz5, train_loss=0.164, train_loss_reg=0.010, validation_loss=0.0636]\n",
            "Epoch 239:  52% 30/58 [00:05<00:04,  5.95it/s, loss=0.0693, v_num=dcz5, train_loss=0.164, train_loss_reg=0.010, validation_loss=0.0636]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.37it/s]\u001b[A\n",
            "Epoch 239: 100% 58/58 [00:07<00:00,  8.10it/s, loss=0.0435, v_num=dcz5, train_loss=0.0135, train_loss_reg=0.00486, validation_loss=0.063]Epoch 239, global step 2399: validation_loss was not in top 1\n",
            "\n",
            "Epoch 240:  52% 30/58 [00:05<00:04,  5.95it/s, loss=0.0435, v_num=dcz5, train_loss=0.0135, train_loss_reg=0.00486, validation_loss=0.063]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.77it/s]\u001b[A\n",
            "Epoch 240: 100% 58/58 [00:06<00:00,  8.58it/s, loss=0.0258, v_num=dcz5, train_loss=0.0115, train_loss_reg=0.0115, validation_loss=0.0614]\n",
            "Epoch 240: 100% 58/58 [00:06<00:00,  8.58it/s, loss=0.0258, v_num=dcz5, train_loss=0.0115, train_loss_reg=0.0115, validation_loss=0.0614]Epoch 240, global step 2409: validation_loss was not in top 1\n",
            "Epoch 241:  52% 30/58 [00:05<00:04,  5.99it/s, loss=0.0258, v_num=dcz5, train_loss=0.0115, train_loss_reg=0.0115, validation_loss=0.0614]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.74it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.33it/s]\u001b[AEpoch 241, global step 2419: validation_loss was not in top 1\n",
            "Epoch 241: 100% 58/58 [00:06<00:00,  8.62it/s, loss=0.0398, v_num=dcz5, train_loss=0.00392, train_loss_reg=0.00392, validation_loss=0.0572]\n",
            "Epoch 242:  52% 30/58 [00:04<00:04,  6.02it/s, loss=0.0398, v_num=dcz5, train_loss=0.00392, train_loss_reg=0.00392, validation_loss=0.0572]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.57it/s]\u001b[A\n",
            "Epoch 242: 100% 58/58 [00:06<00:00,  8.65it/s, loss=0.0526, v_num=dcz5, train_loss=0.318, train_loss_reg=0.0189, validation_loss=0.0591]   Epoch 242, global step 2429: validation_loss was not in top 1\n",
            "\n",
            "Epoch 243:  52% 30/58 [00:05<00:04,  5.99it/s, loss=0.0526, v_num=dcz5, train_loss=0.318, train_loss_reg=0.0189, validation_loss=0.0591]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.32it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 21.94it/s]\u001b[AEpoch 243, global step 2439: validation_loss was not in top 1\n",
            "Epoch 243: 100% 58/58 [00:07<00:00,  8.13it/s, loss=0.0461, v_num=dcz5, train_loss=0.224, train_loss_reg=0.0501, validation_loss=0.0571]\n",
            "Epoch 244:  52% 30/58 [00:05<00:04,  5.89it/s, loss=0.0461, v_num=dcz5, train_loss=0.224, train_loss_reg=0.0501, validation_loss=0.0571]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.72it/s]\u001b[A\n",
            "Epoch 244: 100% 58/58 [00:06<00:00,  8.52it/s, loss=0.0679, v_num=dcz5, train_loss=0.0301, train_loss_reg=0.0301, validation_loss=0.0575]\n",
            "Epoch 244: 100% 58/58 [00:06<00:00,  8.52it/s, loss=0.0679, v_num=dcz5, train_loss=0.0301, train_loss_reg=0.0301, validation_loss=0.0575]Epoch 244, global step 2449: validation_loss was not in top 1\n",
            "Epoch 245:  52% 30/58 [00:04<00:04,  6.01it/s, loss=0.0679, v_num=dcz5, train_loss=0.0301, train_loss_reg=0.0301, validation_loss=0.0575]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.50it/s]\u001b[A\n",
            "Epoch 245: 100% 58/58 [00:06<00:00,  8.63it/s, loss=0.0843, v_num=dcz5, train_loss=0.178, train_loss_reg=0.0834, validation_loss=0.0663] Epoch 245, global step 2459: validation_loss was not in top 1\n",
            "\n",
            "Epoch 246:  52% 30/58 [00:05<00:04,  5.96it/s, loss=0.0843, v_num=dcz5, train_loss=0.178, train_loss_reg=0.0834, validation_loss=0.0663]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.49it/s]\u001b[A\n",
            "Epoch 246: 100% 58/58 [00:07<00:00,  8.10it/s, loss=0.0963, v_num=dcz5, train_loss=0.652, train_loss_reg=0.0366, validation_loss=0.0583]Epoch 246, global step 2469: validation_loss was not in top 1\n",
            "\n",
            "Epoch 247:  52% 30/58 [00:05<00:04,  5.94it/s, loss=0.0963, v_num=dcz5, train_loss=0.652, train_loss_reg=0.0366, validation_loss=0.0583]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.74it/s]\u001b[A\n",
            "Epoch 247: 100% 58/58 [00:07<00:00,  8.10it/s, loss=0.0732, v_num=dcz5, train_loss=0.139, train_loss_reg=0.00361, validation_loss=0.0601]\n",
            "Epoch 248:   0% 0/58 [00:00<?, ?it/s, loss=0.0732, v_num=dcz5, train_loss=0.139, train_loss_reg=0.00361, validation_loss=0.0601]Epoch 247, global step 2479: validation_loss was not in top 1\n",
            "Epoch 248:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.0732, v_num=dcz5, train_loss=0.139, train_loss_reg=0.00361, validation_loss=0.0601]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.63it/s]\u001b[A\n",
            "Epoch 248: 100% 58/58 [00:07<00:00,  8.07it/s, loss=0.0305, v_num=dcz5, train_loss=0.00515, train_loss_reg=0.00515, validation_loss=0.0613]\n",
            "Epoch 249:   0% 0/58 [00:00<?, ?it/s, loss=0.0305, v_num=dcz5, train_loss=0.00515, train_loss_reg=0.00515, validation_loss=0.0613]Epoch 248, global step 2489: validation_loss was not in top 1\n",
            "Epoch 249:  52% 30/58 [00:05<00:04,  5.87it/s, loss=0.0305, v_num=dcz5, train_loss=0.00515, train_loss_reg=0.00515, validation_loss=0.0613]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.62it/s]\u001b[A\n",
            "Epoch 249: 100% 58/58 [00:07<00:00,  8.02it/s, loss=0.0408, v_num=dcz5, train_loss=0.0125, train_loss_reg=0.00374, validation_loss=0.0578] \n",
            "Epoch 249: 100% 58/58 [00:07<00:00,  8.02it/s, loss=0.0408, v_num=dcz5, train_loss=0.0125, train_loss_reg=0.00374, validation_loss=0.0578]Epoch 249, global step 2499: validation_loss was not in top 1\n",
            "Epoch 250:  52% 30/58 [00:05<00:04,  5.82it/s, loss=0.0408, v_num=dcz5, train_loss=0.0125, train_loss_reg=0.00374, validation_loss=0.0578]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.62it/s]\u001b[A\n",
            "Epoch 250: 100% 58/58 [00:07<00:00,  8.20it/s, loss=0.125, v_num=dcz5, train_loss=0.032, train_loss_reg=0.032, validation_loss=0.0576]    \n",
            "Epoch 250:   0% 0/58 [00:00<?, ?it/s, loss=0.125, v_num=dcz5, train_loss=0.032, train_loss_reg=0.032, validation_loss=0.0576]         Epoch 250, global step 2509: validation_loss was not in top 1\n",
            "Epoch 251:  52% 30/58 [00:05<00:04,  5.85it/s, loss=0.125, v_num=dcz5, train_loss=0.032, train_loss_reg=0.032, validation_loss=0.0576]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.56it/s]\u001b[A\n",
            "Epoch 251: 100% 58/58 [00:07<00:00,  8.24it/s, loss=0.192, v_num=dcz5, train_loss=0.0526, train_loss_reg=0.0302, validation_loss=0.0719]Epoch 251, global step 2519: validation_loss was not in top 1\n",
            "\n",
            "Epoch 252:  52% 30/58 [00:05<00:04,  5.85it/s, loss=0.192, v_num=dcz5, train_loss=0.0526, train_loss_reg=0.0302, validation_loss=0.0719]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.58it/s]\u001b[A\n",
            "Epoch 252: 100% 58/58 [00:06<00:00,  8.47it/s, loss=0.21, v_num=dcz5, train_loss=0.215, train_loss_reg=0.0281, validation_loss=0.074]   \n",
            "Epoch 252:   0% 0/58 [00:00<?, ?it/s, loss=0.21, v_num=dcz5, train_loss=0.215, train_loss_reg=0.0281, validation_loss=0.074]         Epoch 252, global step 2529: validation_loss was not in top 1\n",
            "Epoch 253:  52% 30/58 [00:05<00:04,  5.85it/s, loss=0.21, v_num=dcz5, train_loss=0.215, train_loss_reg=0.0281, validation_loss=0.074]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.42it/s]\u001b[A\n",
            "Epoch 253: 100% 58/58 [00:07<00:00,  8.00it/s, loss=0.186, v_num=dcz5, train_loss=0.506, train_loss_reg=0.00967, validation_loss=0.0832]\n",
            "Epoch 253: 100% 58/58 [00:07<00:00,  8.00it/s, loss=0.186, v_num=dcz5, train_loss=0.506, train_loss_reg=0.00967, validation_loss=0.0832]Epoch 253, global step 2539: validation_loss was not in top 1\n",
            "Epoch 254:  52% 30/58 [00:05<00:04,  5.81it/s, loss=0.186, v_num=dcz5, train_loss=0.506, train_loss_reg=0.00967, validation_loss=0.0832]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.55it/s]\u001b[A\n",
            "Epoch 254: 100% 58/58 [00:07<00:00,  7.95it/s, loss=0.245, v_num=dcz5, train_loss=0.971, train_loss_reg=0.00693, validation_loss=0.0826]\n",
            "Epoch 254: 100% 58/58 [00:07<00:00,  7.95it/s, loss=0.245, v_num=dcz5, train_loss=0.971, train_loss_reg=0.00693, validation_loss=0.0826]Epoch 254, global step 2549: validation_loss was not in top 1\n",
            "Epoch 255:  52% 30/58 [00:05<00:04,  5.86it/s, loss=0.245, v_num=dcz5, train_loss=0.971, train_loss_reg=0.00693, validation_loss=0.0826]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.32it/s]\u001b[A\n",
            "Epoch 255: 100% 58/58 [00:07<00:00,  8.01it/s, loss=0.222, v_num=dcz5, train_loss=0.325, train_loss_reg=0.101, validation_loss=0.063]   Epoch 255, global step 2559: validation_loss was not in top 1\n",
            "\n",
            "Epoch 256:  52% 30/58 [00:05<00:04,  5.85it/s, loss=0.222, v_num=dcz5, train_loss=0.325, train_loss_reg=0.101, validation_loss=0.063]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 27.98it/s]\u001b[A\n",
            "Epoch 256: 100% 58/58 [00:07<00:00,  8.01it/s, loss=0.101, v_num=dcz5, train_loss=0.202, train_loss_reg=0.019, validation_loss=0.0681]\n",
            "Epoch 256:   0% 0/58 [00:00<?, ?it/s, loss=0.101, v_num=dcz5, train_loss=0.202, train_loss_reg=0.019, validation_loss=0.0681]         Epoch 256, global step 2569: validation_loss was not in top 1\n",
            "Epoch 257:  52% 30/58 [00:05<00:04,  5.81it/s, loss=0.101, v_num=dcz5, train_loss=0.202, train_loss_reg=0.019, validation_loss=0.0681]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.31it/s]\u001b[A\n",
            "Epoch 257: 100% 58/58 [00:07<00:00,  7.95it/s, loss=0.11, v_num=dcz5, train_loss=0.248, train_loss_reg=0.00257, validation_loss=0.0653]\n",
            "Epoch 258:   0% 0/58 [00:00<?, ?it/s, loss=0.11, v_num=dcz5, train_loss=0.248, train_loss_reg=0.00257, validation_loss=0.0653]Epoch 257, global step 2579: validation_loss was not in top 1\n",
            "Epoch 258:  52% 30/58 [00:05<00:04,  5.88it/s, loss=0.11, v_num=dcz5, train_loss=0.248, train_loss_reg=0.00257, validation_loss=0.0653]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.72it/s]\u001b[A\n",
            "Epoch 258: 100% 58/58 [00:07<00:00,  8.15it/s, loss=0.0847, v_num=dcz5, train_loss=0.0518, train_loss_reg=0.0192, validation_loss=0.0607]\n",
            "Epoch 259:   0% 0/58 [00:00<?, ?it/s, loss=0.0847, v_num=dcz5, train_loss=0.0518, train_loss_reg=0.0192, validation_loss=0.0607]Epoch 258, global step 2589: validation_loss was not in top 1\n",
            "Epoch 259:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.0847, v_num=dcz5, train_loss=0.0518, train_loss_reg=0.0192, validation_loss=0.0607]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.48it/s]\u001b[A\n",
            "Epoch 259: 100% 58/58 [00:07<00:00,  8.06it/s, loss=0.0441, v_num=dcz5, train_loss=0.014, train_loss_reg=0.014, validation_loss=0.0647]  \n",
            "Epoch 259:   0% 0/58 [00:00<?, ?it/s, loss=0.0441, v_num=dcz5, train_loss=0.014, train_loss_reg=0.014, validation_loss=0.0647]         Epoch 259, global step 2599: validation_loss was not in top 1\n",
            "Epoch 260:  52% 30/58 [00:05<00:04,  5.88it/s, loss=0.0441, v_num=dcz5, train_loss=0.014, train_loss_reg=0.014, validation_loss=0.0647]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.70it/s]\u001b[A\n",
            "Epoch 260: 100% 58/58 [00:06<00:00,  8.50it/s, loss=0.0571, v_num=dcz5, train_loss=0.00444, train_loss_reg=0.00444, validation_loss=0.0774]\n",
            "Epoch 261:   0% 0/58 [00:00<?, ?it/s, loss=0.0571, v_num=dcz5, train_loss=0.00444, train_loss_reg=0.00444, validation_loss=0.0774]Epoch 260, global step 2609: validation_loss was not in top 1\n",
            "Epoch 261:  52% 30/58 [00:05<00:04,  5.90it/s, loss=0.0571, v_num=dcz5, train_loss=0.00444, train_loss_reg=0.00444, validation_loss=0.0774]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.71it/s]\u001b[A\n",
            "Epoch 261: 100% 58/58 [00:06<00:00,  8.53it/s, loss=0.11, v_num=dcz5, train_loss=0.00113, train_loss_reg=0.00113, validation_loss=0.0642]  \n",
            "Epoch 262:   0% 0/58 [00:00<?, ?it/s, loss=0.11, v_num=dcz5, train_loss=0.00113, train_loss_reg=0.00113, validation_loss=0.0642]Epoch 261, global step 2619: validation_loss was not in top 1\n",
            "Epoch 262:  52% 30/58 [00:05<00:04,  5.83it/s, loss=0.11, v_num=dcz5, train_loss=0.00113, train_loss_reg=0.00113, validation_loss=0.0642]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.77it/s]\u001b[A\n",
            "Epoch 262: 100% 58/58 [00:07<00:00,  8.03it/s, loss=0.176, v_num=dcz5, train_loss=1.500, train_loss_reg=0.0168, validation_loss=0.0603]  \n",
            "Epoch 262:   0% 0/58 [00:00<?, ?it/s, loss=0.176, v_num=dcz5, train_loss=1.500, train_loss_reg=0.0168, validation_loss=0.0603]         Epoch 262, global step 2629: validation_loss was not in top 1\n",
            "Epoch 263:  52% 30/58 [00:05<00:04,  5.80it/s, loss=0.176, v_num=dcz5, train_loss=1.500, train_loss_reg=0.0168, validation_loss=0.0603]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.76it/s]\u001b[A\n",
            "Epoch 263: 100% 58/58 [00:06<00:00,  8.41it/s, loss=0.194, v_num=dcz5, train_loss=0.845, train_loss_reg=0.026, validation_loss=0.0702] Epoch 263, global step 2639: validation_loss was not in top 1\n",
            "\n",
            "Epoch 264:  52% 30/58 [00:05<00:04,  5.89it/s, loss=0.194, v_num=dcz5, train_loss=0.845, train_loss_reg=0.026, validation_loss=0.0702]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.55it/s]\u001b[A\n",
            "Epoch 264: 100% 58/58 [00:06<00:00,  8.50it/s, loss=0.13, v_num=dcz5, train_loss=0.0642, train_loss_reg=0.024, validation_loss=0.0673]\n",
            "Epoch 264: 100% 58/58 [00:06<00:00,  8.50it/s, loss=0.13, v_num=dcz5, train_loss=0.0642, train_loss_reg=0.024, validation_loss=0.0673]Epoch 264, global step 2649: validation_loss was not in top 1\n",
            "Epoch 265:  52% 30/58 [00:05<00:04,  5.86it/s, loss=0.13, v_num=dcz5, train_loss=0.0642, train_loss_reg=0.024, validation_loss=0.0673]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.59it/s]\u001b[A\n",
            "Epoch 265: 100% 58/58 [00:06<00:00,  8.48it/s, loss=0.0884, v_num=dcz5, train_loss=0.318, train_loss_reg=0.0122, validation_loss=0.0589]Epoch 265, global step 2659: validation_loss was not in top 1\n",
            "\n",
            "Epoch 266:  52% 30/58 [00:05<00:04,  5.94it/s, loss=0.0884, v_num=dcz5, train_loss=0.318, train_loss_reg=0.0122, validation_loss=0.0589]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.59it/s]\u001b[A\n",
            "Epoch 266: 100% 58/58 [00:06<00:00,  8.57it/s, loss=0.0767, v_num=dcz5, train_loss=0.00866, train_loss_reg=0.00866, validation_loss=0.070]\n",
            "Epoch 266: 100% 58/58 [00:06<00:00,  8.56it/s, loss=0.0767, v_num=dcz5, train_loss=0.00866, train_loss_reg=0.00866, validation_loss=0.070]Epoch 266, global step 2669: validation_loss was not in top 1\n",
            "Epoch 267:  52% 30/58 [00:05<00:04,  5.90it/s, loss=0.0767, v_num=dcz5, train_loss=0.00866, train_loss_reg=0.00866, validation_loss=0.070]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.51it/s]\u001b[A\n",
            "Epoch 267: 100% 58/58 [00:07<00:00,  8.06it/s, loss=0.0733, v_num=dcz5, train_loss=0.0118, train_loss_reg=0.00146, validation_loss=0.0553]Epoch 267, global step 2679: validation_loss was not in top 1\n",
            "\n",
            "Epoch 268:  52% 30/58 [00:05<00:04,  5.88it/s, loss=0.0733, v_num=dcz5, train_loss=0.0118, train_loss_reg=0.00146, validation_loss=0.0553]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.84it/s]\u001b[A\n",
            "Epoch 268: 100% 58/58 [00:07<00:00,  8.05it/s, loss=0.0928, v_num=dcz5, train_loss=0.462, train_loss_reg=0.00213, validation_loss=0.0605] Epoch 268, global step 2689: validation_loss was not in top 1\n",
            "\n",
            "Epoch 269:  52% 30/58 [00:05<00:04,  5.90it/s, loss=0.0928, v_num=dcz5, train_loss=0.462, train_loss_reg=0.00213, validation_loss=0.0605]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.53it/s]\u001b[A\n",
            "Epoch 269: 100% 58/58 [00:06<00:00,  8.52it/s, loss=0.0828, v_num=dcz5, train_loss=0.0253, train_loss_reg=0.0253, validation_loss=0.0641]\n",
            "Epoch 269:   0% 0/58 [00:00<?, ?it/s, loss=0.0828, v_num=dcz5, train_loss=0.0253, train_loss_reg=0.0253, validation_loss=0.0641]         Epoch 269, global step 2699: validation_loss was not in top 1\n",
            "Epoch 270:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.0828, v_num=dcz5, train_loss=0.0253, train_loss_reg=0.0253, validation_loss=0.0641]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.63it/s]\u001b[A\n",
            "Epoch 270: 100% 58/58 [00:07<00:00,  8.07it/s, loss=0.071, v_num=dcz5, train_loss=0.452, train_loss_reg=0.00323, validation_loss=0.063]  Epoch 270, global step 2709: validation_loss was not in top 1\n",
            "\n",
            "Epoch 271:  52% 30/58 [00:05<00:04,  5.93it/s, loss=0.071, v_num=dcz5, train_loss=0.452, train_loss_reg=0.00323, validation_loss=0.063]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.60it/s]\u001b[A\n",
            "Epoch 271: 100% 58/58 [00:06<00:00,  8.54it/s, loss=0.0922, v_num=dcz5, train_loss=0.771, train_loss_reg=0.00253, validation_loss=0.0645]Epoch 271, global step 2719: validation_loss was not in top 1\n",
            "\n",
            "Epoch 272:  52% 30/58 [00:05<00:04,  5.87it/s, loss=0.0922, v_num=dcz5, train_loss=0.771, train_loss_reg=0.00253, validation_loss=0.0645]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.63it/s]\u001b[A\n",
            "Epoch 272: 100% 58/58 [00:07<00:00,  8.03it/s, loss=0.158, v_num=dcz5, train_loss=1.560, train_loss_reg=0.00609, validation_loss=0.0774] \n",
            "Epoch 273:   0% 0/58 [00:00<?, ?it/s, loss=0.158, v_num=dcz5, train_loss=1.560, train_loss_reg=0.00609, validation_loss=0.0774]Epoch 272, global step 2729: validation_loss was not in top 1\n",
            "Epoch 273:  52% 30/58 [00:05<00:04,  5.89it/s, loss=0.158, v_num=dcz5, train_loss=1.560, train_loss_reg=0.00609, validation_loss=0.0774]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.34it/s]\u001b[A\n",
            "Epoch 273: 100% 58/58 [00:07<00:00,  8.03it/s, loss=0.133, v_num=dcz5, train_loss=0.0191, train_loss_reg=0.0164, validation_loss=0.0663]\n",
            "Epoch 273: 100% 58/58 [00:07<00:00,  8.03it/s, loss=0.133, v_num=dcz5, train_loss=0.0191, train_loss_reg=0.0164, validation_loss=0.0663]Epoch 273, global step 2739: validation_loss was not in top 1\n",
            "Epoch 274:  52% 30/58 [00:05<00:04,  5.85it/s, loss=0.133, v_num=dcz5, train_loss=0.0191, train_loss_reg=0.0164, validation_loss=0.0663]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.82it/s]\u001b[A\n",
            "Epoch 274: 100% 58/58 [00:06<00:00,  8.48it/s, loss=0.0525, v_num=dcz5, train_loss=0.286, train_loss_reg=0.103, validation_loss=0.0599] Epoch 274, global step 2749: validation_loss was not in top 1\n",
            "\n",
            "Epoch 275:  52% 30/58 [00:05<00:04,  5.93it/s, loss=0.0525, v_num=dcz5, train_loss=0.286, train_loss_reg=0.103, validation_loss=0.0599]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.54it/s]\u001b[A\n",
            "Epoch 275: 100% 58/58 [00:07<00:00,  8.08it/s, loss=0.0628, v_num=dcz5, train_loss=0.108, train_loss_reg=0.00261, validation_loss=0.0568]Epoch 275, global step 2759: validation_loss was not in top 1\n",
            "\n",
            "Epoch 276:  52% 30/58 [00:05<00:04,  5.92it/s, loss=0.0628, v_num=dcz5, train_loss=0.108, train_loss_reg=0.00261, validation_loss=0.0568]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.45it/s]\u001b[A\n",
            "Epoch 276: 100% 58/58 [00:06<00:00,  8.54it/s, loss=0.136, v_num=dcz5, train_loss=1.820, train_loss_reg=0.0218, validation_loss=0.0603]  Epoch 276, global step 2769: validation_loss was not in top 1\n",
            "\n",
            "Epoch 277:  52% 30/58 [00:05<00:04,  5.99it/s, loss=0.136, v_num=dcz5, train_loss=1.820, train_loss_reg=0.0218, validation_loss=0.0603]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.65it/s]\u001b[A\n",
            "Epoch 277: 100% 58/58 [00:06<00:00,  8.62it/s, loss=0.123, v_num=dcz5, train_loss=0.229, train_loss_reg=0.0924, validation_loss=0.066] Epoch 277, global step 2779: validation_loss was not in top 1\n",
            "\n",
            "Epoch 278:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.123, v_num=dcz5, train_loss=0.229, train_loss_reg=0.0924, validation_loss=0.066]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.68it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.26it/s]\u001b[AEpoch 278, global step 2789: validation_loss was not in top 1\n",
            "Epoch 278: 100% 58/58 [00:06<00:00,  8.54it/s, loss=0.0809, v_num=dcz5, train_loss=0.625, train_loss_reg=0.0153, validation_loss=0.0629]\n",
            "Epoch 279:  52% 30/58 [00:05<00:04,  5.81it/s, loss=0.0809, v_num=dcz5, train_loss=0.625, train_loss_reg=0.0153, validation_loss=0.0629]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.40it/s]\u001b[A\n",
            "Epoch 279: 100% 58/58 [00:07<00:00,  7.96it/s, loss=0.158, v_num=dcz5, train_loss=0.242, train_loss_reg=0.00438, validation_loss=0.0615]\n",
            "Epoch 279:   0% 0/58 [00:00<?, ?it/s, loss=0.158, v_num=dcz5, train_loss=0.242, train_loss_reg=0.00438, validation_loss=0.0615]         Epoch 279, global step 2799: validation_loss was not in top 1\n",
            "Epoch 280:  52% 30/58 [00:05<00:04,  5.79it/s, loss=0.158, v_num=dcz5, train_loss=0.242, train_loss_reg=0.00438, validation_loss=0.0615]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.66it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.22it/s]\u001b[AEpoch 280, global step 2809: validation_loss was not in top 1\n",
            "Epoch 280: 100% 58/58 [00:06<00:00,  8.41it/s, loss=0.187, v_num=dcz5, train_loss=0.286, train_loss_reg=0.0247, validation_loss=0.0615] \n",
            "Epoch 281:  52% 30/58 [00:05<00:04,  5.85it/s, loss=0.187, v_num=dcz5, train_loss=0.286, train_loss_reg=0.0247, validation_loss=0.0615]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.18it/s]\u001b[A\n",
            "Epoch 281: 100% 58/58 [00:06<00:00,  8.44it/s, loss=0.177, v_num=dcz5, train_loss=0.734, train_loss_reg=0.000169, validation_loss=0.0648]\n",
            "Epoch 282:   0% 0/58 [00:00<?, ?it/s, loss=0.177, v_num=dcz5, train_loss=0.734, train_loss_reg=0.000169, validation_loss=0.0648]Epoch 281, global step 2819: validation_loss was not in top 1\n",
            "Epoch 282:  52% 30/58 [00:05<00:04,  5.85it/s, loss=0.177, v_num=dcz5, train_loss=0.734, train_loss_reg=0.000169, validation_loss=0.0648]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.79it/s]\u001b[A\n",
            "Epoch 282: 100% 58/58 [00:07<00:00,  8.02it/s, loss=0.358, v_num=dcz5, train_loss=2.800, train_loss_reg=0.127, validation_loss=0.0596]   Epoch 282, global step 2829: validation_loss was not in top 1\n",
            "\n",
            "Epoch 283:  52% 30/58 [00:05<00:04,  5.80it/s, loss=0.358, v_num=dcz5, train_loss=2.800, train_loss_reg=0.127, validation_loss=0.0596]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.36it/s]\u001b[A\n",
            "Epoch 283: 100% 58/58 [00:06<00:00,  8.40it/s, loss=0.388, v_num=dcz5, train_loss=0.282, train_loss_reg=0.0141, validation_loss=0.0673]Epoch 283, global step 2839: validation_loss was not in top 1\n",
            "\n",
            "Epoch 284:  52% 30/58 [00:05<00:04,  5.86it/s, loss=0.388, v_num=dcz5, train_loss=0.282, train_loss_reg=0.0141, validation_loss=0.0673]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.69it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 22.12it/s]\u001b[AEpoch 284, global step 2849: validation_loss was not in top 1\n",
            "Epoch 284: 100% 58/58 [00:07<00:00,  8.03it/s, loss=0.243, v_num=dcz5, train_loss=1.240, train_loss_reg=0.0671, validation_loss=0.0711]\n",
            "Epoch 285:  52% 30/58 [00:05<00:04,  5.85it/s, loss=0.243, v_num=dcz5, train_loss=1.240, train_loss_reg=0.0671, validation_loss=0.0711]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.43it/s]\u001b[A\n",
            "Epoch 285: 100% 58/58 [00:07<00:00,  8.00it/s, loss=0.148, v_num=dcz5, train_loss=0.0929, train_loss_reg=0.00869, validation_loss=0.0714]\n",
            "Epoch 285:   0% 0/58 [00:00<?, ?it/s, loss=0.148, v_num=dcz5, train_loss=0.0929, train_loss_reg=0.00869, validation_loss=0.0714]         Epoch 285, global step 2859: validation_loss was not in top 1\n",
            "Epoch 286:  52% 30/58 [00:05<00:04,  5.87it/s, loss=0.148, v_num=dcz5, train_loss=0.0929, train_loss_reg=0.00869, validation_loss=0.0714]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.73it/s]\u001b[A\n",
            "Epoch 286: 100% 58/58 [00:07<00:00,  8.03it/s, loss=0.0748, v_num=dcz5, train_loss=0.447, train_loss_reg=0.012, validation_loss=0.0619]  \n",
            "Epoch 287:   0% 0/58 [00:00<?, ?it/s, loss=0.0748, v_num=dcz5, train_loss=0.447, train_loss_reg=0.012, validation_loss=0.0619]Epoch 286, global step 2869: validation_loss was not in top 1\n",
            "Epoch 287:  52% 30/58 [00:05<00:04,  5.87it/s, loss=0.0748, v_num=dcz5, train_loss=0.447, train_loss_reg=0.012, validation_loss=0.0619]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.70it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 23.45it/s]\u001b[AEpoch 287, global step 2879: validation_loss was not in top 1\n",
            "Epoch 287: 100% 58/58 [00:07<00:00,  8.16it/s, loss=0.078, v_num=dcz5, train_loss=0.00797, train_loss_reg=0.0054, validation_loss=0.0633]\n",
            "Epoch 288:  52% 30/58 [00:05<00:04,  5.97it/s, loss=0.078, v_num=dcz5, train_loss=0.00797, train_loss_reg=0.0054, validation_loss=0.0633]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.55it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 25.08it/s]\u001b[AEpoch 288, global step 2889: validation_loss was not in top 1\n",
            "Epoch 288: 100% 58/58 [00:06<00:00,  8.38it/s, loss=0.0351, v_num=dcz5, train_loss=0.00348, train_loss_reg=0.00348, validation_loss=0.0633]\n",
            "Epoch 289:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.0351, v_num=dcz5, train_loss=0.00348, train_loss_reg=0.00348, validation_loss=0.0633]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.37it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 21.94it/s]\u001b[AEpoch 289, global step 2899: validation_loss was not in top 1\n",
            "Epoch 289: 100% 58/58 [00:07<00:00,  8.05it/s, loss=0.127, v_num=dcz5, train_loss=1.880, train_loss_reg=0.0472, validation_loss=0.0655]    \n",
            "Epoch 290:  52% 30/58 [00:05<00:04,  5.85it/s, loss=0.127, v_num=dcz5, train_loss=1.880, train_loss_reg=0.0472, validation_loss=0.0655]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.36it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 21.90it/s]\u001b[AEpoch 290, global step 2909: validation_loss was not in top 1\n",
            "Epoch 290: 100% 58/58 [00:07<00:00,  8.00it/s, loss=0.185, v_num=dcz5, train_loss=0.582, train_loss_reg=0.00703, validation_loss=0.0793]\n",
            "Epoch 291:  52% 30/58 [00:05<00:04,  5.81it/s, loss=0.185, v_num=dcz5, train_loss=0.582, train_loss_reg=0.00703, validation_loss=0.0793]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.51it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 21.85it/s]\u001b[AEpoch 291, global step 2919: validation_loss was not in top 1\n",
            "Epoch 291: 100% 58/58 [00:07<00:00,  7.96it/s, loss=0.153, v_num=dcz5, train_loss=0.0234, train_loss_reg=0.00162, validation_loss=0.0664]\n",
            "Epoch 292:  52% 30/58 [00:05<00:04,  5.80it/s, loss=0.153, v_num=dcz5, train_loss=0.0234, train_loss_reg=0.00162, validation_loss=0.0664]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.49it/s]\u001b[A\n",
            "Epoch 292: 100% 58/58 [00:07<00:00,  8.15it/s, loss=0.13, v_num=dcz5, train_loss=0.255, train_loss_reg=0.00885, validation_loss=0.0658]  Epoch 292, global step 2929: validation_loss was not in top 1\n",
            "\n",
            "Epoch 293:  52% 30/58 [00:05<00:04,  5.88it/s, loss=0.13, v_num=dcz5, train_loss=0.255, train_loss_reg=0.00885, validation_loss=0.0658]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.45it/s]\u001b[A\n",
            "Epoch 293: 100% 58/58 [00:07<00:00,  8.26it/s, loss=0.0756, v_num=dcz5, train_loss=0.213, train_loss_reg=0.0106, validation_loss=0.0622]\n",
            "Epoch 293:   0% 0/58 [00:00<?, ?it/s, loss=0.0756, v_num=dcz5, train_loss=0.213, train_loss_reg=0.0106, validation_loss=0.0622]         Epoch 293, global step 2939: validation_loss was not in top 1\n",
            "Epoch 294:  52% 30/58 [00:05<00:04,  5.85it/s, loss=0.0756, v_num=dcz5, train_loss=0.213, train_loss_reg=0.0106, validation_loss=0.0622]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.79it/s]\u001b[A\n",
            "Epoch 294: 100% 58/58 [00:07<00:00,  8.03it/s, loss=0.0883, v_num=dcz5, train_loss=0.370, train_loss_reg=0.00512, validation_loss=0.0591]Epoch 294, global step 2949: validation_loss was not in top 1\n",
            "\n",
            "Epoch 295:  52% 30/58 [00:05<00:04,  5.85it/s, loss=0.0883, v_num=dcz5, train_loss=0.370, train_loss_reg=0.00512, validation_loss=0.0591]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.62it/s]\u001b[A\n",
            "Epoch 295: 100% 58/58 [00:06<00:00,  8.45it/s, loss=0.185, v_num=dcz5, train_loss=1.660, train_loss_reg=0.0413, validation_loss=0.0536]  \n",
            "Epoch 295:   0% 0/58 [00:00<?, ?it/s, loss=0.185, v_num=dcz5, train_loss=1.660, train_loss_reg=0.0413, validation_loss=0.0536]         Epoch 295, global step 2959: validation_loss was not in top 1\n",
            "Epoch 296:  52% 30/58 [00:05<00:04,  5.84it/s, loss=0.185, v_num=dcz5, train_loss=1.660, train_loss_reg=0.0413, validation_loss=0.0536]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.69it/s]\u001b[A\n",
            "Epoch 296: 100% 58/58 [00:06<00:00,  8.46it/s, loss=0.203, v_num=dcz5, train_loss=0.0279, train_loss_reg=0.0189, validation_loss=0.0559]Epoch 296, global step 2969: validation_loss was not in top 1\n",
            "\n",
            "Epoch 297:  52% 30/58 [00:05<00:04,  5.86it/s, loss=0.203, v_num=dcz5, train_loss=0.0279, train_loss_reg=0.0189, validation_loss=0.0559]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.47it/s]\u001b[A\n",
            "Epoch 297: 100% 58/58 [00:07<00:00,  8.22it/s, loss=0.143, v_num=dcz5, train_loss=0.335, train_loss_reg=0.0198, validation_loss=0.0691] Epoch 297, global step 2979: validation_loss was not in top 1\n",
            "\n",
            "Epoch 298:  52% 30/58 [00:05<00:04,  5.88it/s, loss=0.143, v_num=dcz5, train_loss=0.335, train_loss_reg=0.0198, validation_loss=0.0691]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.34it/s]\u001b[A\n",
            "Epoch 298: 100% 58/58 [00:07<00:00,  8.03it/s, loss=0.0866, v_num=dcz5, train_loss=0.000426, train_loss_reg=0.000426, validation_loss=0.0749]Epoch 298, global step 2989: validation_loss was not in top 1\n",
            "\n",
            "Epoch 299:  52% 30/58 [00:05<00:04,  5.92it/s, loss=0.0866, v_num=dcz5, train_loss=0.000426, train_loss_reg=0.000426, validation_loss=0.0749]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.57it/s]\u001b[A\n",
            "Epoch 299: 100% 58/58 [00:06<00:00,  8.29it/s, loss=0.0446, v_num=dcz5, train_loss=0.00156, train_loss_reg=0.00156, validation_loss=0.0561]  \n",
            "Epoch 300:   0% 0/58 [00:00<?, ?it/s, loss=0.0446, v_num=dcz5, train_loss=0.00156, train_loss_reg=0.00156, validation_loss=0.0561]Epoch 299, global step 2999: validation_loss was not in top 1\n",
            "Epoch 300:  52% 30/58 [00:05<00:04,  5.92it/s, loss=0.0446, v_num=dcz5, train_loss=0.00156, train_loss_reg=0.00156, validation_loss=0.0561]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.60it/s]\u001b[A\n",
            "Epoch 300: 100% 58/58 [00:07<00:00,  8.21it/s, loss=0.052, v_num=dcz5, train_loss=0.0134, train_loss_reg=0.00649, validation_loss=0.061]   Epoch 300, global step 3009: validation_loss was not in top 1\n",
            "\n",
            "Epoch 301:  52% 30/58 [00:05<00:04,  6.00it/s, loss=0.052, v_num=dcz5, train_loss=0.0134, train_loss_reg=0.00649, validation_loss=0.061]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.54it/s]\u001b[A\n",
            "Epoch 301: 100% 58/58 [00:06<00:00,  8.62it/s, loss=0.049, v_num=dcz5, train_loss=0.276, train_loss_reg=0.000469, validation_loss=0.0575]Epoch 301, global step 3019: validation_loss was not in top 1\n",
            "\n",
            "Epoch 302:  52% 30/58 [00:05<00:04,  5.93it/s, loss=0.049, v_num=dcz5, train_loss=0.276, train_loss_reg=0.000469, validation_loss=0.0575]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.41it/s]\u001b[A\n",
            "Epoch 302: 100% 58/58 [00:06<00:00,  8.54it/s, loss=0.0563, v_num=dcz5, train_loss=0.176, train_loss_reg=0.00656, validation_loss=0.0615]Epoch 302, global step 3029: validation_loss was not in top 1\n",
            "\n",
            "Epoch 303:  52% 30/58 [00:05<00:04,  5.94it/s, loss=0.0563, v_num=dcz5, train_loss=0.176, train_loss_reg=0.00656, validation_loss=0.0615]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.78it/s]\u001b[A\n",
            "Epoch 303: 100% 58/58 [00:06<00:00,  8.58it/s, loss=0.0374, v_num=dcz5, train_loss=0.0139, train_loss_reg=0.0139, validation_loss=0.066] Epoch 303, global step 3039: validation_loss was not in top 1\n",
            "\n",
            "Epoch 304:  52% 30/58 [00:05<00:04,  5.92it/s, loss=0.0374, v_num=dcz5, train_loss=0.0139, train_loss_reg=0.0139, validation_loss=0.066]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.39it/s]\u001b[A\n",
            "Epoch 304: 100% 58/58 [00:07<00:00,  8.05it/s, loss=0.0594, v_num=dcz5, train_loss=0.777, train_loss_reg=0.022, validation_loss=0.0659] \n",
            "Epoch 304: 100% 58/58 [00:07<00:00,  8.05it/s, loss=0.0594, v_num=dcz5, train_loss=0.777, train_loss_reg=0.022, validation_loss=0.0659]Epoch 304, global step 3049: validation_loss was not in top 1\n",
            "Epoch 305:  52% 30/58 [00:05<00:04,  5.90it/s, loss=0.0594, v_num=dcz5, train_loss=0.777, train_loss_reg=0.022, validation_loss=0.0659]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.69it/s]\u001b[A\n",
            "Epoch 305: 100% 58/58 [00:06<00:00,  8.53it/s, loss=0.0591, v_num=dcz5, train_loss=0.00335, train_loss_reg=0.00299, validation_loss=0.0686]Epoch 305, global step 3059: validation_loss was not in top 1\n",
            "\n",
            "Epoch 306:  52% 30/58 [00:04<00:04,  6.01it/s, loss=0.0591, v_num=dcz5, train_loss=0.00335, train_loss_reg=0.00299, validation_loss=0.0686]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.53it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.24it/s]\u001b[AEpoch 306, global step 3069: validation_loss was not in top 1\n",
            "Epoch 306: 100% 58/58 [00:06<00:00,  8.64it/s, loss=0.0272, v_num=dcz5, train_loss=0.151, train_loss_reg=0.00584, validation_loss=0.0606]  \n",
            "Epoch 307:  52% 30/58 [00:05<00:04,  5.96it/s, loss=0.0272, v_num=dcz5, train_loss=0.151, train_loss_reg=0.00584, validation_loss=0.0606]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.74it/s]\u001b[A\n",
            "Epoch 307: 100% 58/58 [00:06<00:00,  8.59it/s, loss=0.0611, v_num=dcz5, train_loss=0.0522, train_loss_reg=0.0204, validation_loss=0.0509]Epoch 307, global step 3079: validation_loss was not in top 1\n",
            "\n",
            "Epoch 308:  52% 30/58 [00:05<00:04,  5.93it/s, loss=0.0611, v_num=dcz5, train_loss=0.0522, train_loss_reg=0.0204, validation_loss=0.0509]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.73it/s]\u001b[A\n",
            "Epoch 308: 100% 58/58 [00:07<00:00,  8.10it/s, loss=0.0673, v_num=dcz5, train_loss=0.034, train_loss_reg=0.0136, validation_loss=0.0527] Epoch 308, global step 3089: validation_loss was not in top 1\n",
            "\n",
            "Epoch 309:  52% 30/58 [00:05<00:04,  5.86it/s, loss=0.0673, v_num=dcz5, train_loss=0.034, train_loss_reg=0.0136, validation_loss=0.0527]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.38it/s]\u001b[A\n",
            "Epoch 309: 100% 58/58 [00:07<00:00,  8.01it/s, loss=0.143, v_num=dcz5, train_loss=1.280, train_loss_reg=0.0893, validation_loss=0.0561] \n",
            "Epoch 309:   0% 0/58 [00:00<?, ?it/s, loss=0.143, v_num=dcz5, train_loss=1.280, train_loss_reg=0.0893, validation_loss=0.0561]         Epoch 309, global step 3099: validation_loss was not in top 1\n",
            "Epoch 310:  52% 30/58 [00:05<00:04,  5.89it/s, loss=0.143, v_num=dcz5, train_loss=1.280, train_loss_reg=0.0893, validation_loss=0.0561]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.45it/s]\u001b[A\n",
            "Epoch 310: 100% 58/58 [00:07<00:00,  8.05it/s, loss=0.166, v_num=dcz5, train_loss=0.414, train_loss_reg=0.00952, validation_loss=0.0627]\n",
            "Epoch 310:   0% 0/58 [00:00<?, ?it/s, loss=0.166, v_num=dcz5, train_loss=0.414, train_loss_reg=0.00952, validation_loss=0.0627]         Epoch 310, global step 3109: validation_loss was not in top 1\n",
            "Epoch 311:  52% 30/58 [00:05<00:04,  5.90it/s, loss=0.166, v_num=dcz5, train_loss=0.414, train_loss_reg=0.00952, validation_loss=0.0627]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.41it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.17it/s]\u001b[AEpoch 311, global step 3119: validation_loss was not in top 1\n",
            "Epoch 311: 100% 58/58 [00:06<00:00,  8.51it/s, loss=0.118, v_num=dcz5, train_loss=1.240, train_loss_reg=0.0368, validation_loss=0.0552] \n",
            "Epoch 312:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.118, v_num=dcz5, train_loss=1.240, train_loss_reg=0.0368, validation_loss=0.0552]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.70it/s]\u001b[A\n",
            "Epoch 312: 100% 58/58 [00:06<00:00,  8.54it/s, loss=0.149, v_num=dcz5, train_loss=1.000, train_loss_reg=0.00596, validation_loss=0.0505]Epoch 312, global step 3129: validation_loss was not in top 1\n",
            "\n",
            "Epoch 313:  52% 30/58 [00:05<00:04,  5.89it/s, loss=0.149, v_num=dcz5, train_loss=1.000, train_loss_reg=0.00596, validation_loss=0.0505]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.62it/s]\u001b[A\n",
            "Epoch 313: 100% 58/58 [00:07<00:00,  8.05it/s, loss=0.164, v_num=dcz5, train_loss=0.204, train_loss_reg=0.0664, validation_loss=0.0687] \n",
            "                                               \u001b[AEpoch 313, global step 3139: validation_loss was not in top 1\n",
            "Epoch 314:  52% 30/58 [00:05<00:04,  5.85it/s, loss=0.164, v_num=dcz5, train_loss=0.204, train_loss_reg=0.0664, validation_loss=0.0687]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.69it/s]\u001b[A\n",
            "Epoch 314: 100% 58/58 [00:07<00:00,  8.02it/s, loss=0.227, v_num=dcz5, train_loss=0.870, train_loss_reg=0.00802, validation_loss=0.0606]Epoch 314, global step 3149: validation_loss was not in top 1\n",
            "\n",
            "Epoch 315:  52% 30/58 [00:05<00:04,  5.90it/s, loss=0.227, v_num=dcz5, train_loss=0.870, train_loss_reg=0.00802, validation_loss=0.0606]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.74it/s]\u001b[A\n",
            "Epoch 315: 100% 58/58 [00:06<00:00,  8.53it/s, loss=0.212, v_num=dcz5, train_loss=0.838, train_loss_reg=0.00666, validation_loss=0.0545]Epoch 315, global step 3159: validation_loss was not in top 1\n",
            "\n",
            "Epoch 316:  52% 30/58 [00:05<00:04,  5.90it/s, loss=0.212, v_num=dcz5, train_loss=0.838, train_loss_reg=0.00666, validation_loss=0.0545]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.68it/s]\u001b[A\n",
            "Epoch 316: 100% 58/58 [00:07<00:00,  8.07it/s, loss=0.0981, v_num=dcz5, train_loss=0.00814, train_loss_reg=0.00203, validation_loss=0.0524]Epoch 316, global step 3169: validation_loss was not in top 1\n",
            "\n",
            "Epoch 317:  52% 30/58 [00:05<00:04,  5.85it/s, loss=0.0981, v_num=dcz5, train_loss=0.00814, train_loss_reg=0.00203, validation_loss=0.0524]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.62it/s]\u001b[A\n",
            "Epoch 317: 100% 58/58 [00:06<00:00,  8.47it/s, loss=0.0579, v_num=dcz5, train_loss=0.0243, train_loss_reg=0.00061, validation_loss=0.0646] \n",
            "Epoch 317: 100% 58/58 [00:06<00:00,  8.47it/s, loss=0.0579, v_num=dcz5, train_loss=0.0243, train_loss_reg=0.00061, validation_loss=0.0646]Epoch 317, global step 3179: validation_loss was not in top 1\n",
            "Epoch 318:  52% 30/58 [00:05<00:04,  5.89it/s, loss=0.0579, v_num=dcz5, train_loss=0.0243, train_loss_reg=0.00061, validation_loss=0.0646]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.07it/s]\u001b[A\n",
            "Epoch 318: 100% 58/58 [00:07<00:00,  8.03it/s, loss=0.11, v_num=dcz5, train_loss=0.930, train_loss_reg=0.0236, validation_loss=0.0675]    Epoch 318, global step 3189: validation_loss was not in top 1\n",
            "\n",
            "Epoch 319:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.11, v_num=dcz5, train_loss=0.930, train_loss_reg=0.0236, validation_loss=0.0675]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.54it/s]\u001b[A\n",
            "Epoch 319: 100% 58/58 [00:06<00:00,  8.53it/s, loss=0.111, v_num=dcz5, train_loss=0.531, train_loss_reg=0.0255, validation_loss=0.0579]Epoch 319, global step 3199: validation_loss was not in top 1\n",
            "\n",
            "Epoch 320:  52% 30/58 [00:05<00:04,  5.94it/s, loss=0.111, v_num=dcz5, train_loss=0.531, train_loss_reg=0.0255, validation_loss=0.0579]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.56it/s]\u001b[A\n",
            "Epoch 320: 100% 58/58 [00:07<00:00,  8.09it/s, loss=0.156, v_num=dcz5, train_loss=2.100, train_loss_reg=0.0224, validation_loss=0.0591]\n",
            "Epoch 321:   0% 0/58 [00:00<?, ?it/s, loss=0.156, v_num=dcz5, train_loss=2.100, train_loss_reg=0.0224, validation_loss=0.0591]Epoch 320, global step 3209: validation_loss was not in top 1\n",
            "Epoch 321:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.156, v_num=dcz5, train_loss=2.100, train_loss_reg=0.0224, validation_loss=0.0591]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.32it/s]\u001b[A\n",
            "Epoch 321: 100% 58/58 [00:07<00:00,  8.06it/s, loss=0.132, v_num=dcz5, train_loss=0.0533, train_loss_reg=0.0196, validation_loss=0.0602]\n",
            "Epoch 322:   0% 0/58 [00:00<?, ?it/s, loss=0.132, v_num=dcz5, train_loss=0.0533, train_loss_reg=0.0196, validation_loss=0.0602]Epoch 321, global step 3219: validation_loss was not in top 1\n",
            "Epoch 322:  52% 30/58 [00:05<00:04,  5.90it/s, loss=0.132, v_num=dcz5, train_loss=0.0533, train_loss_reg=0.0196, validation_loss=0.0602]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.51it/s]\u001b[A\n",
            "Epoch 322: 100% 58/58 [00:07<00:00,  8.07it/s, loss=0.0568, v_num=dcz5, train_loss=0.825, train_loss_reg=0.00425, validation_loss=0.0751]Epoch 322, global step 3229: validation_loss was not in top 1\n",
            "\n",
            "Epoch 323:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.0568, v_num=dcz5, train_loss=0.825, train_loss_reg=0.00425, validation_loss=0.0751]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.27it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 23.84it/s]\u001b[AEpoch 323, global step 3239: validation_loss was not in top 1\n",
            "Epoch 323: 100% 58/58 [00:07<00:00,  8.22it/s, loss=0.118, v_num=dcz5, train_loss=0.700, train_loss_reg=0.0757, validation_loss=0.0607]  \n",
            "Epoch 324:  52% 30/58 [00:05<00:04,  5.90it/s, loss=0.118, v_num=dcz5, train_loss=0.700, train_loss_reg=0.0757, validation_loss=0.0607]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.64it/s]\u001b[A\n",
            "Epoch 324: 100% 58/58 [00:06<00:00,  8.53it/s, loss=0.14, v_num=dcz5, train_loss=0.979, train_loss_reg=0.114, validation_loss=0.0613]  Epoch 324, global step 3249: validation_loss was not in top 1\n",
            "\n",
            "Epoch 325:  52% 30/58 [00:05<00:04,  5.92it/s, loss=0.14, v_num=dcz5, train_loss=0.979, train_loss_reg=0.114, validation_loss=0.0613]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.08it/s]\u001b[A\n",
            "Epoch 325: 100% 58/58 [00:07<00:00,  8.07it/s, loss=0.0988, v_num=dcz5, train_loss=0.158, train_loss_reg=0.00665, validation_loss=0.0748]\n",
            "Epoch 326:   0% 0/58 [00:00<?, ?it/s, loss=0.0988, v_num=dcz5, train_loss=0.158, train_loss_reg=0.00665, validation_loss=0.0748]Epoch 325, global step 3259: validation_loss was not in top 1\n",
            "Epoch 326:  52% 30/58 [00:05<00:04,  5.90it/s, loss=0.0988, v_num=dcz5, train_loss=0.158, train_loss_reg=0.00665, validation_loss=0.0748]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.79it/s]\u001b[A\n",
            "Epoch 326: 100% 58/58 [00:07<00:00,  8.06it/s, loss=0.0589, v_num=dcz5, train_loss=0.00359, train_loss_reg=0.00359, validation_loss=0.072]Epoch 326, global step 3269: validation_loss was not in top 1\n",
            "\n",
            "Epoch 327:  52% 30/58 [00:05<00:04,  5.95it/s, loss=0.0589, v_num=dcz5, train_loss=0.00359, train_loss_reg=0.00359, validation_loss=0.072]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.53it/s]\u001b[A\n",
            "Epoch 327: 100% 58/58 [00:07<00:00,  8.10it/s, loss=0.0872, v_num=dcz5, train_loss=0.641, train_loss_reg=0.0585, validation_loss=0.0676]  Epoch 327, global step 3279: validation_loss was not in top 1\n",
            "\n",
            "Epoch 328:  52% 30/58 [00:05<00:04,  5.92it/s, loss=0.0872, v_num=dcz5, train_loss=0.641, train_loss_reg=0.0585, validation_loss=0.0676]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.17it/s]\u001b[A\n",
            "Epoch 328: 100% 58/58 [00:07<00:00,  8.06it/s, loss=0.0671, v_num=dcz5, train_loss=0.00183, train_loss_reg=0.00183, validation_loss=0.0634]Epoch 328, global step 3289: validation_loss was not in top 1\n",
            "\n",
            "Epoch 329:  52% 30/58 [00:05<00:04,  5.85it/s, loss=0.0671, v_num=dcz5, train_loss=0.00183, train_loss_reg=0.00183, validation_loss=0.0634]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.67it/s]\u001b[A\n",
            "Epoch 329: 100% 58/58 [00:06<00:00,  8.48it/s, loss=0.152, v_num=dcz5, train_loss=1.590, train_loss_reg=0.018, validation_loss=0.067]      Epoch 329, global step 3299: validation_loss was not in top 1\n",
            "\n",
            "Epoch 330:  52% 30/58 [00:05<00:04,  5.85it/s, loss=0.152, v_num=dcz5, train_loss=1.590, train_loss_reg=0.018, validation_loss=0.067]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.47it/s]\u001b[A\n",
            "Epoch 330: 100% 58/58 [00:07<00:00,  8.01it/s, loss=0.207, v_num=dcz5, train_loss=0.483, train_loss_reg=0.0371, validation_loss=0.0666]Epoch 330, global step 3309: validation_loss was not in top 1\n",
            "\n",
            "Epoch 331:  52% 30/58 [00:05<00:04,  5.88it/s, loss=0.207, v_num=dcz5, train_loss=0.483, train_loss_reg=0.0371, validation_loss=0.0666]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.49it/s]\u001b[A\n",
            "Epoch 331: 100% 58/58 [00:06<00:00,  8.29it/s, loss=0.101, v_num=dcz5, train_loss=0.132, train_loss_reg=0.0194, validation_loss=0.0776]\n",
            "Epoch 331: 100% 58/58 [00:07<00:00,  8.29it/s, loss=0.101, v_num=dcz5, train_loss=0.132, train_loss_reg=0.0194, validation_loss=0.0776]Epoch 331, global step 3319: validation_loss was not in top 1\n",
            "Epoch 332:  52% 30/58 [00:05<00:04,  5.92it/s, loss=0.101, v_num=dcz5, train_loss=0.132, train_loss_reg=0.0194, validation_loss=0.0776]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.66it/s]\u001b[A\n",
            "Epoch 332: 100% 58/58 [00:07<00:00,  8.08it/s, loss=0.0819, v_num=dcz5, train_loss=0.576, train_loss_reg=0.0745, validation_loss=0.072]Epoch 332, global step 3329: validation_loss was not in top 1\n",
            "\n",
            "Epoch 333:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.0819, v_num=dcz5, train_loss=0.576, train_loss_reg=0.0745, validation_loss=0.072]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.81it/s]\u001b[A\n",
            "Epoch 333: 100% 58/58 [00:06<00:00,  8.54it/s, loss=0.0678, v_num=dcz5, train_loss=0.275, train_loss_reg=0.00133, validation_loss=0.0737]\n",
            "Epoch 333: 100% 58/58 [00:06<00:00,  8.53it/s, loss=0.0678, v_num=dcz5, train_loss=0.275, train_loss_reg=0.00133, validation_loss=0.0737]Epoch 333, global step 3339: validation_loss was not in top 1\n",
            "Epoch 334:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.0678, v_num=dcz5, train_loss=0.275, train_loss_reg=0.00133, validation_loss=0.0737]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.55it/s]\u001b[A\n",
            "Epoch 334: 100% 58/58 [00:07<00:00,  8.06it/s, loss=0.0715, v_num=dcz5, train_loss=0.644, train_loss_reg=0.00629, validation_loss=0.0816]Epoch 334, global step 3349: validation_loss was not in top 1\n",
            "\n",
            "Epoch 335:  52% 30/58 [00:05<00:04,  5.87it/s, loss=0.0715, v_num=dcz5, train_loss=0.644, train_loss_reg=0.00629, validation_loss=0.0816]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.18it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 23.82it/s]\u001b[AEpoch 335, global step 3359: validation_loss was not in top 1\n",
            "Epoch 335: 100% 58/58 [00:07<00:00,  8.17it/s, loss=0.149, v_num=dcz5, train_loss=1.470, train_loss_reg=0.0286, validation_loss=0.0578]  \n",
            "Epoch 336:  52% 30/58 [00:05<00:04,  5.95it/s, loss=0.149, v_num=dcz5, train_loss=1.470, train_loss_reg=0.0286, validation_loss=0.0578]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.56it/s]\u001b[A\n",
            "Epoch 336: 100% 58/58 [00:07<00:00,  8.11it/s, loss=0.134, v_num=dcz5, train_loss=0.0194, train_loss_reg=0.0107, validation_loss=0.0661]Epoch 336, global step 3369: validation_loss was not in top 1\n",
            "\n",
            "Epoch 337:  52% 30/58 [00:05<00:04,  5.97it/s, loss=0.134, v_num=dcz5, train_loss=0.0194, train_loss_reg=0.0107, validation_loss=0.0661]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.60it/s]\u001b[A\n",
            "Epoch 337: 100% 58/58 [00:06<00:00,  8.60it/s, loss=0.054, v_num=dcz5, train_loss=0.290, train_loss_reg=0.000255, validation_loss=0.0665]Epoch 337, global step 3379: validation_loss was not in top 1\n",
            "\n",
            "Epoch 338:  52% 30/58 [00:05<00:04,  5.99it/s, loss=0.054, v_num=dcz5, train_loss=0.290, train_loss_reg=0.000255, validation_loss=0.0665]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.76it/s]\u001b[A\n",
            "Epoch 338: 100% 58/58 [00:07<00:00,  8.22it/s, loss=0.122, v_num=dcz5, train_loss=1.800, train_loss_reg=0.0247, validation_loss=0.0772]  \n",
            "Epoch 339:   0% 0/58 [00:00<?, ?it/s, loss=0.122, v_num=dcz5, train_loss=1.800, train_loss_reg=0.0247, validation_loss=0.0772]Epoch 338, global step 3389: validation_loss was not in top 1\n",
            "Epoch 339:  52% 30/58 [00:05<00:04,  5.97it/s, loss=0.122, v_num=dcz5, train_loss=1.800, train_loss_reg=0.0247, validation_loss=0.0772]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.67it/s]\u001b[A\n",
            "Epoch 339: 100% 58/58 [00:06<00:00,  8.60it/s, loss=0.123, v_num=dcz5, train_loss=0.0851, train_loss_reg=0.00106, validation_loss=0.0575]\n",
            "Epoch 339:   0% 0/58 [00:00<?, ?it/s, loss=0.123, v_num=dcz5, train_loss=0.0851, train_loss_reg=0.00106, validation_loss=0.0575]         Epoch 339, global step 3399: validation_loss was not in top 1\n",
            "Epoch 340:  52% 30/58 [00:04<00:04,  6.02it/s, loss=0.123, v_num=dcz5, train_loss=0.0851, train_loss_reg=0.00106, validation_loss=0.0575]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.59it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.32it/s]\u001b[AEpoch 340, global step 3409: validation_loss was not in top 1\n",
            "Epoch 340: 100% 58/58 [00:06<00:00,  8.65it/s, loss=0.0254, v_num=dcz5, train_loss=0.00714, train_loss_reg=0.00714, validation_loss=0.0537]\n",
            "Epoch 341:  52% 30/58 [00:04<00:04,  6.04it/s, loss=0.0254, v_num=dcz5, train_loss=0.00714, train_loss_reg=0.00714, validation_loss=0.0537]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.73it/s]\u001b[A\n",
            "Epoch 341: 100% 58/58 [00:06<00:00,  8.68it/s, loss=0.0227, v_num=dcz5, train_loss=0.257, train_loss_reg=0.00163, validation_loss=0.0606]  \n",
            "Epoch 342:   0% 0/58 [00:00<?, ?it/s, loss=0.0227, v_num=dcz5, train_loss=0.257, train_loss_reg=0.00163, validation_loss=0.0606]Epoch 341, global step 3419: validation_loss was not in top 1\n",
            "Epoch 342:  52% 30/58 [00:04<00:04,  6.04it/s, loss=0.0227, v_num=dcz5, train_loss=0.257, train_loss_reg=0.00163, validation_loss=0.0606]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.57it/s]\u001b[A\n",
            "Epoch 342: 100% 58/58 [00:07<00:00,  8.20it/s, loss=0.02, v_num=dcz5, train_loss=0.0108, train_loss_reg=0.00231, validation_loss=0.0606] Epoch 342, global step 3429: validation_loss was not in top 1\n",
            "\n",
            "Epoch 343:  52% 30/58 [00:05<00:04,  5.94it/s, loss=0.02, v_num=dcz5, train_loss=0.0108, train_loss_reg=0.00231, validation_loss=0.0606]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.66it/s]\u001b[A\n",
            "Epoch 343: 100% 58/58 [00:06<00:00,  8.56it/s, loss=0.0167, v_num=dcz5, train_loss=0.000121, train_loss_reg=0.000121, validation_loss=0.0583]\n",
            "Epoch 343: 100% 58/58 [00:06<00:00,  8.56it/s, loss=0.0167, v_num=dcz5, train_loss=0.000121, train_loss_reg=0.000121, validation_loss=0.0583]Epoch 343, global step 3439: validation_loss was not in top 1\n",
            "Epoch 344:  52% 30/58 [00:04<00:04,  6.02it/s, loss=0.0167, v_num=dcz5, train_loss=0.000121, train_loss_reg=0.000121, validation_loss=0.0583]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.77it/s]\u001b[A\n",
            "Epoch 344: 100% 58/58 [00:06<00:00,  8.66it/s, loss=0.0412, v_num=dcz5, train_loss=0.438, train_loss_reg=0.118, validation_loss=0.0607]      Epoch 344, global step 3449: validation_loss was not in top 1\n",
            "\n",
            "Epoch 345:  52% 30/58 [00:05<00:04,  5.99it/s, loss=0.0412, v_num=dcz5, train_loss=0.438, train_loss_reg=0.118, validation_loss=0.0607]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.67it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.41it/s]\u001b[AEpoch 345, global step 3459: validation_loss was not in top 1\n",
            "Epoch 345: 100% 58/58 [00:06<00:00,  8.63it/s, loss=0.0344, v_num=dcz5, train_loss=0.0511, train_loss_reg=0.00548, validation_loss=0.0559]\n",
            "Epoch 346:  52% 30/58 [00:05<00:04,  5.99it/s, loss=0.0344, v_num=dcz5, train_loss=0.0511, train_loss_reg=0.00548, validation_loss=0.0559]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.76it/s]\u001b[A\n",
            "Epoch 346: 100% 58/58 [00:07<00:00,  8.17it/s, loss=0.0104, v_num=dcz5, train_loss=0.0168, train_loss_reg=0.0131, validation_loss=0.0577] Epoch 346, global step 3469: validation_loss was not in top 1\n",
            "\n",
            "Epoch 347:  52% 30/58 [00:05<00:04,  5.96it/s, loss=0.0104, v_num=dcz5, train_loss=0.0168, train_loss_reg=0.0131, validation_loss=0.0577]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.62it/s]\u001b[A\n",
            "Epoch 347: 100% 58/58 [00:06<00:00,  8.58it/s, loss=0.0102, v_num=dcz5, train_loss=0.0218, train_loss_reg=0.00344, validation_loss=0.0596]Epoch 347, global step 3479: validation_loss was not in top 1\n",
            "\n",
            "Epoch 348:  52% 30/58 [00:04<00:04,  6.01it/s, loss=0.0102, v_num=dcz5, train_loss=0.0218, train_loss_reg=0.00344, validation_loss=0.0596]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.82it/s]\u001b[A\n",
            "Epoch 348: 100% 58/58 [00:07<00:00,  8.17it/s, loss=0.21, v_num=dcz5, train_loss=3.530, train_loss_reg=0.035, validation_loss=0.0551]     Epoch 348, global step 3489: validation_loss was not in top 1\n",
            "\n",
            "Epoch 349:  52% 30/58 [00:05<00:04,  5.95it/s, loss=0.21, v_num=dcz5, train_loss=3.530, train_loss_reg=0.035, validation_loss=0.0551]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.46it/s]\u001b[A\n",
            "Epoch 349: 100% 58/58 [00:07<00:00,  8.10it/s, loss=0.254, v_num=dcz5, train_loss=0.895, train_loss_reg=0.00787, validation_loss=0.0562]\n",
            "Epoch 349:   0% 0/58 [00:00<?, ?it/s, loss=0.254, v_num=dcz5, train_loss=0.895, train_loss_reg=0.00787, validation_loss=0.0562]         Epoch 349, global step 3499: validation_loss was not in top 1\n",
            "Epoch 350:  52% 30/58 [00:05<00:04,  5.90it/s, loss=0.254, v_num=dcz5, train_loss=0.895, train_loss_reg=0.00787, validation_loss=0.0562]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.50it/s]\u001b[A\n",
            "Epoch 350: 100% 58/58 [00:06<00:00,  8.52it/s, loss=0.0672, v_num=dcz5, train_loss=0.238, train_loss_reg=0.00886, validation_loss=0.0661]Epoch 350, global step 3509: validation_loss was not in top 1\n",
            "\n",
            "Epoch 351:  52% 30/58 [00:05<00:04,  5.90it/s, loss=0.0672, v_num=dcz5, train_loss=0.238, train_loss_reg=0.00886, validation_loss=0.0661]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.78it/s]\u001b[A\n",
            "Epoch 351: 100% 58/58 [00:07<00:00,  8.08it/s, loss=0.0416, v_num=dcz5, train_loss=0.0818, train_loss_reg=0.00386, validation_loss=0.0525]Epoch 351, global step 3519: validation_loss was not in top 1\n",
            "\n",
            "Epoch 352:  52% 30/58 [00:05<00:04,  5.92it/s, loss=0.0416, v_num=dcz5, train_loss=0.0818, train_loss_reg=0.00386, validation_loss=0.0525]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.74it/s]\u001b[A\n",
            "Epoch 352: 100% 58/58 [00:07<00:00,  8.09it/s, loss=0.036, v_num=dcz5, train_loss=0.0392, train_loss_reg=0.000185, validation_loss=0.0536]\n",
            "Epoch 352:   0% 0/58 [00:00<?, ?it/s, loss=0.036, v_num=dcz5, train_loss=0.0392, train_loss_reg=0.000185, validation_loss=0.0536]         Epoch 352, global step 3529: validation_loss was not in top 1\n",
            "Epoch 353:  52% 30/58 [00:05<00:04,  5.92it/s, loss=0.036, v_num=dcz5, train_loss=0.0392, train_loss_reg=0.000185, validation_loss=0.0536]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.46it/s]\u001b[A\n",
            "Epoch 353: 100% 58/58 [00:07<00:00,  8.06it/s, loss=0.091, v_num=dcz5, train_loss=1.500, train_loss_reg=0.0374, validation_loss=0.0512]   Epoch 353, global step 3539: validation_loss was not in top 1\n",
            "\n",
            "Epoch 354:  52% 30/58 [00:05<00:04,  5.90it/s, loss=0.091, v_num=dcz5, train_loss=1.500, train_loss_reg=0.0374, validation_loss=0.0512]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.82it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 24.57it/s]\u001b[AEpoch 354, global step 3549: validation_loss was not in top 1\n",
            "Epoch 354: 100% 58/58 [00:07<00:00,  8.27it/s, loss=0.146, v_num=dcz5, train_loss=1.170, train_loss_reg=0.00584, validation_loss=0.0694]\n",
            "Epoch 355:  52% 30/58 [00:05<00:04,  5.89it/s, loss=0.146, v_num=dcz5, train_loss=1.170, train_loss_reg=0.00584, validation_loss=0.0694]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.45it/s]\u001b[A\n",
            "Epoch 355: 100% 58/58 [00:07<00:00,  8.04it/s, loss=0.0968, v_num=dcz5, train_loss=0.071, train_loss_reg=0.0063, validation_loss=0.0775]Epoch 355, global step 3559: validation_loss was not in top 1\n",
            "\n",
            "Epoch 356:  52% 30/58 [00:05<00:04,  5.87it/s, loss=0.0968, v_num=dcz5, train_loss=0.071, train_loss_reg=0.0063, validation_loss=0.0775]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.56it/s]\u001b[A\n",
            "Epoch 356: 100% 58/58 [00:07<00:00,  8.04it/s, loss=0.0427, v_num=dcz5, train_loss=0.0144, train_loss_reg=0.0132, validation_loss=0.0621]Epoch 356, global step 3569: validation_loss was not in top 1\n",
            "\n",
            "Epoch 357:  52% 30/58 [00:05<00:04,  5.89it/s, loss=0.0427, v_num=dcz5, train_loss=0.0144, train_loss_reg=0.0132, validation_loss=0.0621]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.61it/s]\u001b[A\n",
            "Epoch 357: 100% 58/58 [00:07<00:00,  8.04it/s, loss=0.0411, v_num=dcz5, train_loss=0.400, train_loss_reg=0.0101, validation_loss=0.062]  Epoch 357, global step 3579: validation_loss was not in top 1\n",
            "\n",
            "Epoch 358:  52% 30/58 [00:05<00:04,  5.89it/s, loss=0.0411, v_num=dcz5, train_loss=0.400, train_loss_reg=0.0101, validation_loss=0.062]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.22it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 21.74it/s]\u001b[AEpoch 358, global step 3589: validation_loss was not in top 1\n",
            "Epoch 358: 100% 58/58 [00:07<00:00,  8.02it/s, loss=0.0369, v_num=dcz5, train_loss=0.0672, train_loss_reg=0.0195, validation_loss=0.0536]\n",
            "Epoch 359:  52% 30/58 [00:05<00:04,  5.86it/s, loss=0.0369, v_num=dcz5, train_loss=0.0672, train_loss_reg=0.0195, validation_loss=0.0536]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.43it/s]\u001b[A\n",
            "Epoch 359: 100% 58/58 [00:06<00:00,  8.47it/s, loss=0.0346, v_num=dcz5, train_loss=0.369, train_loss_reg=0.00468, validation_loss=0.0587]\n",
            "Epoch 359:   0% 0/58 [00:00<?, ?it/s, loss=0.0346, v_num=dcz5, train_loss=0.369, train_loss_reg=0.00468, validation_loss=0.0587]         Epoch 359, global step 3599: validation_loss was not in top 1\n",
            "Epoch 360:  52% 30/58 [00:05<00:04,  5.89it/s, loss=0.0346, v_num=dcz5, train_loss=0.369, train_loss_reg=0.00468, validation_loss=0.0587]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.43it/s]\u001b[A\n",
            "Epoch 360: 100% 58/58 [00:07<00:00,  8.03it/s, loss=0.116, v_num=dcz5, train_loss=1.480, train_loss_reg=0.0027, validation_loss=0.0719]  Epoch 360, global step 3609: validation_loss was not in top 1\n",
            "\n",
            "Epoch 361:  52% 30/58 [00:05<00:04,  5.87it/s, loss=0.116, v_num=dcz5, train_loss=1.480, train_loss_reg=0.0027, validation_loss=0.0719]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.67it/s]\u001b[A\n",
            "Epoch 361: 100% 58/58 [00:06<00:00,  8.49it/s, loss=0.17, v_num=dcz5, train_loss=0.816, train_loss_reg=0.00372, validation_loss=0.0806]\n",
            "Epoch 361:   0% 0/58 [00:00<?, ?it/s, loss=0.17, v_num=dcz5, train_loss=0.816, train_loss_reg=0.00372, validation_loss=0.0806]         Epoch 361, global step 3619: validation_loss was not in top 1\n",
            "Epoch 362:  52% 30/58 [00:05<00:04,  5.95it/s, loss=0.17, v_num=dcz5, train_loss=0.816, train_loss_reg=0.00372, validation_loss=0.0806]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.81it/s]\u001b[A\n",
            "Epoch 362: 100% 58/58 [00:07<00:00,  8.12it/s, loss=0.134, v_num=dcz5, train_loss=0.707, train_loss_reg=0.0188, validation_loss=0.0743]\n",
            "Epoch 362:   0% 0/58 [00:00<?, ?it/s, loss=0.134, v_num=dcz5, train_loss=0.707, train_loss_reg=0.0188, validation_loss=0.0743]         Epoch 362, global step 3629: validation_loss was not in top 1\n",
            "Epoch 363:  52% 30/58 [00:05<00:04,  5.93it/s, loss=0.134, v_num=dcz5, train_loss=0.707, train_loss_reg=0.0188, validation_loss=0.0743]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.12it/s]\u001b[A\n",
            "Epoch 363: 100% 58/58 [00:06<00:00,  8.36it/s, loss=0.105, v_num=dcz5, train_loss=0.704, train_loss_reg=0.00821, validation_loss=0.0683]Epoch 363, global step 3639: validation_loss was not in top 1\n",
            "\n",
            "Epoch 364:  52% 30/58 [00:05<00:04,  5.95it/s, loss=0.105, v_num=dcz5, train_loss=0.704, train_loss_reg=0.00821, validation_loss=0.0683]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.53it/s]\u001b[A\n",
            "Epoch 364: 100% 58/58 [00:06<00:00,  8.57it/s, loss=0.212, v_num=dcz5, train_loss=2.300, train_loss_reg=0.0396, validation_loss=0.0655] \n",
            "Epoch 364:   0% 0/58 [00:00<?, ?it/s, loss=0.212, v_num=dcz5, train_loss=2.300, train_loss_reg=0.0396, validation_loss=0.0655]         Epoch 364, global step 3649: validation_loss was not in top 1\n",
            "Epoch 365:  52% 30/58 [00:05<00:04,  5.95it/s, loss=0.212, v_num=dcz5, train_loss=2.300, train_loss_reg=0.0396, validation_loss=0.0655]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.82it/s]\u001b[A\n",
            "Epoch 365: 100% 58/58 [00:06<00:00,  8.59it/s, loss=0.18, v_num=dcz5, train_loss=0.0344, train_loss_reg=0.0135, validation_loss=0.0655]\n",
            "Epoch 365:   0% 0/58 [00:00<?, ?it/s, loss=0.18, v_num=dcz5, train_loss=0.0344, train_loss_reg=0.0135, validation_loss=0.0655]         Epoch 365, global step 3659: validation_loss was not in top 1\n",
            "Epoch 366:  52% 30/58 [00:05<00:04,  5.97it/s, loss=0.18, v_num=dcz5, train_loss=0.0344, train_loss_reg=0.0135, validation_loss=0.0655]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.79it/s]\u001b[A\n",
            "Epoch 366: 100% 58/58 [00:06<00:00,  8.60it/s, loss=0.0538, v_num=dcz5, train_loss=0.537, train_loss_reg=0.00362, validation_loss=0.0722]Epoch 366, global step 3669: validation_loss was not in top 1\n",
            "\n",
            "Epoch 367:  52% 30/58 [00:05<00:04,  5.95it/s, loss=0.0538, v_num=dcz5, train_loss=0.537, train_loss_reg=0.00362, validation_loss=0.0722]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.42it/s]\u001b[A\n",
            "Epoch 367: 100% 58/58 [00:07<00:00,  8.11it/s, loss=0.0569, v_num=dcz5, train_loss=0.266, train_loss_reg=0.00224, validation_loss=0.0606]Epoch 367, global step 3679: validation_loss was not in top 1\n",
            "\n",
            "Epoch 368:  52% 30/58 [00:05<00:04,  5.94it/s, loss=0.0569, v_num=dcz5, train_loss=0.266, train_loss_reg=0.00224, validation_loss=0.0606]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.88it/s]\u001b[A\n",
            "Epoch 368: 100% 58/58 [00:07<00:00,  8.12it/s, loss=0.0797, v_num=dcz5, train_loss=0.915, train_loss_reg=0.0988, validation_loss=0.0704] Epoch 368, global step 3689: validation_loss was not in top 1\n",
            "\n",
            "Epoch 369:  52% 30/58 [00:05<00:04,  5.92it/s, loss=0.0797, v_num=dcz5, train_loss=0.915, train_loss_reg=0.0988, validation_loss=0.0704]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.54it/s]\u001b[A\n",
            "Epoch 369: 100% 58/58 [00:07<00:00,  8.11it/s, loss=0.0991, v_num=dcz5, train_loss=0.000741, train_loss_reg=0.000263, validation_loss=0.0696]\n",
            "Epoch 369: 100% 58/58 [00:07<00:00,  8.10it/s, loss=0.0991, v_num=dcz5, train_loss=0.000741, train_loss_reg=0.000263, validation_loss=0.0696]Epoch 369, global step 3699: validation_loss was not in top 1\n",
            "Epoch 370:  52% 30/58 [00:05<00:04,  5.84it/s, loss=0.0991, v_num=dcz5, train_loss=0.000741, train_loss_reg=0.000263, validation_loss=0.0696]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.63it/s]\u001b[A\n",
            "Epoch 370: 100% 58/58 [00:07<00:00,  8.00it/s, loss=0.223, v_num=dcz5, train_loss=1.290, train_loss_reg=0.0659, validation_loss=0.0623]      \n",
            "                                               \u001b[AEpoch 370, global step 3709: validation_loss was not in top 1\n",
            "Epoch 371:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.223, v_num=dcz5, train_loss=1.290, train_loss_reg=0.0659, validation_loss=0.0623]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.52it/s]\u001b[A\n",
            "Epoch 371: 100% 58/58 [00:07<00:00,  8.25it/s, loss=0.251, v_num=dcz5, train_loss=0.132, train_loss_reg=0.00623, validation_loss=0.0726]Epoch 371, global step 3719: validation_loss was not in top 1\n",
            "\n",
            "Epoch 372:  52% 30/58 [00:05<00:04,  5.96it/s, loss=0.251, v_num=dcz5, train_loss=0.132, train_loss_reg=0.00623, validation_loss=0.0726]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.51it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 21.95it/s]\u001b[AEpoch 372, global step 3729: validation_loss was not in top 1\n",
            "Epoch 372: 100% 58/58 [00:07<00:00,  8.11it/s, loss=0.0845, v_num=dcz5, train_loss=0.0954, train_loss_reg=0.0106, validation_loss=0.064]\n",
            "Epoch 373:  52% 30/58 [00:05<00:04,  5.88it/s, loss=0.0845, v_num=dcz5, train_loss=0.0954, train_loss_reg=0.0106, validation_loss=0.064]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.49it/s]\u001b[A\n",
            "Epoch 373: 100% 58/58 [00:07<00:00,  8.03it/s, loss=0.0694, v_num=dcz5, train_loss=0.313, train_loss_reg=9.21e-6, validation_loss=0.0724]Epoch 373, global step 3739: validation_loss was not in top 1\n",
            "\n",
            "Epoch 374:  52% 30/58 [00:05<00:04,  5.87it/s, loss=0.0694, v_num=dcz5, train_loss=0.313, train_loss_reg=9.21e-6, validation_loss=0.0724]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.77it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 21.92it/s]\u001b[AEpoch 374, global step 3749: validation_loss was not in top 1\n",
            "Epoch 374: 100% 58/58 [00:07<00:00,  8.02it/s, loss=0.0869, v_num=dcz5, train_loss=0.0976, train_loss_reg=0.00301, validation_loss=0.0687]\n",
            "Epoch 375:  52% 30/58 [00:05<00:04,  5.92it/s, loss=0.0869, v_num=dcz5, train_loss=0.0976, train_loss_reg=0.00301, validation_loss=0.0687]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.82it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.34it/s]\u001b[AEpoch 375, global step 3759: validation_loss was not in top 1\n",
            "Epoch 375: 100% 58/58 [00:06<00:00,  8.56it/s, loss=0.0736, v_num=dcz5, train_loss=0.766, train_loss_reg=0.00317, validation_loss=0.0707] \n",
            "Epoch 376:  52% 30/58 [00:05<00:04,  5.92it/s, loss=0.0736, v_num=dcz5, train_loss=0.766, train_loss_reg=0.00317, validation_loss=0.0707]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.60it/s]\u001b[A\n",
            "Epoch 376: 100% 58/58 [00:07<00:00,  8.07it/s, loss=0.177, v_num=dcz5, train_loss=2.430, train_loss_reg=0.0911, validation_loss=0.0582]  Epoch 376, global step 3769: validation_loss was not in top 1\n",
            "\n",
            "Epoch 377:  52% 30/58 [00:05<00:04,  5.87it/s, loss=0.177, v_num=dcz5, train_loss=2.430, train_loss_reg=0.0911, validation_loss=0.0582]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.81it/s]\u001b[A\n",
            "Epoch 377: 100% 58/58 [00:06<00:00,  8.51it/s, loss=0.202, v_num=dcz5, train_loss=0.837, train_loss_reg=0.00355, validation_loss=0.0723]Epoch 377, global step 3779: validation_loss was not in top 1\n",
            "\n",
            "Epoch 378:  52% 30/58 [00:05<00:04,  5.83it/s, loss=0.202, v_num=dcz5, train_loss=0.837, train_loss_reg=0.00355, validation_loss=0.0723]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.62it/s]\u001b[A\n",
            "Epoch 378: 100% 58/58 [00:06<00:00,  8.45it/s, loss=0.249, v_num=dcz5, train_loss=2.800, train_loss_reg=0.0881, validation_loss=0.0782] Epoch 378, global step 3789: validation_loss was not in top 1\n",
            "\n",
            "Epoch 379:  52% 30/58 [00:05<00:04,  5.88it/s, loss=0.249, v_num=dcz5, train_loss=2.800, train_loss_reg=0.0881, validation_loss=0.0782]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.72it/s]\u001b[A\n",
            "Epoch 379: 100% 58/58 [00:06<00:00,  8.51it/s, loss=0.214, v_num=dcz5, train_loss=0.0307, train_loss_reg=0.0307, validation_loss=0.0728]\n",
            "Epoch 379:   0% 0/58 [00:00<?, ?it/s, loss=0.214, v_num=dcz5, train_loss=0.0307, train_loss_reg=0.0307, validation_loss=0.0728]         Epoch 379, global step 3799: validation_loss was not in top 1\n",
            "Epoch 380:  52% 30/58 [00:05<00:04,  5.87it/s, loss=0.214, v_num=dcz5, train_loss=0.0307, train_loss_reg=0.0307, validation_loss=0.0728]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.55it/s]\u001b[A\n",
            "Epoch 380: 100% 58/58 [00:06<00:00,  8.31it/s, loss=0.098, v_num=dcz5, train_loss=0.474, train_loss_reg=0.00959, validation_loss=0.0629]\n",
            "Epoch 380: 100% 58/58 [00:06<00:00,  8.30it/s, loss=0.098, v_num=dcz5, train_loss=0.474, train_loss_reg=0.00959, validation_loss=0.0629]Epoch 380, global step 3809: validation_loss was not in top 1\n",
            "Epoch 381:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.098, v_num=dcz5, train_loss=0.474, train_loss_reg=0.00959, validation_loss=0.0629]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.72it/s]\u001b[A\n",
            "Epoch 381: 100% 58/58 [00:06<00:00,  8.53it/s, loss=0.116, v_num=dcz5, train_loss=0.498, train_loss_reg=0.0502, validation_loss=0.0648] Epoch 381, global step 3819: validation_loss was not in top 1\n",
            "\n",
            "Epoch 382:  52% 30/58 [00:05<00:04,  5.88it/s, loss=0.116, v_num=dcz5, train_loss=0.498, train_loss_reg=0.0502, validation_loss=0.0648]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.58it/s]\u001b[A\n",
            "Epoch 382: 100% 58/58 [00:06<00:00,  8.50it/s, loss=0.118, v_num=dcz5, train_loss=0.775, train_loss_reg=0.0694, validation_loss=0.064] Epoch 382, global step 3829: validation_loss was not in top 1\n",
            "\n",
            "Epoch 383:  52% 30/58 [00:05<00:04,  5.94it/s, loss=0.118, v_num=dcz5, train_loss=0.775, train_loss_reg=0.0694, validation_loss=0.064]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.40it/s]\u001b[A\n",
            "Epoch 383: 100% 58/58 [00:07<00:00,  8.09it/s, loss=0.126, v_num=dcz5, train_loss=0.322, train_loss_reg=0.00794, validation_loss=0.069]\n",
            "Epoch 384:   0% 0/58 [00:00<?, ?it/s, loss=0.126, v_num=dcz5, train_loss=0.322, train_loss_reg=0.00794, validation_loss=0.069]Epoch 383, global step 3839: validation_loss was not in top 1\n",
            "Epoch 384:  52% 30/58 [00:05<00:04,  5.97it/s, loss=0.126, v_num=dcz5, train_loss=0.322, train_loss_reg=0.00794, validation_loss=0.069]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.60it/s]\u001b[A\n",
            "Epoch 384: 100% 58/58 [00:07<00:00,  8.13it/s, loss=0.0666, v_num=dcz5, train_loss=0.0112, train_loss_reg=0.0112, validation_loss=0.073]Epoch 384, global step 3849: validation_loss was not in top 1\n",
            "\n",
            "Epoch 385:  52% 30/58 [00:05<00:04,  5.92it/s, loss=0.0666, v_num=dcz5, train_loss=0.0112, train_loss_reg=0.0112, validation_loss=0.073]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.67it/s]\u001b[A\n",
            "Epoch 385: 100% 58/58 [00:06<00:00,  8.55it/s, loss=0.0403, v_num=dcz5, train_loss=0.352, train_loss_reg=0.000115, validation_loss=0.0625]\n",
            "Epoch 386:   0% 0/58 [00:00<?, ?it/s, loss=0.0403, v_num=dcz5, train_loss=0.352, train_loss_reg=0.000115, validation_loss=0.0625]Epoch 385, global step 3859: validation_loss was not in top 1\n",
            "Epoch 386:  52% 30/58 [00:05<00:04,  5.93it/s, loss=0.0403, v_num=dcz5, train_loss=0.352, train_loss_reg=0.000115, validation_loss=0.0625]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.65it/s]\u001b[A\n",
            "Epoch 386: 100% 58/58 [00:06<00:00,  8.55it/s, loss=0.0792, v_num=dcz5, train_loss=0.695, train_loss_reg=0.0389, validation_loss=0.0639]  Epoch 386, global step 3869: validation_loss was not in top 1\n",
            "\n",
            "Epoch 387:  52% 30/58 [00:05<00:04,  5.92it/s, loss=0.0792, v_num=dcz5, train_loss=0.695, train_loss_reg=0.0389, validation_loss=0.0639]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.56it/s]\u001b[A\n",
            "Epoch 387: 100% 58/58 [00:06<00:00,  8.55it/s, loss=0.07, v_num=dcz5, train_loss=0.247, train_loss_reg=0.00147, validation_loss=0.0717] Epoch 387, global step 3879: validation_loss was not in top 1\n",
            "\n",
            "Epoch 388:  52% 30/58 [00:05<00:04,  5.97it/s, loss=0.07, v_num=dcz5, train_loss=0.247, train_loss_reg=0.00147, validation_loss=0.0717]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.77it/s]\u001b[A\n",
            "Epoch 388: 100% 58/58 [00:07<00:00,  8.14it/s, loss=0.0272, v_num=dcz5, train_loss=0.0208, train_loss_reg=0.00562, validation_loss=0.064]\n",
            "Epoch 388, global step 3889: validation_loss was not in top 1\n",
            "Epoch 389:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.0272, v_num=dcz5, train_loss=0.0208, train_loss_reg=0.00562, validation_loss=0.064]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.71it/s]\u001b[A\n",
            "Epoch 389: 100% 58/58 [00:07<00:00,  8.09it/s, loss=0.0193, v_num=dcz5, train_loss=0.0608, train_loss_reg=0.015, validation_loss=0.0605] Epoch 389, global step 3899: validation_loss was not in top 1\n",
            "\n",
            "Epoch 390:  52% 30/58 [00:05<00:04,  5.94it/s, loss=0.0193, v_num=dcz5, train_loss=0.0608, train_loss_reg=0.015, validation_loss=0.0605]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.67it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 24.56it/s]\u001b[AEpoch 390, global step 3909: validation_loss was not in top 1\n",
            "Epoch 390: 100% 58/58 [00:06<00:00,  8.31it/s, loss=0.0383, v_num=dcz5, train_loss=0.0366, train_loss_reg=0.00522, validation_loss=0.068]\n",
            "Epoch 391:  52% 30/58 [00:04<00:04,  6.02it/s, loss=0.0383, v_num=dcz5, train_loss=0.0366, train_loss_reg=0.00522, validation_loss=0.068]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.72it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.23it/s]\u001b[AEpoch 391, global step 3919: validation_loss was not in top 1\n",
            "Epoch 391: 100% 58/58 [00:06<00:00,  8.65it/s, loss=0.0296, v_num=dcz5, train_loss=0.0188, train_loss_reg=0.0188, validation_loss=0.0677]\n",
            "Epoch 392:  52% 30/58 [00:04<00:04,  6.05it/s, loss=0.0296, v_num=dcz5, train_loss=0.0188, train_loss_reg=0.0188, validation_loss=0.0677]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.61it/s]\u001b[A\n",
            "Epoch 392: 100% 58/58 [00:07<00:00,  8.22it/s, loss=0.0893, v_num=dcz5, train_loss=1.120, train_loss_reg=0.00651, validation_loss=0.0584]\n",
            "Epoch 392:   0% 0/58 [00:00<?, ?it/s, loss=0.0893, v_num=dcz5, train_loss=1.120, train_loss_reg=0.00651, validation_loss=0.0584]         Epoch 392, global step 3929: validation_loss was not in top 1\n",
            "Epoch 393:  52% 30/58 [00:05<00:04,  5.95it/s, loss=0.0893, v_num=dcz5, train_loss=1.120, train_loss_reg=0.00651, validation_loss=0.0584]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.45it/s]\u001b[A\n",
            "Epoch 393: 100% 58/58 [00:06<00:00,  8.42it/s, loss=0.113, v_num=dcz5, train_loss=0.528, train_loss_reg=0.00252, validation_loss=0.0732] \n",
            "Epoch 393: 100% 58/58 [00:06<00:00,  8.42it/s, loss=0.113, v_num=dcz5, train_loss=0.528, train_loss_reg=0.00252, validation_loss=0.0732]Epoch 393, global step 3939: validation_loss was not in top 1\n",
            "Epoch 394:  52% 30/58 [00:05<00:04,  5.94it/s, loss=0.113, v_num=dcz5, train_loss=0.528, train_loss_reg=0.00252, validation_loss=0.0732]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.80it/s]\u001b[A\n",
            "Epoch 394: 100% 58/58 [00:07<00:00,  8.10it/s, loss=0.0642, v_num=dcz5, train_loss=0.513, train_loss_reg=0.00559, validation_loss=0.0654]Epoch 394, global step 3949: validation_loss was not in top 1\n",
            "\n",
            "Epoch 395:  52% 30/58 [00:05<00:04,  5.84it/s, loss=0.0642, v_num=dcz5, train_loss=0.513, train_loss_reg=0.00559, validation_loss=0.0654]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.27it/s]\u001b[A\n",
            "Epoch 395: 100% 58/58 [00:06<00:00,  8.44it/s, loss=0.0703, v_num=dcz5, train_loss=0.252, train_loss_reg=0.0235, validation_loss=0.055]  \n",
            "Epoch 395:   0% 0/58 [00:00<?, ?it/s, loss=0.0703, v_num=dcz5, train_loss=0.252, train_loss_reg=0.0235, validation_loss=0.055]         Epoch 395, global step 3959: validation_loss was not in top 1\n",
            "Epoch 396:  52% 30/58 [00:05<00:04,  5.88it/s, loss=0.0703, v_num=dcz5, train_loss=0.252, train_loss_reg=0.0235, validation_loss=0.055]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.68it/s]\u001b[A\n",
            "Epoch 396: 100% 58/58 [00:07<00:00,  8.05it/s, loss=0.0622, v_num=dcz5, train_loss=0.0107, train_loss_reg=0.0107, validation_loss=0.0557]\n",
            "Epoch 397:   0% 0/58 [00:00<?, ?it/s, loss=0.0622, v_num=dcz5, train_loss=0.0107, train_loss_reg=0.0107, validation_loss=0.0557]Epoch 396, global step 3969: validation_loss was not in top 1\n",
            "Epoch 397:  52% 30/58 [00:05<00:04,  5.94it/s, loss=0.0622, v_num=dcz5, train_loss=0.0107, train_loss_reg=0.0107, validation_loss=0.0557]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.54it/s]\u001b[A\n",
            "Epoch 397: 100% 58/58 [00:07<00:00,  8.11it/s, loss=0.0345, v_num=dcz5, train_loss=0.045, train_loss_reg=0.00839, validation_loss=0.0568]\n",
            "Epoch 397: 100% 58/58 [00:07<00:00,  8.11it/s, loss=0.0345, v_num=dcz5, train_loss=0.045, train_loss_reg=0.00839, validation_loss=0.0568]Epoch 397, global step 3979: validation_loss was not in top 1\n",
            "Epoch 398:  52% 30/58 [00:05<00:04,  5.86it/s, loss=0.0345, v_num=dcz5, train_loss=0.045, train_loss_reg=0.00839, validation_loss=0.0568]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.85it/s]\u001b[A\n",
            "Epoch 398: 100% 58/58 [00:06<00:00,  8.49it/s, loss=0.0163, v_num=dcz5, train_loss=0.0268, train_loss_reg=0.0124, validation_loss=0.0603]\n",
            "Epoch 398:   0% 0/58 [00:00<?, ?it/s, loss=0.0163, v_num=dcz5, train_loss=0.0268, train_loss_reg=0.0124, validation_loss=0.0603]         Epoch 398, global step 3989: validation_loss was not in top 1\n",
            "Epoch 399:  52% 30/58 [00:05<00:04,  5.97it/s, loss=0.0163, v_num=dcz5, train_loss=0.0268, train_loss_reg=0.0124, validation_loss=0.0603]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.62it/s]\u001b[A\n",
            "Epoch 399: 100% 58/58 [00:07<00:00,  8.13it/s, loss=0.0324, v_num=dcz5, train_loss=0.301, train_loss_reg=0.0362, validation_loss=0.0531] \n",
            "Epoch 399: 100% 58/58 [00:07<00:00,  8.13it/s, loss=0.0324, v_num=dcz5, train_loss=0.301, train_loss_reg=0.0362, validation_loss=0.0531]Epoch 399, global step 3999: validation_loss was not in top 1\n",
            "Epoch 400:  52% 30/58 [00:05<00:04,  5.96it/s, loss=0.0324, v_num=dcz5, train_loss=0.301, train_loss_reg=0.0362, validation_loss=0.0531]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.65it/s]\u001b[A\n",
            "Epoch 400: 100% 58/58 [00:06<00:00,  8.59it/s, loss=0.0274, v_num=dcz5, train_loss=0.0183, train_loss_reg=0.00244, validation_loss=0.0644]Epoch 400, global step 4009: validation_loss was not in top 1\n",
            "\n",
            "Epoch 401:  52% 30/58 [00:04<00:04,  6.01it/s, loss=0.0274, v_num=dcz5, train_loss=0.0183, train_loss_reg=0.00244, validation_loss=0.0644]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.63it/s]\u001b[A\n",
            "Epoch 401: 100% 58/58 [00:06<00:00,  8.64it/s, loss=0.00592, v_num=dcz5, train_loss=0.00145, train_loss_reg=0.00145, validation_loss=0.0597]Epoch 401, global step 4019: validation_loss was not in top 1\n",
            "\n",
            "Epoch 402:  52% 30/58 [00:05<00:04,  5.98it/s, loss=0.00592, v_num=dcz5, train_loss=0.00145, train_loss_reg=0.00145, validation_loss=0.0597]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.70it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 22.03it/s]\u001b[AEpoch 402, global step 4029: validation_loss was not in top 1\n",
            "Epoch 402: 100% 58/58 [00:07<00:00,  8.13it/s, loss=0.00646, v_num=dcz5, train_loss=0.0115, train_loss_reg=0.0115, validation_loss=0.054]   \n",
            "Epoch 403:  52% 30/58 [00:05<00:04,  5.95it/s, loss=0.00646, v_num=dcz5, train_loss=0.0115, train_loss_reg=0.0115, validation_loss=0.054]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.46it/s]\u001b[A\n",
            "Epoch 403: 100% 58/58 [00:07<00:00,  8.10it/s, loss=0.0198, v_num=dcz5, train_loss=0.013, train_loss_reg=0.013, validation_loss=0.0633]  \n",
            "Epoch 404:   0% 0/58 [00:00<?, ?it/s, loss=0.0198, v_num=dcz5, train_loss=0.013, train_loss_reg=0.013, validation_loss=0.0633]Epoch 403, global step 4039: validation_loss was not in top 1\n",
            "Epoch 404:  52% 30/58 [00:05<00:04,  5.94it/s, loss=0.0198, v_num=dcz5, train_loss=0.013, train_loss_reg=0.013, validation_loss=0.0633]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.45it/s]\u001b[A\n",
            "Epoch 404: 100% 58/58 [00:07<00:00,  8.09it/s, loss=0.0224, v_num=dcz5, train_loss=0.0443, train_loss_reg=0.00407, validation_loss=0.0628]\n",
            "Epoch 404: 100% 58/58 [00:07<00:00,  8.09it/s, loss=0.0224, v_num=dcz5, train_loss=0.0443, train_loss_reg=0.00407, validation_loss=0.0628]Epoch 404, global step 4049: validation_loss was not in top 1\n",
            "Epoch 405:  52% 30/58 [00:05<00:04,  5.97it/s, loss=0.0224, v_num=dcz5, train_loss=0.0443, train_loss_reg=0.00407, validation_loss=0.0628]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.62it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.26it/s]\u001b[AEpoch 405, global step 4059: validation_loss was not in top 1\n",
            "Epoch 405: 100% 58/58 [00:06<00:00,  8.60it/s, loss=0.0176, v_num=dcz5, train_loss=0.180, train_loss_reg=0.00663, validation_loss=0.0625] \n",
            "Epoch 406:  52% 30/58 [00:05<00:04,  5.95it/s, loss=0.0176, v_num=dcz5, train_loss=0.180, train_loss_reg=0.00663, validation_loss=0.0625]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.79it/s]\u001b[A\n",
            "Epoch 406: 100% 58/58 [00:07<00:00,  8.09it/s, loss=0.0311, v_num=dcz5, train_loss=0.028, train_loss_reg=0.00444, validation_loss=0.0529]\n",
            "Epoch 406: 100% 58/58 [00:07<00:00,  8.09it/s, loss=0.0311, v_num=dcz5, train_loss=0.028, train_loss_reg=0.00444, validation_loss=0.0529]Epoch 406, global step 4069: validation_loss was not in top 1\n",
            "Epoch 407:  52% 30/58 [00:05<00:04,  5.90it/s, loss=0.0311, v_num=dcz5, train_loss=0.028, train_loss_reg=0.00444, validation_loss=0.0529]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.31it/s]\u001b[A\n",
            "Epoch 407: 100% 58/58 [00:07<00:00,  8.04it/s, loss=0.0249, v_num=dcz5, train_loss=0.0248, train_loss_reg=0.00951, validation_loss=0.065]Epoch 407, global step 4079: validation_loss was not in top 1\n",
            "\n",
            "Epoch 408:  52% 30/58 [00:05<00:04,  5.96it/s, loss=0.0249, v_num=dcz5, train_loss=0.0248, train_loss_reg=0.00951, validation_loss=0.065]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.69it/s]\u001b[A\n",
            "Epoch 408: 100% 58/58 [00:07<00:00,  8.12it/s, loss=0.0359, v_num=dcz5, train_loss=0.285, train_loss_reg=0.00923, validation_loss=0.0576]\n",
            "Epoch 408:   0% 0/58 [00:00<?, ?it/s, loss=0.0359, v_num=dcz5, train_loss=0.285, train_loss_reg=0.00923, validation_loss=0.0576]         Epoch 408, global step 4089: validation_loss was not in top 1\n",
            "Epoch 409:  52% 30/58 [00:05<00:04,  5.88it/s, loss=0.0359, v_num=dcz5, train_loss=0.285, train_loss_reg=0.00923, validation_loss=0.0576]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.71it/s]\u001b[A\n",
            "Epoch 409: 100% 58/58 [00:06<00:00,  8.50it/s, loss=0.0563, v_num=dcz5, train_loss=0.259, train_loss_reg=0.00426, validation_loss=0.0648]\n",
            "Epoch 409:   0% 0/58 [00:00<?, ?it/s, loss=0.0563, v_num=dcz5, train_loss=0.259, train_loss_reg=0.00426, validation_loss=0.0648]         Epoch 409, global step 4099: validation_loss was not in top 1\n",
            "Epoch 410:  52% 30/58 [00:05<00:04,  5.99it/s, loss=0.0563, v_num=dcz5, train_loss=0.259, train_loss_reg=0.00426, validation_loss=0.0648]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.83it/s]\u001b[A\n",
            "Epoch 410: 100% 58/58 [00:07<00:00,  8.16it/s, loss=0.0328, v_num=dcz5, train_loss=0.00239, train_loss_reg=0.00239, validation_loss=0.060]Epoch 410, global step 4109: validation_loss was not in top 1\n",
            "\n",
            "Epoch 411:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.0328, v_num=dcz5, train_loss=0.00239, train_loss_reg=0.00239, validation_loss=0.060]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.48it/s]\u001b[A\n",
            "Epoch 411: 100% 58/58 [00:07<00:00,  8.14it/s, loss=0.0279, v_num=dcz5, train_loss=0.292, train_loss_reg=0.0136, validation_loss=0.0643]  Epoch 411, global step 4119: validation_loss was not in top 1\n",
            "\n",
            "Epoch 412:  52% 30/58 [00:05<00:04,  5.94it/s, loss=0.0279, v_num=dcz5, train_loss=0.292, train_loss_reg=0.0136, validation_loss=0.0643]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.61it/s]\u001b[A\n",
            "Epoch 412: 100% 58/58 [00:06<00:00,  8.42it/s, loss=0.0444, v_num=dcz5, train_loss=0.0226, train_loss_reg=0.0226, validation_loss=0.0705]\n",
            "                                               \u001b[AEpoch 412, global step 4129: validation_loss was not in top 1\n",
            "Epoch 413:  52% 30/58 [00:05<00:04,  5.90it/s, loss=0.0444, v_num=dcz5, train_loss=0.0226, train_loss_reg=0.0226, validation_loss=0.0705]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 27.95it/s]\u001b[A\n",
            "Epoch 413: 100% 58/58 [00:07<00:00,  8.02it/s, loss=0.0411, v_num=dcz5, train_loss=0.182, train_loss_reg=0.00511, validation_loss=0.0722]\n",
            "Epoch 414:   0% 0/58 [00:00<?, ?it/s, loss=0.0411, v_num=dcz5, train_loss=0.182, train_loss_reg=0.00511, validation_loss=0.0722]Epoch 413, global step 4139: validation_loss was not in top 1\n",
            "Epoch 414:  52% 30/58 [00:05<00:04,  5.89it/s, loss=0.0411, v_num=dcz5, train_loss=0.182, train_loss_reg=0.00511, validation_loss=0.0722]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.18it/s]\u001b[A\n",
            "Epoch 414: 100% 58/58 [00:07<00:00,  8.03it/s, loss=0.0257, v_num=dcz5, train_loss=0.00102, train_loss_reg=0.00102, validation_loss=0.0668]\n",
            "Epoch 414: 100% 58/58 [00:07<00:00,  8.03it/s, loss=0.0257, v_num=dcz5, train_loss=0.00102, train_loss_reg=0.00102, validation_loss=0.0668]Epoch 414, global step 4149: validation_loss was not in top 1\n",
            "Epoch 415:  52% 30/58 [00:05<00:04,  5.99it/s, loss=0.0257, v_num=dcz5, train_loss=0.00102, train_loss_reg=0.00102, validation_loss=0.0668]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.44it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 22.03it/s]\u001b[AEpoch 415, global step 4159: validation_loss was not in top 1\n",
            "Epoch 415: 100% 58/58 [00:07<00:00,  8.15it/s, loss=0.0114, v_num=dcz5, train_loss=0.00957, train_loss_reg=0.00957, validation_loss=0.0604]\n",
            "Epoch 416:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.0114, v_num=dcz5, train_loss=0.00957, train_loss_reg=0.00957, validation_loss=0.0604]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.54it/s]\u001b[A\n",
            "Epoch 416: 100% 58/58 [00:07<00:00,  8.09it/s, loss=0.00586, v_num=dcz5, train_loss=0.00156, train_loss_reg=0.00156, validation_loss=0.0699]Epoch 416, global step 4169: validation_loss was not in top 1\n",
            "\n",
            "Epoch 417:  52% 30/58 [00:05<00:04,  5.98it/s, loss=0.00586, v_num=dcz5, train_loss=0.00156, train_loss_reg=0.00156, validation_loss=0.0699]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.80it/s]\u001b[A\n",
            "Epoch 417: 100% 58/58 [00:07<00:00,  8.15it/s, loss=0.13, v_num=dcz5, train_loss=2.480, train_loss_reg=0.285, validation_loss=0.0555]       Epoch 417, global step 4179: validation_loss was not in top 1\n",
            "\n",
            "Epoch 418:  52% 30/58 [00:05<00:04,  5.93it/s, loss=0.13, v_num=dcz5, train_loss=2.480, train_loss_reg=0.285, validation_loss=0.0555]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.69it/s]\u001b[A\n",
            "Epoch 418: 100% 58/58 [00:07<00:00,  8.10it/s, loss=0.139, v_num=dcz5, train_loss=0.176, train_loss_reg=0.0342, validation_loss=0.0716]Epoch 418, global step 4189: validation_loss was not in top 1\n",
            "\n",
            "Epoch 419:  52% 30/58 [00:05<00:04,  5.93it/s, loss=0.139, v_num=dcz5, train_loss=0.176, train_loss_reg=0.0342, validation_loss=0.0716]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.52it/s]\u001b[A\n",
            "Epoch 419: 100% 58/58 [00:07<00:00,  8.21it/s, loss=0.024, v_num=dcz5, train_loss=0.0141, train_loss_reg=0.0108, validation_loss=0.0878]\n",
            "Epoch 419: 100% 58/58 [00:07<00:00,  8.21it/s, loss=0.024, v_num=dcz5, train_loss=0.0141, train_loss_reg=0.0108, validation_loss=0.0878]Epoch 419, global step 4199: validation_loss was not in top 1\n",
            "Epoch 420:  52% 30/58 [00:05<00:04,  5.93it/s, loss=0.024, v_num=dcz5, train_loss=0.0141, train_loss_reg=0.0108, validation_loss=0.0878]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.64it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.35it/s]\u001b[AEpoch 420, global step 4209: validation_loss was not in top 1\n",
            "Epoch 420: 100% 58/58 [00:06<00:00,  8.57it/s, loss=0.0451, v_num=dcz5, train_loss=0.323, train_loss_reg=0.000519, validation_loss=0.0773]\n",
            "Epoch 421:  52% 30/58 [00:05<00:04,  5.98it/s, loss=0.0451, v_num=dcz5, train_loss=0.323, train_loss_reg=0.000519, validation_loss=0.0773]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.66it/s]\u001b[A\n",
            "Epoch 421: 100% 58/58 [00:06<00:00,  8.61it/s, loss=0.121, v_num=dcz5, train_loss=1.570, train_loss_reg=0.085, validation_loss=0.0607]    Epoch 421, global step 4219: validation_loss was not in top 1\n",
            "\n",
            "Epoch 422:  52% 30/58 [00:05<00:04,  5.97it/s, loss=0.121, v_num=dcz5, train_loss=1.570, train_loss_reg=0.085, validation_loss=0.0607]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.50it/s]\u001b[A\n",
            "Epoch 422: 100% 58/58 [00:06<00:00,  8.44it/s, loss=0.102, v_num=dcz5, train_loss=0.207, train_loss_reg=0.0131, validation_loss=0.068]\n",
            "Epoch 423:   0% 0/58 [00:00<?, ?it/s, loss=0.102, v_num=dcz5, train_loss=0.207, train_loss_reg=0.0131, validation_loss=0.068]Epoch 422, global step 4229: validation_loss was not in top 1\n",
            "Epoch 423:  52% 30/58 [00:05<00:04,  5.99it/s, loss=0.102, v_num=dcz5, train_loss=0.207, train_loss_reg=0.0131, validation_loss=0.068]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.47it/s]\u001b[A\n",
            "Epoch 423: 100% 58/58 [00:07<00:00,  8.14it/s, loss=0.0193, v_num=dcz5, train_loss=0.0128, train_loss_reg=0.0116, validation_loss=0.0629]\n",
            "Epoch 423: 100% 58/58 [00:07<00:00,  8.14it/s, loss=0.0193, v_num=dcz5, train_loss=0.0128, train_loss_reg=0.0116, validation_loss=0.0629]Epoch 423, global step 4239: validation_loss was not in top 1\n",
            "Epoch 424:  52% 30/58 [00:05<00:04,  5.95it/s, loss=0.0193, v_num=dcz5, train_loss=0.0128, train_loss_reg=0.0116, validation_loss=0.0629]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.47it/s]\u001b[A\n",
            "Epoch 424: 100% 58/58 [00:07<00:00,  8.10it/s, loss=0.0104, v_num=dcz5, train_loss=0.00503, train_loss_reg=0.0048, validation_loss=0.0568]Epoch 424, global step 4249: validation_loss was not in top 1\n",
            "\n",
            "Epoch 425:  52% 30/58 [00:05<00:04,  5.95it/s, loss=0.0104, v_num=dcz5, train_loss=0.00503, train_loss_reg=0.0048, validation_loss=0.0568]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.78it/s]\u001b[A\n",
            "Epoch 425: 100% 58/58 [00:06<00:00,  8.59it/s, loss=0.00731, v_num=dcz5, train_loss=0.00599, train_loss_reg=0.00146, validation_loss=0.0564]\n",
            "Epoch 425: 100% 58/58 [00:06<00:00,  8.58it/s, loss=0.00731, v_num=dcz5, train_loss=0.00599, train_loss_reg=0.00146, validation_loss=0.0564]Epoch 425, global step 4259: validation_loss was not in top 1\n",
            "Epoch 426:  52% 30/58 [00:05<00:04,  5.94it/s, loss=0.00731, v_num=dcz5, train_loss=0.00599, train_loss_reg=0.00146, validation_loss=0.0564]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.49it/s]\u001b[A\n",
            "Epoch 426: 100% 58/58 [00:07<00:00,  8.09it/s, loss=0.0883, v_num=dcz5, train_loss=1.510, train_loss_reg=0.0382, validation_loss=0.0592]    Epoch 426, global step 4269: validation_loss was not in top 1\n",
            "\n",
            "Epoch 427:  52% 30/58 [00:05<00:04,  5.97it/s, loss=0.0883, v_num=dcz5, train_loss=1.510, train_loss_reg=0.0382, validation_loss=0.0592]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.36it/s]\u001b[A\n",
            "Epoch 427: 100% 58/58 [00:07<00:00,  8.12it/s, loss=0.0916, v_num=dcz5, train_loss=0.0549, train_loss_reg=0.000768, validation_loss=0.0592]Epoch 427, global step 4279: validation_loss was not in top 1\n",
            "\n",
            "Epoch 428:  52% 30/58 [00:05<00:04,  5.92it/s, loss=0.0916, v_num=dcz5, train_loss=0.0549, train_loss_reg=0.000768, validation_loss=0.0592]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.61it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 24.15it/s]\u001b[AEpoch 428, global step 4289: validation_loss was not in top 1\n",
            "Epoch 428: 100% 58/58 [00:07<00:00,  8.26it/s, loss=0.0311, v_num=dcz5, train_loss=0.385, train_loss_reg=0.00404, validation_loss=0.0706]  \n",
            "Epoch 429:  52% 30/58 [00:05<00:04,  5.96it/s, loss=0.0311, v_num=dcz5, train_loss=0.385, train_loss_reg=0.00404, validation_loss=0.0706]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.34it/s]\u001b[A\n",
            "Epoch 429: 100% 58/58 [00:07<00:00,  8.11it/s, loss=0.0873, v_num=dcz5, train_loss=1.010, train_loss_reg=0.00341, validation_loss=0.0549]Epoch 429, global step 4299: validation_loss was not in top 1\n",
            "\n",
            "Epoch 430:  52% 30/58 [00:05<00:04,  5.96it/s, loss=0.0873, v_num=dcz5, train_loss=1.010, train_loss_reg=0.00341, validation_loss=0.0549]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.45it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:02<00:00, 21.93it/s]\u001b[AEpoch 430, global step 4309: validation_loss was not in top 1\n",
            "Epoch 430: 100% 58/58 [00:07<00:00,  8.10it/s, loss=0.0859, v_num=dcz5, train_loss=0.439, train_loss_reg=0.00839, validation_loss=0.0545]\n",
            "Epoch 431:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.0859, v_num=dcz5, train_loss=0.439, train_loss_reg=0.00839, validation_loss=0.0545]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.66it/s]\u001b[A\n",
            "Epoch 431: 100% 58/58 [00:06<00:00,  8.54it/s, loss=0.0345, v_num=dcz5, train_loss=0.0436, train_loss_reg=0.00446, validation_loss=0.0545]Epoch 431, global step 4319: validation_loss was not in top 1\n",
            "\n",
            "Epoch 432:  52% 30/58 [00:05<00:04,  5.99it/s, loss=0.0345, v_num=dcz5, train_loss=0.0436, train_loss_reg=0.00446, validation_loss=0.0545]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.52it/s]\u001b[A\n",
            "Epoch 432: 100% 58/58 [00:07<00:00,  8.12it/s, loss=0.0757, v_num=dcz5, train_loss=1.220, train_loss_reg=0.0595, validation_loss=0.0538]  \n",
            "Epoch 432: 100% 58/58 [00:07<00:00,  8.12it/s, loss=0.0757, v_num=dcz5, train_loss=1.220, train_loss_reg=0.0595, validation_loss=0.0538]Epoch 432, global step 4329: validation_loss was not in top 1\n",
            "Epoch 433:  52% 30/58 [00:05<00:04,  5.89it/s, loss=0.0757, v_num=dcz5, train_loss=1.220, train_loss_reg=0.0595, validation_loss=0.0538]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.49it/s]\u001b[A\n",
            "Epoch 433: 100% 58/58 [00:07<00:00,  8.04it/s, loss=0.0969, v_num=dcz5, train_loss=0.0038, train_loss_reg=0.0038, validation_loss=0.0597]\n",
            "Epoch 434:   0% 0/58 [00:00<?, ?it/s, loss=0.0969, v_num=dcz5, train_loss=0.0038, train_loss_reg=0.0038, validation_loss=0.0597]Epoch 433, global step 4339: validation_loss was not in top 1\n",
            "Epoch 434:  52% 30/58 [00:05<00:04,  5.89it/s, loss=0.0969, v_num=dcz5, train_loss=0.0038, train_loss_reg=0.0038, validation_loss=0.0597]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.69it/s]\u001b[A\n",
            "Epoch 434: 100% 58/58 [00:07<00:00,  8.05it/s, loss=0.0397, v_num=dcz5, train_loss=0.115, train_loss_reg=0.0147, validation_loss=0.0644] \n",
            "Epoch 435:   0% 0/58 [00:00<?, ?it/s, loss=0.0397, v_num=dcz5, train_loss=0.115, train_loss_reg=0.0147, validation_loss=0.0644]Epoch 434, global step 4349: validation_loss was not in top 1\n",
            "Epoch 435:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.0397, v_num=dcz5, train_loss=0.115, train_loss_reg=0.0147, validation_loss=0.0644]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.68it/s]\u001b[A\n",
            "Validating: 100% 48/48 [00:01<00:00, 28.27it/s]\u001b[AEpoch 435, global step 4359: validation_loss was not in top 1\n",
            "Epoch 435: 100% 58/58 [00:06<00:00,  8.54it/s, loss=0.0125, v_num=dcz5, train_loss=0.000869, train_loss_reg=0.000869, validation_loss=0.0619]\n",
            "Epoch 436:  52% 30/58 [00:05<00:04,  5.95it/s, loss=0.0125, v_num=dcz5, train_loss=0.000869, train_loss_reg=0.000869, validation_loss=0.0619]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.55it/s]\u001b[A\n",
            "Epoch 436: 100% 58/58 [00:07<00:00,  8.11it/s, loss=0.0207, v_num=dcz5, train_loss=0.283, train_loss_reg=0.00909, validation_loss=0.0618]    \n",
            "Epoch 437:   0% 0/58 [00:00<?, ?it/s, loss=0.0207, v_num=dcz5, train_loss=0.283, train_loss_reg=0.00909, validation_loss=0.0618]Epoch 436, global step 4369: validation_loss was not in top 1\n",
            "Epoch 437:  52% 30/58 [00:05<00:04,  5.94it/s, loss=0.0207, v_num=dcz5, train_loss=0.283, train_loss_reg=0.00909, validation_loss=0.0618]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.71it/s]\u001b[A\n",
            "Epoch 437: 100% 58/58 [00:06<00:00,  8.58it/s, loss=0.0231, v_num=dcz5, train_loss=0.0631, train_loss_reg=0.0176, validation_loss=0.0638]Epoch 437, global step 4379: validation_loss was not in top 1\n",
            "\n",
            "Epoch 438:  52% 30/58 [00:05<00:04,  5.96it/s, loss=0.0231, v_num=dcz5, train_loss=0.0631, train_loss_reg=0.0176, validation_loss=0.0638]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.69it/s]\u001b[A\n",
            "Epoch 438: 100% 58/58 [00:06<00:00,  8.60it/s, loss=0.0115, v_num=dcz5, train_loss=0.0329, train_loss_reg=0.00279, validation_loss=0.0606]\n",
            "Epoch 438:   0% 0/58 [00:00<?, ?it/s, loss=0.0115, v_num=dcz5, train_loss=0.0329, train_loss_reg=0.00279, validation_loss=0.0606]         Epoch 438, global step 4389: validation_loss was not in top 1\n",
            "Epoch 439:  52% 30/58 [00:05<00:04,  5.97it/s, loss=0.0115, v_num=dcz5, train_loss=0.0329, train_loss_reg=0.00279, validation_loss=0.0606]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.63it/s]\u001b[A\n",
            "Epoch 439: 100% 58/58 [00:06<00:00,  8.59it/s, loss=0.00838, v_num=dcz5, train_loss=0.0141, train_loss_reg=0.00392, validation_loss=0.0561]\n",
            "Epoch 439:   0% 0/58 [00:00<?, ?it/s, loss=0.00838, v_num=dcz5, train_loss=0.0141, train_loss_reg=0.00392, validation_loss=0.0561]         Epoch 439, global step 4399: validation_loss was not in top 1\n",
            "Epoch 440:  52% 30/58 [00:04<00:04,  6.02it/s, loss=0.00838, v_num=dcz5, train_loss=0.0141, train_loss_reg=0.00392, validation_loss=0.0561]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.52it/s]\u001b[A\n",
            "Epoch 440: 100% 58/58 [00:07<00:00,  8.18it/s, loss=0.00589, v_num=dcz5, train_loss=0.0313, train_loss_reg=0.00966, validation_loss=0.0582]\n",
            "Epoch 440:   0% 0/58 [00:00<?, ?it/s, loss=0.00589, v_num=dcz5, train_loss=0.0313, train_loss_reg=0.00966, validation_loss=0.0582]         Epoch 440, global step 4409: validation_loss was not in top 1\n",
            "Epoch 441:  52% 30/58 [00:05<00:04,  5.98it/s, loss=0.00589, v_num=dcz5, train_loss=0.0313, train_loss_reg=0.00966, validation_loss=0.0582]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.26it/s]\u001b[A\n",
            "Epoch 441: 100% 58/58 [00:07<00:00,  8.13it/s, loss=0.141, v_num=dcz5, train_loss=2.730, train_loss_reg=0.0726, validation_loss=0.0564]    Epoch 441, global step 4419: validation_loss was not in top 1\n",
            "\n",
            "Epoch 442:  52% 30/58 [00:05<00:04,  5.91it/s, loss=0.141, v_num=dcz5, train_loss=2.730, train_loss_reg=0.0726, validation_loss=0.0564]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.55it/s]\u001b[A\n",
            "Epoch 442: 100% 58/58 [00:06<00:00,  8.53it/s, loss=0.143, v_num=dcz5, train_loss=0.017, train_loss_reg=0.0117, validation_loss=0.062] \n",
            "Epoch 442:   0% 0/58 [00:00<?, ?it/s, loss=0.143, v_num=dcz5, train_loss=0.017, train_loss_reg=0.0117, validation_loss=0.062]         Epoch 442, global step 4429: validation_loss was not in top 1\n",
            "Epoch 443:  52% 30/58 [00:04<00:04,  6.02it/s, loss=0.143, v_num=dcz5, train_loss=0.017, train_loss_reg=0.0117, validation_loss=0.062]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.51it/s]\u001b[A\n",
            "Epoch 443: 100% 58/58 [00:07<00:00,  8.17it/s, loss=0.019, v_num=dcz5, train_loss=0.008, train_loss_reg=0.0023, validation_loss=0.0674]Epoch 443, global step 4439: validation_loss was not in top 1\n",
            "\n",
            "Epoch 444:  52% 30/58 [00:05<00:04,  5.88it/s, loss=0.019, v_num=dcz5, train_loss=0.008, train_loss_reg=0.0023, validation_loss=0.0674]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.62it/s]\u001b[A\n",
            "Epoch 444: 100% 58/58 [00:07<00:00,  8.04it/s, loss=0.0321, v_num=dcz5, train_loss=0.266, train_loss_reg=0.00933, validation_loss=0.0629]Epoch 444, global step 4449: validation_loss was not in top 1\n",
            "\n",
            "Epoch 445:  52% 30/58 [00:05<00:04,  5.95it/s, loss=0.0321, v_num=dcz5, train_loss=0.266, train_loss_reg=0.00933, validation_loss=0.0629]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.34it/s]\u001b[A\n",
            "Epoch 445: 100% 58/58 [00:07<00:00,  8.10it/s, loss=0.0215, v_num=dcz5, train_loss=0.006, train_loss_reg=0.006, validation_loss=0.0567]  Epoch 445, global step 4459: validation_loss was not in top 1\n",
            "\n",
            "Epoch 446:  52% 30/58 [00:05<00:04,  5.98it/s, loss=0.0215, v_num=dcz5, train_loss=0.006, train_loss_reg=0.006, validation_loss=0.0567]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.73it/s]\u001b[A\n",
            "Epoch 446: 100% 58/58 [00:06<00:00,  8.60it/s, loss=0.00489, v_num=dcz5, train_loss=0.00216, train_loss_reg=0.00216, validation_loss=0.0576]Epoch 446, global step 4469: validation_loss was not in top 1\n",
            "\n",
            "Epoch 447:  52% 30/58 [00:05<00:04,  5.94it/s, loss=0.00489, v_num=dcz5, train_loss=0.00216, train_loss_reg=0.00216, validation_loss=0.0576]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.57it/s]\u001b[A\n",
            "Epoch 447: 100% 58/58 [00:06<00:00,  8.57it/s, loss=0.00802, v_num=dcz5, train_loss=0.000145, train_loss_reg=0.000145, validation_loss=0.0526]Epoch 447, global step 4479: validation_loss was not in top 1\n",
            "\n",
            "Epoch 448:  52% 30/58 [00:05<00:04,  5.96it/s, loss=0.00802, v_num=dcz5, train_loss=0.000145, train_loss_reg=0.000145, validation_loss=0.0526]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.41it/s]\u001b[A\n",
            "Epoch 448: 100% 58/58 [00:07<00:00,  8.09it/s, loss=0.0376, v_num=dcz5, train_loss=0.528, train_loss_reg=0.0169, validation_loss=0.0566]      \n",
            "Epoch 448:   0% 0/58 [00:00<?, ?it/s, loss=0.0376, v_num=dcz5, train_loss=0.528, train_loss_reg=0.0169, validation_loss=0.0566]         Epoch 448, global step 4489: validation_loss was not in top 1\n",
            "Epoch 449:  52% 30/58 [00:05<00:04,  5.97it/s, loss=0.0376, v_num=dcz5, train_loss=0.528, train_loss_reg=0.0169, validation_loss=0.0566]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Validating:   0% 0/48 [00:00<?, ?it/s]\u001b[A\n",
            "Validating:  62% 30/48 [00:01<00:00, 28.54it/s]\u001b[A\n",
            "Epoch 449: 100% 58/58 [00:07<00:00,  8.12it/s, loss=0.0348, v_num=dcz5, train_loss=0.0333, train_loss_reg=0.0141, validation_loss=0.063]\n",
            "Epoch 449: 100% 58/58 [00:07<00:00,  8.12it/s, loss=0.0348, v_num=dcz5, train_loss=0.0333, train_loss_reg=0.0141, validation_loss=0.063]Epoch 449, global step 4499: validation_loss was not in top 1\n",
            "Epoch 449: 100% 58/58 [00:07<00:00,  8.11it/s, loss=0.0348, v_num=dcz5, train_loss=0.0333, train_loss_reg=0.0141, validation_loss=0.063]\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 851... (success).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train_loss ▆▆▇▄▁▁▁▂▁█▁▁▅▄▃▁▄▂▂▂▁▁▄▁▂▇▁▅▃▃▂▅▁▁▁▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        train_loss_reg ▄█▃▁▂▂▁▂▂▂▁▂▃▆▂▁▁▁▁▁▁▁▁▂▄▂▁▃▂▁▄▁▁▂▁▂▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   trainer/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss █▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:                 epoch 449\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:            train_loss 0.03332\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:        train_loss_reg 0.01406\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:   trainer/global_step 4499\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m:       validation_loss 0.06297\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Synced \u001b[33mdecent-water-106\u001b[0m: \u001b[34mhttps://wandb.ai/onurcopur/Engagement%20Detection/runs/1i19dcz5\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: ./wandb/run-20220118_150830-1i19dcz5/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyper-parameter search\n",
        "If you want to do hyperparameter search, you can modify sweep.yaml file and manage your search via [wandb sweeps](https://docs.wandb.ai/guides/sweeps)"
      ],
      "metadata": {
        "id": "C2VGUUPsH6zM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb sweep configs/sweep.yaml"
      ],
      "metadata": {
        "id": "S0lcjT0xIC8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading pre-trained weights\n",
        "If you don't want to train the model from scratch, you can download the pre-train weights for fine-tunnig or inference. "
      ],
      "metadata": {
        "id": "xUM9A-vmIMCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fileid=\"1iKqfokZUWNKM5riVa5-B_UVWFOIkCPb2\"\n",
        "url = 'https://drive.google.com/uc?id={}'.format(fileid)\n",
        "output = '/content/ED-MTT/pre-trained-weights.ckpt'\n",
        "gdown.download(url, output, quiet=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "KYw2LIMJILe6",
        "outputId": "452adb21-cff1-4b18-86dc-2339300de152"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1iKqfokZUWNKM5riVa5-B_UVWFOIkCPb2\n",
            "To: /content/ED-MTT/pre-trained-weights.ckpt\n",
            "100%|██████████| 415M/415M [00:04<00:00, 102MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/ED-MTT/pre-trained-weights.ckpt'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python code/test.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wnducIIZz7Q",
        "outputId": "54e9dce1-1fd2-45c2-ff29-86c599e92915"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33monurcopur\u001b[0m (use `wandb login --relogin` to force relogin)\n",
            "/usr/local/lib/python3.7/dist-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'batchnorm_default': Defaults list is missing `_self_`. See https://hydra.cc/docs/upgrades/1.0_to_1.1/default_composition_order for more information\n",
            "  warnings.warn(msg, UserWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/hydra/_internal/defaults_list.py:412: UserWarning: In batchnorm_default: Invalid overriding of hydra/job_logging:\n",
            "Default list overrides requires 'override' keyword.\n",
            "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/defaults_list_override for more information.\n",
            "\n",
            "  deprecation_warning(msg)\n",
            "/usr/local/lib/python3.7/dist-packages/hydra/_internal/defaults_list.py:412: UserWarning: In batchnorm_default: Invalid overriding of hydra/hydra_logging:\n",
            "Default list overrides requires 'override' keyword.\n",
            "See https://hydra.cc/docs/next/upgrades/1.0_to_1.1/defaults_list_override for more information.\n",
            "\n",
            "  deprecation_warning(msg)\n",
            "[\u001b[36m2022-01-18 16:05:39,580\u001b[0m][\u001b[34m__main__\u001b[0m][\u001b[32mINFO\u001b[0m] - data:\n",
            "  root: /content/ED-MTT/data/OpenFace_features/\n",
            "  l_dir: /content/ED-MTT/Engagement_Labels.xlsx\n",
            "  level:\n",
            "  - 0.0\n",
            "  - 0.33\n",
            "  - 0.66\n",
            "  - 1.0\n",
            "  frame_size: 100\n",
            "  step_size: 1.2\n",
            "  gaze_range:\n",
            "  - 4\n",
            "  - 10\n",
            "  head_range:\n",
            "  - 10\n",
            "  - 13\n",
            "  rot_range:\n",
            "  - 13\n",
            "  - 16\n",
            "  aus_range:\n",
            "  - -35\n",
            "  - -18\n",
            "  attributes:\n",
            "  - gaze_seg\n",
            "  - head_seg\n",
            "  - aus_seg\n",
            "  functions:\n",
            "  - length\n",
            "  - maximum\n",
            "  - minimum\n",
            "  - variance\n",
            "  cols:\n",
            "  - gaze_cols\n",
            "  - head_cols\n",
            "  - aus_cols\n",
            "  batch_size: 16\n",
            "model:\n",
            "  lstm:\n",
            "    n_hidden: 1024\n",
            "    n_layers: 2\n",
            "  mlp:\n",
            "    h1: 64\n",
            "    h2: 32\n",
            "    out: 2\n",
            "  train:\n",
            "    dropout: 0\n",
            "    n_epochs: 450\n",
            "    lr: 5.0e-05\n",
            "    triplet_margin: 1\n",
            "    threshold: 2.5\n",
            "  seed: 214\n",
            "\u001b[0m\n",
            "Global seed set to 214\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:474: DtypeWarning: Columns (10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:474: DtypeWarning: Columns (4,5,6,7,8,9) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/core/datamodule.py:474: DtypeWarning: Columns (4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395) have mixed types.Specify dtype option on import or set low_memory=False.\n",
            "  fn(*args, **kwargs)\n",
            "Global seed set to 214\n",
            "Global seed set to 214\n",
            "  0% 0/48 [00:00<?, ?it/s]0.39755458\n",
            "0.33000001311302185\n",
            "  2% 1/48 [00:00<00:25,  1.81it/s]0.544789\n",
            "0.33000001311302185\n",
            "  4% 2/48 [00:00<00:20,  2.20it/s]0.6436634\n",
            "1.0\n",
            "  6% 3/48 [00:01<00:18,  2.37it/s]0.7259592\n",
            "1.0\n",
            "  8% 4/48 [00:01<00:18,  2.43it/s]0.77951026\n",
            "1.0\n",
            " 10% 5/48 [00:02<00:17,  2.47it/s]0.47331023\n",
            "0.33000001311302185\n",
            " 12% 6/48 [00:02<00:16,  2.49it/s]0.83041286\n",
            "1.0\n",
            " 15% 7/48 [00:02<00:16,  2.52it/s]0.7855187\n",
            "1.0\n",
            " 17% 8/48 [00:03<00:15,  2.53it/s]0.58490443\n",
            "0.33000001311302185\n",
            " 19% 9/48 [00:03<00:15,  2.54it/s]0.4997396\n",
            "0.33000001311302185\n",
            " 21% 10/48 [00:04<00:14,  2.54it/s]0.4798603\n",
            "0.33000001311302185\n",
            " 23% 11/48 [00:04<00:14,  2.52it/s]0.8899333\n",
            "1.0\n",
            " 25% 12/48 [00:04<00:14,  2.54it/s]0.5954861\n",
            "0.33000001311302185\n",
            " 27% 13/48 [00:05<00:13,  2.56it/s]0.6622756\n",
            "0.6600000262260437\n",
            " 29% 14/48 [00:05<00:13,  2.56it/s]0.8199185\n",
            "0.6600000262260437\n",
            " 31% 15/48 [00:06<00:12,  2.57it/s]1.0082583\n",
            "1.0\n",
            " 33% 16/48 [00:06<00:12,  2.57it/s]0.36943567\n",
            "0.6600000262260437\n",
            " 35% 17/48 [00:06<00:12,  2.58it/s]0.5911242\n",
            "0.33000001311302185\n",
            " 38% 18/48 [00:07<00:11,  2.58it/s]0.57541317\n",
            "0.6600000262260437\n",
            " 40% 19/48 [00:07<00:11,  2.58it/s]0.63589805\n",
            "0.33000001311302185\n",
            " 42% 20/48 [00:07<00:10,  2.58it/s]0.7954043\n",
            "0.6600000262260437\n",
            " 44% 21/48 [00:08<00:10,  2.59it/s]0.5613143\n",
            "0.6600000262260437\n",
            " 46% 22/48 [00:08<00:10,  2.59it/s]0.8345752\n",
            "1.0\n",
            " 48% 23/48 [00:09<00:09,  2.59it/s]0.64603114\n",
            "0.33000001311302185\n",
            " 50% 24/48 [00:09<00:09,  2.58it/s]0.6741966\n",
            "0.6600000262260437\n",
            " 52% 25/48 [00:09<00:08,  2.59it/s]0.4281987\n",
            "0.6600000262260437\n",
            " 54% 26/48 [00:10<00:08,  2.61it/s]0.5786853\n",
            "1.0\n",
            " 56% 27/48 [00:10<00:08,  2.61it/s]0.82513547\n",
            "0.6600000262260437\n",
            " 58% 28/48 [00:11<00:07,  2.62it/s]0.88244975\n",
            "1.0\n",
            " 60% 29/48 [00:11<00:07,  2.63it/s]0.7029027\n",
            "1.0\n",
            " 62% 30/48 [00:11<00:06,  2.62it/s]0.8899333\n",
            "1.0\n",
            " 65% 31/48 [00:12<00:06,  2.62it/s]0.64445204\n",
            "0.6600000262260437\n",
            " 67% 32/48 [00:12<00:06,  2.61it/s]0.6492062\n",
            "0.6600000262260437\n",
            " 69% 33/48 [00:12<00:05,  2.59it/s]0.72412276\n",
            "0.6600000262260437\n",
            " 71% 34/48 [00:13<00:05,  2.60it/s]0.7495798\n",
            "0.6600000262260437\n",
            " 73% 35/48 [00:13<00:05,  2.59it/s]0.20606089\n",
            "0.0\n",
            " 75% 36/48 [00:14<00:04,  2.59it/s]0.84642094\n",
            "1.0\n",
            " 77% 37/48 [00:14<00:04,  2.59it/s]0.6937537\n",
            "1.0\n",
            " 79% 38/48 [00:14<00:03,  2.56it/s]0.7698127\n",
            "0.6600000262260437\n",
            " 81% 39/48 [00:15<00:03,  2.58it/s]0.6191989\n",
            "0.6600000262260437\n",
            " 83% 40/48 [00:15<00:03,  2.59it/s]0.16687489\n",
            "0.0\n",
            " 85% 41/48 [00:16<00:02,  2.60it/s]0.7109448\n",
            "1.0\n",
            " 88% 42/48 [00:16<00:02,  2.62it/s]0.77825\n",
            "0.6600000262260437\n",
            " 90% 43/48 [00:16<00:01,  2.61it/s]0.7562103\n",
            "0.6600000262260437\n",
            " 92% 44/48 [00:17<00:01,  2.61it/s]0.7065394\n",
            "0.6600000262260437\n",
            " 94% 45/48 [00:17<00:01,  2.61it/s]0.20459509\n",
            "0.0\n",
            " 96% 46/48 [00:17<00:00,  2.60it/s]0.49305087\n",
            "0.0\n",
            " 98% 47/48 [00:18<00:00,  2.61it/s]0.8584481\n",
            "0.6600000262260437\n",
            "100% 48/48 [00:18<00:00,  2.56it/s]\n",
            "mse  0.04270711165768837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "sys.path.insert(1, '/content/ED-MTT/code')\n",
        "import utils\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n"
      ],
      "metadata": {
        "id": "YS51LM23Z5bM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%config InlineBackend.figure_format='retina'\n",
        "sns.set(style='whitegrid', palette='muted', font_scale=1.2)\n",
        "HAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#93D30C\", \"#8F00FF\"]\n",
        "sns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\n",
        "rcParams['figure.figsize'] = 16, 10"
      ],
      "metadata": {
        "id": "McKKj5XXaJa6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = np.load(\"predictions.npy\")\n",
        "labels = np.load(\"labels.npy\")"
      ],
      "metadata": {
        "id": "m_ZUYoFJaovI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "utils.plot_graph(predictions,labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "N7NmgIv-at8_",
        "outputId": "e6203b73-24ad-4850-cd84-62c980cb160e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "image/png": {
              "width": 937,
              "height": 580
            }
          }
        }
      ]
    }
  ]
}